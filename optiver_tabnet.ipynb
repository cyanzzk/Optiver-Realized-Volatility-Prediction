{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "062b3e8e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep 17 18:45:23 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "|  0%   33C    P8    23W / 370W |      1MiB / 24268MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:03:00.0  On |                  N/A |\r\n",
      "| 36%   31C    P5    32W / 370W |    161MiB / 24262MiB |     50%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1   N/A  N/A      1290      G   /usr/lib/xorg/Xorg                 92MiB |\r\n",
      "|    1   N/A  N/A      1466      G   /usr/bin/gnome-shell               28MiB |\r\n",
      "|    1   N/A  N/A      2720      G   ...AAAAAAAAA= --shared-files       37MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把原版 改成groupkfold  做一个小范围的调参\n",
    "\n",
    "!nvidia-smi\n",
    "import psutil\n",
    "psutil.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6985a9d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suff = 917000\n",
    "ENV = \"10900\"\n",
    "n_startup_trials=15\n",
    "n_trials=20\n",
    "\n",
    "if ENV == \"9700\":\n",
    "    data_dir = 'E:/optiver-realized-volatility-prediction'\n",
    "    output_dir = \"E:/output\"\n",
    "elif ENV == \"10900\":\n",
    "    data_dir = '/home/xuming/workspace/optiver-realized-volatility-prediction'\n",
    "    output_dir = \"/home/xuming/workspace/output\"\n",
    "elif ENV == \"colab\":\n",
    "    data_dir = '/content/drive/Shareddrives/workspace/optiver-realized-volatility-prediction'\n",
    "    output_dir = \"/content/drive/Shareddrives/workspace/output\"\n",
    "    !pip -q install pytorch_tabnet==3.1.1\n",
    "    !pip -q install optuna\n",
    "    !pip -q install -U pandas==1.2.4\n",
    "    !pip -q install -U scikit-learn==0.23.2\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb69c8c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-28T05:33:23.104972Z",
     "iopub.status.busy": "2021-08-28T05:33:23.104175Z",
     "iopub.status.idle": "2021-08-28T05:33:25.413436Z",
     "shell.execute_reply": "2021-08-28T05:33:25.412970Z",
     "shell.execute_reply.started": "2021-08-27T20:25:44.050584Z"
    },
    "papermill": {
     "duration": 2.337906,
     "end_time": "2021-08-28T05:33:25.413564",
     "exception": false,
     "start_time": "2021-08-28T05:33:23.075658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy.matlib\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import shutil\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import optuna\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5647d561",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def init_logger(log_file=f'{output_dir}/train_tabnet.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "def get_timediff(time1,time2):\n",
    "    minute_,second_ = divmod(time2-time1,60)\n",
    "    return f\"{int(minute_):02d}:{int(second_):02d}\"\n",
    "\n",
    "LOGGER = init_logger(f'{output_dir}/train_tabnet_{suff}.log')\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False # set True to be faster\n",
    "seed_everything(42) ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc67464",
   "metadata": {
    "papermill": {
     "duration": 0.020526,
     "end_time": "2021-08-28T05:33:25.599198",
     "exception": false,
     "start_time": "2021-08-28T05:33:25.578672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54c42228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T05:33:25.648178Z",
     "iopub.status.busy": "2021-08-28T05:33:25.647351Z",
     "iopub.status.idle": "2021-08-28T05:33:25.649868Z",
     "shell.execute_reply": "2021-08-28T05:33:25.649459Z",
     "shell.execute_reply.started": "2021-08-27T19:56:21.615461Z"
    },
    "papermill": {
     "duration": 0.029359,
     "end_time": "2021-08-28T05:33:25.649987",
     "exception": false,
     "start_time": "2021-08-28T05:33:25.620628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_train_test():\n",
    "    # Function to read our base train and test set\n",
    "    train = pd.read_csv(f'{data_dir}/train.csv')\n",
    "    test = pd.read_csv(f'{data_dir}/test.csv')\n",
    "    # Create a key to merge with book and trade data\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n",
    "    print(f'Our training set has {train.shape[0]} rows')\n",
    "    print(f'Our test set has {test.shape[0]} rows')\n",
    "    print(f'Our training set has {train.isna().sum().sum()} missing values')\n",
    "    print(f'Our test set has {test.isna().sum().sum()} missing values')\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5282fa63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T05:33:25.695336Z",
     "iopub.status.busy": "2021-08-28T05:33:25.694846Z",
     "iopub.status.idle": "2021-08-28T05:33:27.037052Z",
     "shell.execute_reply": "2021-08-28T05:33:27.036261Z",
     "shell.execute_reply.started": "2021-08-27T19:56:21.625036Z"
    },
    "papermill": {
     "duration": 1.366299,
     "end_time": "2021-08-28T05:33:27.037203",
     "exception": false,
     "start_time": "2021-08-28T05:33:25.670904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training set has 428932 rows\n",
      "Our test set has 3 rows\n",
      "Our training set has 0 missing values\n",
      "Our test set has 0 missing values\n"
     ]
    }
   ],
   "source": [
    "train, test = read_train_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1962ba6",
   "metadata": {
    "papermill": {
     "duration": 0.020835,
     "end_time": "2021-08-28T05:33:27.079039",
     "exception": false,
     "start_time": "2021-08-28T05:33:27.058204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff25066c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T05:33:27.179871Z",
     "iopub.status.busy": "2021-08-28T05:33:27.155192Z",
     "iopub.status.idle": "2021-08-28T05:33:27.182246Z",
     "shell.execute_reply": "2021-08-28T05:33:27.181812Z",
     "shell.execute_reply.started": "2021-08-27T19:56:23.227967Z"
    },
    "papermill": {
     "duration": 0.082398,
     "end_time": "2021-08-28T05:33:27.182370",
     "exception": false,
     "start_time": "2021-08-28T05:33:27.099972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data directory\n",
    "def calc_wap1(df):\n",
    "    # Function to calculate first WAP\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap2(df):\n",
    "    # Function to calculate second WAP\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "def log_return(series):\n",
    "    # Function to calculate the log of the return\n",
    "    return np.log(series).diff()\n",
    "\n",
    "def realized_volatility(series):\n",
    "    # Calculate the realized volatility\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "def count_unique(series):\n",
    "    # Function to count unique elements of a series\n",
    "    return len(np.unique(series))\n",
    "\n",
    "def book_preprocessor(file_path):\n",
    "    # Function to preprocess book data (for each stock id)\n",
    "    \n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Calculate Wap\n",
    "    df['wap1'] = calc_wap1(df)\n",
    "    df['wap2'] = calc_wap2(df)\n",
    "    \n",
    "    # Calculate log returns\n",
    "    df['log_return1'] = df.groupby(['time_id'])['wap1'].apply(log_return)\n",
    "    df['log_return2'] = df.groupby(['time_id'])['wap2'].apply(log_return)\n",
    "    \n",
    "    # Calculate wap balance\n",
    "    df['wap_balance'] = abs(df['wap1'] - df['wap2'])\n",
    "    \n",
    "    # Calculate spread\n",
    "    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n",
    "    df['price_spread2'] = (df['ask_price2'] - df['bid_price2']) / ((df['ask_price2'] + df['bid_price2']) / 2)\n",
    "    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n",
    "    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n",
    "    df[\"bid_ask_spread\"] = abs(df['bid_spread'] - df['ask_spread'])\n",
    "    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'wap1': [np.sum, np.mean, np.std],\n",
    "        'wap2': [np.sum, np.mean, np.std],\n",
    "        'log_return1': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return2': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'wap_balance': [np.sum, np.mean, np.std],\n",
    "        'price_spread':[np.sum, np.mean, np.std],\n",
    "        'price_spread2':[np.sum, np.mean, np.std],\n",
    "        'bid_spread':[np.sum, np.mean, np.std],\n",
    "        'ask_spread':[np.sum, np.mean, np.std],\n",
    "        'total_volume':[np.sum, np.mean, np.std],\n",
    "        'volume_imbalance':[np.sum, np.mean, np.std],\n",
    "        \"bid_ask_spread\":[np.sum, np.mean, np.std],\n",
    "    }\n",
    "    \n",
    "    def get_stats_window(seconds_in_bucket, add_suffix = False):\n",
    "        # Function to get group stats for different windows (seconds in bucket)\n",
    "        \n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(create_feature_dict).reset_index()\n",
    "        \n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        \n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_400 = get_stats_window(seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(seconds_in_bucket = 200, add_suffix = True)\n",
    "    \n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__400', 'time_id__300', 'time_id__200'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    # Create row_id so we can merge\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n",
    "    df_feature.drop(['time_id_'], axis = 1, inplace = True)\n",
    "    \n",
    "    return df_feature\n",
    "\n",
    "\n",
    "def trade_preprocessor(file_path):\n",
    "    # Function to preprocess trade data (for each stock id)\n",
    "    \n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum, realized_volatility, np.mean, np.std, np.max, np.min],\n",
    "        'order_count':[np.mean,np.sum,np.max],\n",
    "    }\n",
    "    \n",
    "    def get_stats_window(seconds_in_bucket, add_suffix = False):\n",
    "        # Function to get group stats for different windows (seconds in bucket)\n",
    "        \n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(create_feature_dict).reset_index()\n",
    "        \n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        \n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_400 = get_stats_window(seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(seconds_in_bucket = 200, add_suffix = True)\n",
    "    \n",
    "    def tendency(price, vol):    \n",
    "        df_diff = np.diff(price)\n",
    "        val = (df_diff/price[1:])*100\n",
    "        power = np.sum(val*vol[1:])\n",
    "        return(power)\n",
    "    \n",
    "    lis = []\n",
    "    for n_time_id in df['time_id'].unique():\n",
    "        df_id = df[df['time_id'] == n_time_id]        \n",
    "        tendencyV = tendency(df_id['price'].values, df_id['size'].values)      \n",
    "        f_max = np.sum(df_id['price'].values > np.mean(df_id['price'].values))\n",
    "        f_min = np.sum(df_id['price'].values < np.mean(df_id['price'].values))\n",
    "        df_max =  np.sum(np.diff(df_id['price'].values) > 0)\n",
    "        df_min =  np.sum(np.diff(df_id['price'].values) < 0)\n",
    "        abs_diff = np.median(np.abs( df_id['price'].values - np.mean(df_id['price'].values)))        \n",
    "        energy = np.mean(df_id['price'].values**2)\n",
    "        iqr_p = np.percentile(df_id['price'].values,75) - np.percentile(df_id['price'].values,25)\n",
    "        abs_diff_v = np.median(np.abs( df_id['size'].values - np.mean(df_id['size'].values)))        \n",
    "        energy_v = np.sum(df_id['size'].values**2)\n",
    "        iqr_p_v = np.percentile(df_id['size'].values,75) - np.percentile(df_id['size'].values,25)\n",
    "        \n",
    "        lis.append({'time_id':n_time_id,'tendency':tendencyV,'f_max':f_max,'f_min':f_min,'df_max':df_max,'df_min':df_min,\n",
    "                   'abs_diff':abs_diff,'energy':energy,'iqr_p':iqr_p,'abs_diff_v':abs_diff_v,'energy_v':energy_v,'iqr_p_v':iqr_p_v})\n",
    "    \n",
    "    df_lr = pd.DataFrame(lis)\n",
    "        \n",
    "   \n",
    "    df_feature = df_feature.merge(df_lr, how = 'left', left_on = 'time_id_', right_on = 'time_id')\n",
    "    \n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__400', 'time_id__300', 'time_id__200','time_id'], axis = 1, inplace = True)\n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature.drop(['trade_time_id_'], axis = 1, inplace = True)\n",
    "    \n",
    "    def order_sum(df, sec:str):\n",
    "        new_col = 'size_tau' + sec\n",
    "        bucket_col = 'trade_seconds_in_bucket_count_unique' + sec\n",
    "        df[new_col] = np.sqrt(1/df[bucket_col])\n",
    "        \n",
    "        new_col2 = 'size_tau2' + sec\n",
    "        order_col = 'trade_order_count_sum' + sec\n",
    "        df[new_col2] = np.sqrt(1/df[order_col])\n",
    "        \n",
    "        if sec == '400_':\n",
    "            df['size_tau2_d'] = df['size_tau2_400'] - df['size_tau2']\n",
    "        \n",
    "\n",
    "    \n",
    "    for sec in ['','_200','_300','_400']:\n",
    "        order_sum(df_feature, sec)\n",
    "        \n",
    "    df_feature['size_tau2_d'] = df_feature['size_tau2_400'] - df_feature['size_tau2']\n",
    "    \n",
    "    return df_feature\n",
    "\n",
    "\n",
    "def get_time_stock(df):\n",
    "    # Function to get group stats for the stock_id and time_id\n",
    "    \n",
    "    # Get realized volatility columns\n",
    "    vol_cols = ['log_return1_realized_volatility', 'log_return2_realized_volatility', 'log_return1_realized_volatility_400', 'log_return2_realized_volatility_400', \n",
    "                'log_return1_realized_volatility_300', 'log_return2_realized_volatility_300', 'log_return1_realized_volatility_200', 'log_return2_realized_volatility_200', \n",
    "                'trade_log_return_realized_volatility', 'trade_log_return_realized_volatility_400', 'trade_log_return_realized_volatility_300', 'trade_log_return_realized_volatility_200']\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    \n",
    "    # Rename columns joining suffix\n",
    "    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n",
    "    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    \n",
    "    # Rename columns joining suffix\n",
    "    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n",
    "    df_time_id = df_time_id.add_suffix('_' + 'time')\n",
    "    \n",
    "    # Merge with original dataframe\n",
    "    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n",
    "    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n",
    "    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_agg_features(train, test):\n",
    "\n",
    "    # Making agg features\n",
    "\n",
    "    train_p = pd.read_csv(f'{data_dir}/train.csv')\n",
    "    train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "    corr = train_p.corr()\n",
    "    ids = corr.index\n",
    "    kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "    l = []\n",
    "    for n in range(7):\n",
    "        l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "\n",
    "    mat = []\n",
    "    matTest = []\n",
    "    n = 0\n",
    "    for ind in l:\n",
    "        newDf = train.loc[train['stock_id'].isin(ind) ]\n",
    "        newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "        newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "        mat.append ( newDf )\n",
    "        newDf = test.loc[test['stock_id'].isin(ind) ]    \n",
    "        newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "        newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "        matTest.append ( newDf )\n",
    "        n+=1\n",
    "\n",
    "    mat1 = pd.concat(mat).reset_index()\n",
    "    mat1.drop(columns=['target'],inplace=True)\n",
    "    mat2 = pd.concat(matTest).reset_index()\n",
    "    \n",
    "    mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])\n",
    "    \n",
    "    mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "    mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "    mat1.reset_index(inplace=True)\n",
    "    \n",
    "    mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "    mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "    mat2.reset_index(inplace=True)\n",
    "    \n",
    "    prefix = ['log_return1_realized_volatility', 'total_volume_mean', 'trade_size_mean', 'trade_order_count_mean','price_spread_mean','bid_spread_mean','ask_spread_mean',\n",
    "              'volume_imbalance_mean', 'bid_ask_spread_mean','size_tau2']\n",
    "    selected_cols=mat1.filter(regex='|'.join(f'^{x}.(0|1|3|4|6)c1' for x in prefix)).columns.tolist()\n",
    "    selected_cols.append('time_id')\n",
    "    \n",
    "    train_m = pd.merge(train,mat1[selected_cols],how='left',on='time_id')\n",
    "    test_m = pd.merge(test,mat2[selected_cols],how='left',on='time_id')\n",
    "    \n",
    "    # filling missing values with train means\n",
    "\n",
    "    features = [col for col in train_m.columns.tolist() if col not in ['time_id','target','row_id']]\n",
    "    train_m[features] = train_m[features].fillna(train_m[features].mean())\n",
    "    test_m[features] = test_m[features].fillna(train_m[features].mean())\n",
    "\n",
    "    return train_m, test_m\n",
    "    \n",
    "    \n",
    "def preprocessor(list_stock_ids, is_train = True):\n",
    "    # Funtion to make preprocessing function in parallel (for each stock id)\n",
    "    \n",
    "    # Parrallel for loop\n",
    "    def for_joblib(stock_id):\n",
    "        # Train\n",
    "        if is_train:\n",
    "            file_path_book = data_dir + \"/book_train.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"/trade_train.parquet/stock_id=\" + str(stock_id)\n",
    "        # Test\n",
    "        else:\n",
    "            file_path_book = data_dir + \"/book_test.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"/trade_test.parquet/stock_id=\" + str(stock_id)\n",
    "    \n",
    "        # Preprocess book and trade data and merge them\n",
    "        df_tmp = pd.merge(book_preprocessor(file_path_book), trade_preprocessor(file_path_trade), on = 'row_id', how = 'left')\n",
    "        \n",
    "        # Return the merge dataframe\n",
    "        return df_tmp\n",
    "    \n",
    "    # Use parallel api to call paralle for loop\n",
    "    df = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(stock_id) for stock_id in list_stock_ids)\n",
    "    \n",
    "    # Concatenate all the dataframes that return from Parallel\n",
    "    df = pd.concat(df, ignore_index = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    # Function to calculate the root mean squared percentage error\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "class RMSPE(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"rmspe\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "\n",
    "        return np.sqrt(np.mean(np.square((y_true - y_score) / y_true)))\n",
    "\n",
    "\n",
    "def RMSPELoss(y_pred, y_true):\n",
    "    return torch.sqrt(torch.mean( ((y_true - y_pred) / y_true) ** 2 )).clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e945bfbb",
   "metadata": {
    "papermill": {
     "duration": 0.020714,
     "end_time": "2021-08-28T05:33:27.224282",
     "exception": false,
     "start_time": "2021-08-28T05:33:27.203568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loding the and doing some feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fd81cce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T05:33:27.274200Z",
     "iopub.status.busy": "2021-08-28T05:33:27.273431Z",
     "iopub.status.idle": "2021-08-28T06:22:23.981260Z",
     "shell.execute_reply": "2021-08-28T06:22:23.980737Z",
     "shell.execute_reply.started": "2021-08-27T19:56:23.301366Z"
    },
    "papermill": {
     "duration": 2936.736105,
     "end_time": "2021-08-28T06:22:23.981399",
     "exception": false,
     "start_time": "2021-08-28T05:33:27.245294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed:  3.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Get unique stock ids \n",
    "train_stock_ids = train['stock_id'].unique()\n",
    "\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "train_ = preprocessor(train_stock_ids, is_train = True)\n",
    "train = train.merge(train_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get unique stock ids \n",
    "test_stock_ids = test['stock_id'].unique()\n",
    "\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "test_ = preprocessor(test_stock_ids, is_train = False)\n",
    "test = test.merge(test_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get group stats of time_id and stock_id\n",
    "train = get_time_stock(train)\n",
    "test = get_time_stock(test)\n",
    "\n",
    "# Fill inf values\n",
    "train.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "test.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "\n",
    "# Aggregating some features\n",
    "train, test = create_agg_features(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef8361f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>row_id</th>\n",
       "      <th>wap1_sum</th>\n",
       "      <th>wap1_mean</th>\n",
       "      <th>wap1_std</th>\n",
       "      <th>wap2_sum</th>\n",
       "      <th>wap2_mean</th>\n",
       "      <th>wap2_std</th>\n",
       "      <th>...</th>\n",
       "      <th>trade_order_count_mean_0c1</th>\n",
       "      <th>trade_order_count_mean_1c1</th>\n",
       "      <th>trade_order_count_mean_3c1</th>\n",
       "      <th>trade_order_count_mean_4c1</th>\n",
       "      <th>trade_order_count_mean_6c1</th>\n",
       "      <th>size_tau2_0c1</th>\n",
       "      <th>size_tau2_1c1</th>\n",
       "      <th>size_tau2_3c1</th>\n",
       "      <th>size_tau2_4c1</th>\n",
       "      <th>size_tau2_6c1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0-5</td>\n",
       "      <td>303.125061</td>\n",
       "      <td>1.003725</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>303.105530</td>\n",
       "      <td>1.003661</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>...</td>\n",
       "      <td>3.809776</td>\n",
       "      <td>3.838125</td>\n",
       "      <td>4.213097</td>\n",
       "      <td>3.737627</td>\n",
       "      <td>4.477624</td>\n",
       "      <td>0.058550</td>\n",
       "      <td>0.057267</td>\n",
       "      <td>0.078471</td>\n",
       "      <td>0.054691</td>\n",
       "      <td>0.050700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0-11</td>\n",
       "      <td>200.047775</td>\n",
       "      <td>1.000239</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>200.041168</td>\n",
       "      <td>1.000206</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>...</td>\n",
       "      <td>3.536027</td>\n",
       "      <td>3.827231</td>\n",
       "      <td>4.151908</td>\n",
       "      <td>4.292891</td>\n",
       "      <td>5.890478</td>\n",
       "      <td>0.081235</td>\n",
       "      <td>0.078955</td>\n",
       "      <td>0.122289</td>\n",
       "      <td>0.078616</td>\n",
       "      <td>0.045740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0-16</td>\n",
       "      <td>187.913849</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>187.939819</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>...</td>\n",
       "      <td>2.934143</td>\n",
       "      <td>2.865731</td>\n",
       "      <td>3.599012</td>\n",
       "      <td>3.359532</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>0.078550</td>\n",
       "      <td>0.087378</td>\n",
       "      <td>0.116278</td>\n",
       "      <td>0.074977</td>\n",
       "      <td>0.080722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0-31</td>\n",
       "      <td>119.859779</td>\n",
       "      <td>0.998832</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>119.835945</td>\n",
       "      <td>0.998633</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>...</td>\n",
       "      <td>3.266455</td>\n",
       "      <td>3.702063</td>\n",
       "      <td>3.768233</td>\n",
       "      <td>3.502680</td>\n",
       "      <td>4.665943</td>\n",
       "      <td>0.100382</td>\n",
       "      <td>0.089673</td>\n",
       "      <td>0.105948</td>\n",
       "      <td>0.094684</td>\n",
       "      <td>0.055447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0-62</td>\n",
       "      <td>175.932861</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>175.934250</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>...</td>\n",
       "      <td>3.367228</td>\n",
       "      <td>3.730579</td>\n",
       "      <td>4.435158</td>\n",
       "      <td>3.860256</td>\n",
       "      <td>4.257065</td>\n",
       "      <td>0.087285</td>\n",
       "      <td>0.089068</td>\n",
       "      <td>0.112663</td>\n",
       "      <td>0.086381</td>\n",
       "      <td>0.046358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126</td>\n",
       "      <td>32751</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>126-32751</td>\n",
       "      <td>309.870453</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>309.871368</td>\n",
       "      <td>0.999585</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>...</td>\n",
       "      <td>3.685610</td>\n",
       "      <td>4.051199</td>\n",
       "      <td>4.464154</td>\n",
       "      <td>3.978511</td>\n",
       "      <td>5.506404</td>\n",
       "      <td>0.064380</td>\n",
       "      <td>0.064007</td>\n",
       "      <td>0.089665</td>\n",
       "      <td>0.061596</td>\n",
       "      <td>0.041157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126</td>\n",
       "      <td>32753</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>126-32753</td>\n",
       "      <td>223.552139</td>\n",
       "      <td>1.002476</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>223.580322</td>\n",
       "      <td>1.002602</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>...</td>\n",
       "      <td>4.169403</td>\n",
       "      <td>4.519246</td>\n",
       "      <td>5.345999</td>\n",
       "      <td>5.369023</td>\n",
       "      <td>4.483678</td>\n",
       "      <td>0.073644</td>\n",
       "      <td>0.065909</td>\n",
       "      <td>0.085298</td>\n",
       "      <td>0.062453</td>\n",
       "      <td>0.062479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126</td>\n",
       "      <td>32758</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>126-32758</td>\n",
       "      <td>256.277039</td>\n",
       "      <td>1.001082</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>256.255066</td>\n",
       "      <td>1.000996</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>...</td>\n",
       "      <td>3.131133</td>\n",
       "      <td>3.431899</td>\n",
       "      <td>3.444819</td>\n",
       "      <td>3.262376</td>\n",
       "      <td>2.590000</td>\n",
       "      <td>0.098654</td>\n",
       "      <td>0.092117</td>\n",
       "      <td>0.124247</td>\n",
       "      <td>0.090574</td>\n",
       "      <td>0.120507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126</td>\n",
       "      <td>32763</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>126-32763</td>\n",
       "      <td>399.721741</td>\n",
       "      <td>1.001809</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>399.714325</td>\n",
       "      <td>1.001790</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>...</td>\n",
       "      <td>3.511471</td>\n",
       "      <td>3.562323</td>\n",
       "      <td>4.019130</td>\n",
       "      <td>4.069066</td>\n",
       "      <td>4.440582</td>\n",
       "      <td>0.051648</td>\n",
       "      <td>0.054263</td>\n",
       "      <td>0.067649</td>\n",
       "      <td>0.051358</td>\n",
       "      <td>0.040747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126</td>\n",
       "      <td>32767</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>126-32767</td>\n",
       "      <td>217.058914</td>\n",
       "      <td>1.000272</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>217.079727</td>\n",
       "      <td>1.000367</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>...</td>\n",
       "      <td>2.758541</td>\n",
       "      <td>3.168344</td>\n",
       "      <td>3.487645</td>\n",
       "      <td>3.852589</td>\n",
       "      <td>3.107042</td>\n",
       "      <td>0.077370</td>\n",
       "      <td>0.078584</td>\n",
       "      <td>0.108765</td>\n",
       "      <td>0.079125</td>\n",
       "      <td>0.053870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_id  time_id    target     row_id    wap1_sum  wap1_mean  \\\n",
       "0              0        5  0.004136        0-5  303.125061   1.003725   \n",
       "1              0       11  0.001445       0-11  200.047775   1.000239   \n",
       "2              0       16  0.002168       0-16  187.913849   0.999542   \n",
       "3              0       31  0.002195       0-31  119.859779   0.998832   \n",
       "4              0       62  0.001747       0-62  175.932861   0.999619   \n",
       "...          ...      ...       ...        ...         ...        ...   \n",
       "428927       126    32751  0.003461  126-32751  309.870453   0.999582   \n",
       "428928       126    32753  0.003113  126-32753  223.552139   1.002476   \n",
       "428929       126    32758  0.004070  126-32758  256.277039   1.001082   \n",
       "428930       126    32763  0.003357  126-32763  399.721741   1.001809   \n",
       "428931       126    32767  0.002090  126-32767  217.058914   1.000272   \n",
       "\n",
       "        wap1_std    wap2_sum  wap2_mean  wap2_std  ...  \\\n",
       "0       0.000693  303.105530   1.003661  0.000781  ...   \n",
       "1       0.000262  200.041168   1.000206  0.000272  ...   \n",
       "2       0.000864  187.939819   0.999680  0.000862  ...   \n",
       "3       0.000757  119.835945   0.998633  0.000656  ...   \n",
       "4       0.000258  175.934250   0.999626  0.000317  ...   \n",
       "...          ...         ...        ...       ...  ...   \n",
       "428927  0.000486  309.871368   0.999585  0.000613  ...   \n",
       "428928  0.001264  223.580322   1.002602  0.001303  ...   \n",
       "428929  0.000466  256.255066   1.000996  0.000599  ...   \n",
       "428930  0.000456  399.714325   1.001790  0.000507  ...   \n",
       "428931  0.000384  217.079727   1.000367  0.000465  ...   \n",
       "\n",
       "        trade_order_count_mean_0c1  trade_order_count_mean_1c1  \\\n",
       "0                         3.809776                    3.838125   \n",
       "1                         3.536027                    3.827231   \n",
       "2                         2.934143                    2.865731   \n",
       "3                         3.266455                    3.702063   \n",
       "4                         3.367228                    3.730579   \n",
       "...                            ...                         ...   \n",
       "428927                    3.685610                    4.051199   \n",
       "428928                    4.169403                    4.519246   \n",
       "428929                    3.131133                    3.431899   \n",
       "428930                    3.511471                    3.562323   \n",
       "428931                    2.758541                    3.168344   \n",
       "\n",
       "        trade_order_count_mean_3c1  trade_order_count_mean_4c1  \\\n",
       "0                         4.213097                    3.737627   \n",
       "1                         4.151908                    4.292891   \n",
       "2                         3.599012                    3.359532   \n",
       "3                         3.768233                    3.502680   \n",
       "4                         4.435158                    3.860256   \n",
       "...                            ...                         ...   \n",
       "428927                    4.464154                    3.978511   \n",
       "428928                    5.345999                    5.369023   \n",
       "428929                    3.444819                    3.262376   \n",
       "428930                    4.019130                    4.069066   \n",
       "428931                    3.487645                    3.852589   \n",
       "\n",
       "        trade_order_count_mean_6c1  size_tau2_0c1  size_tau2_1c1  \\\n",
       "0                         4.477624       0.058550       0.057267   \n",
       "1                         5.890478       0.081235       0.078955   \n",
       "2                         2.350000       0.078550       0.087378   \n",
       "3                         4.665943       0.100382       0.089673   \n",
       "4                         4.257065       0.087285       0.089068   \n",
       "...                            ...            ...            ...   \n",
       "428927                    5.506404       0.064380       0.064007   \n",
       "428928                    4.483678       0.073644       0.065909   \n",
       "428929                    2.590000       0.098654       0.092117   \n",
       "428930                    4.440582       0.051648       0.054263   \n",
       "428931                    3.107042       0.077370       0.078584   \n",
       "\n",
       "        size_tau2_3c1  size_tau2_4c1  size_tau2_6c1  \n",
       "0            0.078471       0.054691       0.050700  \n",
       "1            0.122289       0.078616       0.045740  \n",
       "2            0.116278       0.074977       0.080722  \n",
       "3            0.105948       0.094684       0.055447  \n",
       "4            0.112663       0.086381       0.046358  \n",
       "...               ...            ...            ...  \n",
       "428927       0.089665       0.061596       0.041157  \n",
       "428928       0.085298       0.062453       0.062479  \n",
       "428929       0.124247       0.090574       0.120507  \n",
       "428930       0.067649       0.051358       0.040747  \n",
       "428931       0.108765       0.079125       0.053870  \n",
       "\n",
       "[428932 rows x 366 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d37f9cf",
   "metadata": {
    "papermill": {
     "duration": 0.021954,
     "end_time": "2021-08-28T06:22:24.026367",
     "exception": false,
     "start_time": "2021-08-28T06:22:24.004413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training\n",
    "\n",
    "First we selecting columns for the training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a280507f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T06:22:24.338526Z",
     "iopub.status.busy": "2021-08-28T06:22:24.336901Z",
     "iopub.status.idle": "2021-08-28T06:22:24.339232Z",
     "shell.execute_reply": "2021-08-28T06:22:24.339624Z",
     "shell.execute_reply.started": "2021-08-27T20:25:10.491822Z"
    },
    "papermill": {
     "duration": 0.291046,
     "end_time": "2021-08-28T06:22:24.339785",
     "exception": false,
     "start_time": "2021-08-28T06:22:24.048739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train.drop(['row_id', 'target', 'time_id'], axis = 1)\n",
    "y = train['target']\n",
    "X_test=test.copy()\n",
    "X_test.drop(['time_id','row_id'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e20b3ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T06:22:24.537087Z",
     "iopub.status.busy": "2021-08-28T06:22:24.536459Z",
     "iopub.status.idle": "2021-08-28T06:22:33.815876Z",
     "shell.execute_reply": "2021-08-28T06:22:33.815382Z",
     "shell.execute_reply.started": "2021-08-27T20:25:52.337263Z"
    },
    "papermill": {
     "duration": 9.309102,
     "end_time": "2021-08-28T06:22:33.816021",
     "exception": false,
     "start_time": "2021-08-28T06:22:24.506919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nunique = X.nunique()\n",
    "types = X.dtypes\n",
    "\n",
    "categorical_columns = []\n",
    "categorical_dims =  {}\n",
    "\n",
    "for col in X.columns:\n",
    "    if  col == 'stock_id':\n",
    "        l_enc = LabelEncoder()\n",
    "        X[col] = l_enc.fit_transform(X[col].values)\n",
    "        X_test[col] = l_enc.transform(X_test[col].values)\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(l_enc.classes_)\n",
    "    else:\n",
    "        scaler = StandardScaler()\n",
    "        X[col] = scaler.fit_transform(X[col].values.reshape(-1, 1))\n",
    "        X_test[col] = scaler.transform(X_test[col].values.reshape(-1, 1))\n",
    "        \n",
    "\n",
    "\n",
    "cat_idxs = [ i for i, f in enumerate(X.columns.tolist()) if f in categorical_columns]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(X.columns.tolist()) if f in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "870911a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f6fd4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[112]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0306a5e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn import model_selection\n",
    "\n",
    "# ---- GroupKFold ----\n",
    "class GroupKFold(object):\n",
    "    \"\"\"\n",
    "    GroupKFold with random shuffle with a sklearn-like structure\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=4, shuffle=True, random_state=42):\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, group=None):\n",
    "        return self.n_splits\n",
    "\n",
    "    def split(self, X, y, group):\n",
    "        kf = model_selection.KFold(n_splits=self.n_splits, shuffle=self.shuffle, random_state=self.random_state)\n",
    "        unique_ids = X[group].unique()\n",
    "        for fold, (tr_group_idx, va_group_idx) in enumerate(kf.split(unique_ids)):\n",
    "            # split group\n",
    "            tr_group, va_group = unique_ids[tr_group_idx], unique_ids[va_group_idx]\n",
    "            train_idx = np.where(X[group].isin(tr_group))[0]\n",
    "            val_idx = np.where(X[group].isin(va_group))[0]\n",
    "            yield train_idx, val_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95caffb8",
   "metadata": {
    "papermill": {
     "duration": 0.022213,
     "end_time": "2021-08-28T06:22:33.861196",
     "exception": false,
     "start_time": "2021-08-28T06:22:33.838983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### TabNet train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461bb7c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T06:22:33.911684Z",
     "iopub.status.busy": "2021-08-28T06:22:33.911134Z",
     "iopub.status.idle": "2021-08-28T06:22:33.915097Z",
     "shell.execute_reply": "2021-08-28T06:22:33.914634Z",
     "shell.execute_reply.started": "2021-08-27T20:26:02.886403Z"
    },
    "papermill": {
     "duration": 0.03172,
     "end_time": "2021-08-28T06:22:33.915219",
     "exception": false,
     "start_time": "2021-08-28T06:22:33.883499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    start_time = time.time()\n",
    "    global suff\n",
    "    class CFG:\n",
    "        suffix = str(suff)\n",
    "    suff += 1\n",
    "    cv = GroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    kf = cv.split(train, train['target'], 'time_id')\n",
    "    # kfold = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros((X.shape[0], 1))\n",
    "    # test_predictions = np.zeros(X_test.shape[0])\n",
    "    feature_importances = pd.DataFrame()\n",
    "    feature_importances[\"feature\"] = X.columns.tolist()\n",
    "    explain_matrices = []\n",
    "\n",
    "    tabnet_params = dict(\n",
    "        cat_idxs=cat_idxs,\n",
    "        cat_dims=cat_dims,\n",
    "        cat_emb_dim=1,\n",
    "        n_d = trial.suggest_int(\"n_d\", 14, 18),\n",
    "        n_a = trial.suggest_int(\"n_a\", 14, 18),\n",
    "        n_steps = trial.suggest_int(\"n_steps\", 1, 3), #2\n",
    "        gamma = trial.suggest_uniform(\"gamma\", 1.8, 2.0),\n",
    "        n_independent = trial.suggest_int(\"n_independent\", 1, 3), # 2\n",
    "        n_shared = trial.suggest_int(\"n_shared\", 1, 3), #2\n",
    "        lambda_sparse = trial.suggest_categorical(\"lambda_sparse\",  [0.0, 1e-3]), #0\n",
    "        optimizer_fn = Adam,\n",
    "        optimizer_params = dict(lr = (trial.suggest_loguniform(\"learning_rate\", 1e-2, 3e-2))),# dict(lr = (2e-2)), # dict(lr = (trial.suggest_loguniform(\"learning_rate\", 7e-3, 5e-2))),\n",
    "        mask_type = \"entmax\",\n",
    "        scheduler_params = dict(T_0=200, T_mult=1, eta_min=1e-4, last_epoch=-1, verbose=False),\n",
    "        scheduler_fn = CosineAnnealingWarmRestarts,\n",
    "        seed = 42,\n",
    "        verbose = 50,\n",
    "    )\n",
    "\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kf):\n",
    "    # for fold, (trn_ind, val_ind) in enumerate(kfold.split(X)):\n",
    "        print(f'Training fold {fold}')\n",
    "        X_train, X_val = X.iloc[trn_ind].values, X.iloc[val_ind].values\n",
    "        y_train, y_val = y.iloc[trn_ind].values.reshape(-1,1), y.iloc[val_ind].values.reshape(-1,1)\n",
    "\n",
    "\n",
    "        clf =  TabNetRegressor(**tabnet_params)\n",
    "        clf.fit(\n",
    "          X_train, y_train,\n",
    "          eval_set=[(X_val, y_val)],\n",
    "          max_epochs = 200,\n",
    "          patience = 50,\n",
    "          batch_size = 1024*16,\n",
    "          virtual_batch_size = 128*16,\n",
    "          num_workers = 10,\n",
    "          drop_last = False,\n",
    "          eval_metric=[RMSPE],\n",
    "          loss_fn=RMSPELoss\n",
    "          )\n",
    "\n",
    "        clf.save_model(f\"{output_dir}/tabnet_{CFG.suffix}_fold{fold}.model\")\n",
    "        oof_predictions[val_ind] = clf.predict(X_val)\n",
    "        feature_importances[f\"importance_fold{fold}+1\"] = clf.feature_importances_\n",
    "        feature_importances.to_csv(f\"{output_dir}/tabnet_feature_imp_{CFG.suffix}_fold{fold}.csv\",index=False)\n",
    "\n",
    "\n",
    "    elapsed_time = get_timediff(start_time, time.time())\n",
    "    rmspe_score = rmspe(y, oof_predictions.flatten())\n",
    "    print(f'OOF score across folds: {rmspe_score}')\n",
    "    LOGGER.info(f' suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time')\n",
    "    LOGGER.info(f' {CFG.suffix}   {rmspe_score:.7f}      {tabnet_params[\"cat_emb_dim\"]:>3d}      {tabnet_params[\"n_d\"]:>3d}  {tabnet_params[\"n_a\"]:>3d}     {tabnet_params[\"n_steps\"]:>2d}     {tabnet_params[\"gamma\"]:.2f}        {tabnet_params[\"n_independent\"]:>2d}           {tabnet_params[\"n_shared\"]:>2d}          {tabnet_params[\"lambda_sparse\"]:.2f}          {tabnet_params[\"optimizer_params\"][\"lr\"]:.8f}      {tabnet_params[\"mask_type\"]}  {tabnet_params[\"scheduler_params\"][\"T_0\"]:>4d}    {tabnet_params[\"scheduler_params\"][\"T_mult\"]:>2d}   {tabnet_params[\"scheduler_params\"][\"eta_min\"]:.8f}  {elapsed_time} ')\n",
    "    return rmspe_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4235807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T09:02:30.782879Z",
     "iopub.status.busy": "2021-08-28T09:02:30.782134Z",
     "iopub.status.idle": "2021-08-28T09:02:30.787866Z",
     "shell.execute_reply": "2021-08-28T09:02:30.787433Z"
    },
    "papermill": {
     "duration": 0.079733,
     "end_time": "2021-08-28T09:02:30.787988",
     "exception": false,
     "start_time": "2021-08-28T09:02:30.708255",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-17 18:49:06,042]\u001b[0m A new study created in memory with name: no-name-cb0949eb-4997-43f4-a4ad-6e728e8c893e\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 35.77371| val_0_rmspe: 3.26264 |  0:00:02s\n",
      "epoch 50 | loss: 0.22953 | val_0_rmspe: 0.22243 |  0:01:49s\n",
      "epoch 100| loss: 0.20859 | val_0_rmspe: 0.2149  |  0:03:36s\n",
      "epoch 150| loss: 0.20146 | val_0_rmspe: 0.21573 |  0:05:24s\n",
      "\n",
      "Early stopping occurred at epoch 158 with best_epoch = 108 and best_val_0_rmspe = 0.21283\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917000_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 47.63717| val_0_rmspe: 4.38736 |  0:00:02s\n",
      "epoch 50 | loss: 0.21934 | val_0_rmspe: 0.22739 |  0:01:50s\n",
      "epoch 100| loss: 0.20921 | val_0_rmspe: 0.21544 |  0:03:38s\n",
      "\n",
      "Early stopping occurred at epoch 140 with best_epoch = 90 and best_val_0_rmspe = 0.21402\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917000_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 28.38775| val_0_rmspe: 5.06596 |  0:00:02s\n",
      "epoch 50 | loss: 0.21873 | val_0_rmspe: 0.22913 |  0:01:49s\n",
      "epoch 100| loss: 0.20962 | val_0_rmspe: 0.21819 |  0:03:36s\n",
      "\n",
      "Early stopping occurred at epoch 137 with best_epoch = 87 and best_val_0_rmspe = 0.21615\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917000_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 35.37135| val_0_rmspe: 3.05632 |  0:00:02s\n",
      "epoch 50 | loss: 0.21955 | val_0_rmspe: 0.22105 |  0:01:49s\n",
      "epoch 100| loss: 0.21254 | val_0_rmspe: 0.21449 |  0:03:37s\n",
      "epoch 150| loss: 0.2063  | val_0_rmspe: 0.21051 |  0:05:24s\n",
      "\n",
      "Early stopping occurred at epoch 175 with best_epoch = 125 and best_val_0_rmspe = 0.21032\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917000_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 24.90579| val_0_rmspe: 3.89623 |  0:00:02s\n",
      "epoch 50 | loss: 0.22141 | val_0_rmspe: 0.21746 |  0:01:48s\n",
      "epoch 100| loss: 0.20808 | val_0_rmspe: 0.22603 |  0:03:36s\n",
      "\n",
      "Early stopping occurred at epoch 130 with best_epoch = 80 and best_val_0_rmspe = 0.21432\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917000_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917000   0.2135363        1       14   15      1     1.86         1            3          0.00          0.02770695      entmax   200     1   0.00010000  26:56 \n",
      "\u001b[32m[I 2021-09-17 19:16:02,124]\u001b[0m Trial 0 finished with value: 0.21353625583126887 and parameters: {'n_d': 14, 'n_a': 15, 'n_steps': 1, 'gamma': 1.855270815491862, 'n_independent': 1, 'n_shared': 3, 'lambda_sparse': 0.001, 'learning_rate': 0.02770695027554611}. Best is trial 0 with value: 0.21353625583126887.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.21353625583126887\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 273.74466| val_0_rmspe: 69.66301|  0:00:02s\n",
      "epoch 50 | loss: 0.23167 | val_0_rmspe: 0.2274  |  0:02:07s\n",
      "epoch 100| loss: 0.21246 | val_0_rmspe: 0.21732 |  0:04:12s\n",
      "epoch 150| loss: 0.20536 | val_0_rmspe: 0.21182 |  0:06:17s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 150 and best_val_0_rmspe = 0.21182\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917001_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 332.07167| val_0_rmspe: 152.8688|  0:00:02s\n",
      "epoch 50 | loss: 0.24979 | val_0_rmspe: 0.24021 |  0:02:08s\n",
      "epoch 100| loss: 0.21672 | val_0_rmspe: 0.22238 |  0:04:13s\n",
      "epoch 150| loss: 0.20781 | val_0_rmspe: 0.23357 |  0:06:17s\n",
      "\n",
      "Early stopping occurred at epoch 161 with best_epoch = 111 and best_val_0_rmspe = 0.21861\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917001_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 266.09339| val_0_rmspe: 94.05831|  0:00:02s\n",
      "epoch 50 | loss: 0.23898 | val_0_rmspe: 0.23832 |  0:02:07s\n",
      "epoch 100| loss: 0.2169  | val_0_rmspe: 0.22242 |  0:04:12s\n",
      "epoch 150| loss: 0.20911 | val_0_rmspe: 0.21685 |  0:06:16s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 185 and best_val_0_rmspe = 0.2156\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917001_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 347.19677| val_0_rmspe: 162.14792|  0:00:02s\n",
      "epoch 50 | loss: 0.24303 | val_0_rmspe: 0.24632 |  0:02:06s\n",
      "epoch 100| loss: 0.21662 | val_0_rmspe: 0.22162 |  0:04:11s\n",
      "epoch 150| loss: 0.21075 | val_0_rmspe: 0.2114  |  0:06:16s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 158 and best_val_0_rmspe = 0.21077\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917001_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 358.02552| val_0_rmspe: 194.4407|  0:00:02s\n",
      "epoch 50 | loss: 0.23762 | val_0_rmspe: 0.24765 |  0:02:07s\n",
      "epoch 100| loss: 0.21927 | val_0_rmspe: 0.2165  |  0:04:10s\n",
      "epoch 150| loss: 0.20732 | val_0_rmspe: 0.21485 |  0:06:14s\n",
      "\n",
      "Early stopping occurred at epoch 183 with best_epoch = 133 and best_val_0_rmspe = 0.21231\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917001_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917001   0.2138404        1       17   17      2     1.85         2            3          0.00          0.01767668      entmax   200     1   0.00010000  39:29 \n",
      "\u001b[32m[I 2021-09-17 19:55:31,888]\u001b[0m Trial 1 finished with value: 0.2138404018966662 and parameters: {'n_d': 17, 'n_a': 17, 'n_steps': 2, 'gamma': 1.8548744443818146, 'n_independent': 2, 'n_shared': 3, 'lambda_sparse': 0.0, 'learning_rate': 0.017676675348710213}. Best is trial 0 with value: 0.21353625583126887.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.2138404018966662\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 252.97805| val_0_rmspe: 166.98995|  0:00:02s\n",
      "epoch 50 | loss: 0.2364  | val_0_rmspe: 0.22887 |  0:02:11s\n",
      "epoch 100| loss: 0.20789 | val_0_rmspe: 0.21328 |  0:04:20s\n",
      "epoch 150| loss: 0.20177 | val_0_rmspe: 0.21227 |  0:06:28s\n",
      "\n",
      "Early stopping occurred at epoch 154 with best_epoch = 104 and best_val_0_rmspe = 0.21164\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917002_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 274.30318| val_0_rmspe: 56.43198|  0:00:02s\n",
      "epoch 50 | loss: 0.22169 | val_0_rmspe: 0.22426 |  0:02:13s\n",
      "epoch 100| loss: 0.20823 | val_0_rmspe: 0.21567 |  0:04:21s\n",
      "epoch 150| loss: 0.20392 | val_0_rmspe: 0.21556 |  0:06:31s\n",
      "\n",
      "Early stopping occurred at epoch 162 with best_epoch = 112 and best_val_0_rmspe = 0.21475\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917002_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 253.26336| val_0_rmspe: 52.28658|  0:00:02s\n",
      "epoch 50 | loss: 0.23177 | val_0_rmspe: 0.26632 |  0:02:11s\n",
      "epoch 100| loss: 0.21922 | val_0_rmspe: 0.22683 |  0:04:19s\n",
      "epoch 150| loss: 0.20974 | val_0_rmspe: 0.2176  |  0:06:28s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 174 and best_val_0_rmspe = 0.21663\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917002_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 260.11105| val_0_rmspe: 17.95858|  0:00:02s\n",
      "epoch 50 | loss: 0.2491  | val_0_rmspe: 0.23715 |  0:02:12s\n",
      "epoch 100| loss: 0.21475 | val_0_rmspe: 0.22542 |  0:04:22s\n",
      "epoch 150| loss: 0.20472 | val_0_rmspe: 0.21569 |  0:06:31s\n",
      "\n",
      "Early stopping occurred at epoch 164 with best_epoch = 114 and best_val_0_rmspe = 0.2112\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917002_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 229.72314| val_0_rmspe: 28.97636|  0:00:02s\n",
      "epoch 50 | loss: 0.23642 | val_0_rmspe: 0.23548 |  0:02:11s\n",
      "epoch 100| loss: 0.21707 | val_0_rmspe: 0.21994 |  0:04:19s\n",
      "epoch 150| loss: 0.21165 | val_0_rmspe: 0.21766 |  0:06:28s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 162 and best_val_0_rmspe = 0.21573\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917002_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917002   0.2140049        1       17   16      3     1.87         2            1          0.00          0.02893596      entmax   200     1   0.00010000  38:09 \n",
      "\u001b[32m[I 2021-09-17 20:33:41,603]\u001b[0m Trial 2 finished with value: 0.21400485488737345 and parameters: {'n_d': 17, 'n_a': 16, 'n_steps': 3, 'gamma': 1.8729158987711878, 'n_independent': 2, 'n_shared': 1, 'lambda_sparse': 0.0, 'learning_rate': 0.028935963899215492}. Best is trial 0 with value: 0.21353625583126887.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.21400485488737345\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 102.42106| val_0_rmspe: 19.11488|  0:00:02s\n",
      "epoch 50 | loss: 0.23253 | val_0_rmspe: 0.22536 |  0:01:50s\n",
      "epoch 100| loss: 0.21508 | val_0_rmspe: 0.21635 |  0:03:39s\n",
      "epoch 150| loss: 0.20762 | val_0_rmspe: 0.21291 |  0:05:28s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 188 and best_val_0_rmspe = 0.21209\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917003_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 199.51747| val_0_rmspe: 28.63246|  0:00:02s\n",
      "epoch 50 | loss: 0.24173 | val_0_rmspe: 0.23947 |  0:01:50s\n",
      "epoch 100| loss: 0.22034 | val_0_rmspe: 0.23113 |  0:03:38s\n",
      "epoch 150| loss: 0.21077 | val_0_rmspe: 0.21687 |  0:05:28s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 172 and best_val_0_rmspe = 0.21685\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917003_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 145.11886| val_0_rmspe: 30.43279|  0:00:02s\n",
      "epoch 50 | loss: 0.27062 | val_0_rmspe: 0.35465 |  0:01:50s\n",
      "epoch 100| loss: 0.21723 | val_0_rmspe: 0.22084 |  0:03:38s\n",
      "epoch 150| loss: 0.21083 | val_0_rmspe: 0.21803 |  0:05:26s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 196 and best_val_0_rmspe = 0.21671\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917003_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 189.93519| val_0_rmspe: 137.06124|  0:00:02s\n",
      "epoch 50 | loss: 0.24459 | val_0_rmspe: 0.24253 |  0:01:51s\n",
      "epoch 100| loss: 0.22522 | val_0_rmspe: 0.22871 |  0:03:40s\n",
      "epoch 150| loss: 0.21788 | val_0_rmspe: 0.22036 |  0:05:29s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 187 and best_val_0_rmspe = 0.21514\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917003_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 172.58556| val_0_rmspe: 45.12072|  0:00:02s\n",
      "epoch 50 | loss: 0.25644 | val_0_rmspe: 0.2577  |  0:01:50s\n",
      "epoch 100| loss: 0.22934 | val_0_rmspe: 0.21683 |  0:03:38s\n",
      "epoch 150| loss: 0.21247 | val_0_rmspe: 0.25946 |  0:05:26s\n",
      "\n",
      "Early stopping occurred at epoch 176 with best_epoch = 126 and best_val_0_rmspe = 0.21532\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917003_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917003   0.2152273        1       16   16      1     1.85         2            2          0.00          0.01158809      entmax   200     1   0.00010000  35:32 \n",
      "\u001b[32m[I 2021-09-17 21:09:14,184]\u001b[0m Trial 3 finished with value: 0.21522729523252876 and parameters: {'n_d': 16, 'n_a': 16, 'n_steps': 1, 'gamma': 1.8512532363486294, 'n_independent': 2, 'n_shared': 2, 'lambda_sparse': 0.001, 'learning_rate': 0.011588091035802618}. Best is trial 0 with value: 0.21353625583126887.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.21522729523252876\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 149.63884| val_0_rmspe: 25.37738|  0:00:02s\n",
      "epoch 50 | loss: 0.22709 | val_0_rmspe: 0.24037 |  0:02:11s\n",
      "epoch 100| loss: 0.21476 | val_0_rmspe: 0.21909 |  0:04:19s\n",
      "epoch 150| loss: 0.20589 | val_0_rmspe: 0.21134 |  0:06:27s\n",
      "\n",
      "Early stopping occurred at epoch 179 with best_epoch = 129 and best_val_0_rmspe = 0.211\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917004_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 150.89711| val_0_rmspe: 20.89955|  0:00:02s\n",
      "epoch 50 | loss: 0.22931 | val_0_rmspe: 0.26365 |  0:02:11s\n",
      "epoch 100| loss: 0.21089 | val_0_rmspe: 0.21658 |  0:04:20s\n",
      "epoch 150| loss: 0.20665 | val_0_rmspe: 0.21457 |  0:06:29s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 171 and best_val_0_rmspe = 0.21359\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917004_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 154.16432| val_0_rmspe: 26.47307|  0:00:02s\n",
      "epoch 50 | loss: 0.22382 | val_0_rmspe: 0.22152 |  0:02:10s\n",
      "epoch 100| loss: 0.21476 | val_0_rmspe: 0.22264 |  0:04:17s\n",
      "epoch 150| loss: 0.2051  | val_0_rmspe: 0.21608 |  0:06:24s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 152 and best_val_0_rmspe = 0.21545\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917004_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 158.18835| val_0_rmspe: 17.88751|  0:00:02s\n",
      "epoch 50 | loss: 0.26054 | val_0_rmspe: 0.24208 |  0:02:12s\n",
      "epoch 100| loss: 0.21805 | val_0_rmspe: 0.21432 |  0:04:21s\n",
      "epoch 150| loss: 0.20646 | val_0_rmspe: 0.21321 |  0:06:30s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 182 and best_val_0_rmspe = 0.21222\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917004_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 155.47151| val_0_rmspe: 59.82528|  0:00:02s\n",
      "epoch 50 | loss: 0.22683 | val_0_rmspe: 0.22994 |  0:02:10s\n",
      "epoch 100| loss: 0.21088 | val_0_rmspe: 0.23111 |  0:04:17s\n",
      "\n",
      "Early stopping occurred at epoch 119 with best_epoch = 69 and best_val_0_rmspe = 0.21476\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917004_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917004   0.2134098        1       17   17      2     1.96         3            3          0.00          0.02421223      entmax   200     1   0.00010000  38:44 \n",
      "\u001b[32m[I 2021-09-17 21:47:58,433]\u001b[0m Trial 4 finished with value: 0.2134098425361398 and parameters: {'n_d': 17, 'n_a': 17, 'n_steps': 2, 'gamma': 1.9607034966122827, 'n_independent': 3, 'n_shared': 3, 'lambda_sparse': 0.001, 'learning_rate': 0.024212229612217914}. Best is trial 4 with value: 0.2134098425361398.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.2134098425361398\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 248.14693| val_0_rmspe: 36.97003|  0:00:02s\n",
      "epoch 50 | loss: 0.24611 | val_0_rmspe: 0.24452 |  0:02:06s\n",
      "epoch 100| loss: 0.21724 | val_0_rmspe: 0.22275 |  0:04:10s\n",
      "epoch 150| loss: 0.20725 | val_0_rmspe: 0.21188 |  0:06:14s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 166 and best_val_0_rmspe = 0.21164\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917005_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 181.37516| val_0_rmspe: 31.54778|  0:00:02s\n",
      "epoch 50 | loss: 0.23879 | val_0_rmspe: 0.248   |  0:02:07s\n",
      "epoch 100| loss: 0.21254 | val_0_rmspe: 0.21741 |  0:04:12s\n",
      "epoch 150| loss: 0.20591 | val_0_rmspe: 0.21563 |  0:06:16s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 184 and best_val_0_rmspe = 0.21518\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917005_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 159.06248| val_0_rmspe: 37.35016|  0:00:02s\n",
      "epoch 50 | loss: 0.22718 | val_0_rmspe: 0.24228 |  0:02:06s\n",
      "epoch 100| loss: 0.21377 | val_0_rmspe: 0.22281 |  0:04:10s\n",
      "epoch 150| loss: 0.20309 | val_0_rmspe: 0.21684 |  0:06:14s\n",
      "\n",
      "Early stopping occurred at epoch 162 with best_epoch = 112 and best_val_0_rmspe = 0.21545\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917005_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 276.49424| val_0_rmspe: 94.97189|  0:00:02s\n",
      "epoch 50 | loss: 0.23372 | val_0_rmspe: 0.2218  |  0:02:07s\n",
      "epoch 100| loss: 0.21153 | val_0_rmspe: 0.21318 |  0:04:12s\n",
      "epoch 150| loss: 0.20385 | val_0_rmspe: 0.21061 |  0:06:16s\n",
      "\n",
      "Early stopping occurred at epoch 176 with best_epoch = 126 and best_val_0_rmspe = 0.21012\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917005_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 188.28253| val_0_rmspe: 43.19256|  0:00:02s\n",
      "epoch 50 | loss: 0.22414 | val_0_rmspe: 0.22761 |  0:02:07s\n",
      "epoch 100| loss: 0.21074 | val_0_rmspe: 0.22907 |  0:04:11s\n",
      "\n",
      "Early stopping occurred at epoch 105 with best_epoch = 55 and best_val_0_rmspe = 0.21586\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917005_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917005   0.2136636        1       18   16      2     1.90         2            3          0.00          0.02856818      entmax   200     1   0.00010000  35:17 \n",
      "\u001b[32m[I 2021-09-17 22:23:16,061]\u001b[0m Trial 5 finished with value: 0.2136636232332618 and parameters: {'n_d': 18, 'n_a': 16, 'n_steps': 2, 'gamma': 1.899131184141647, 'n_independent': 2, 'n_shared': 3, 'lambda_sparse': 0.0, 'learning_rate': 0.028568181121925343}. Best is trial 4 with value: 0.2134098425361398.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.2136636232332618\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 109.61789| val_0_rmspe: 11.52867|  0:00:02s\n",
      "epoch 50 | loss: 0.24651 | val_0_rmspe: 0.23671 |  0:01:48s\n",
      "epoch 100| loss: 0.21844 | val_0_rmspe: 0.21591 |  0:03:35s\n",
      "epoch 150| loss: 0.20785 | val_0_rmspe: 0.21387 |  0:05:21s\n",
      "\n",
      "Early stopping occurred at epoch 196 with best_epoch = 146 and best_val_0_rmspe = 0.21225\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917006_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 127.09303| val_0_rmspe: 7.35667 |  0:00:02s\n",
      "epoch 50 | loss: 0.23839 | val_0_rmspe: 0.23454 |  0:01:48s\n",
      "epoch 100| loss: 0.21258 | val_0_rmspe: 0.22552 |  0:03:35s\n",
      "epoch 150| loss: 0.20527 | val_0_rmspe: 0.21895 |  0:05:22s\n",
      "\n",
      "Early stopping occurred at epoch 194 with best_epoch = 144 and best_val_0_rmspe = 0.21542\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917006_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 53.59448| val_0_rmspe: 16.46007|  0:00:02s\n",
      "epoch 50 | loss: 0.22694 | val_0_rmspe: 0.23112 |  0:01:47s\n",
      "epoch 100| loss: 0.21013 | val_0_rmspe: 0.21873 |  0:03:33s\n",
      "epoch 150| loss: 0.20548 | val_0_rmspe: 0.21557 |  0:05:18s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 182 and best_val_0_rmspe = 0.2149\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917006_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 78.18097| val_0_rmspe: 19.73391|  0:00:02s\n",
      "epoch 50 | loss: 0.23157 | val_0_rmspe: 0.21977 |  0:01:48s\n",
      "epoch 100| loss: 0.21226 | val_0_rmspe: 0.213   |  0:03:36s\n",
      "epoch 150| loss: 0.20351 | val_0_rmspe: 0.2141  |  0:05:22s\n",
      "\n",
      "Early stopping occurred at epoch 158 with best_epoch = 108 and best_val_0_rmspe = 0.21111\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917006_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 84.61214| val_0_rmspe: 5.377   |  0:00:02s\n",
      "epoch 50 | loss: 0.22055 | val_0_rmspe: 0.21664 |  0:01:47s\n",
      "epoch 100| loss: 0.21554 | val_0_rmspe: 0.22517 |  0:03:34s\n",
      "epoch 150| loss: 0.20317 | val_0_rmspe: 0.21634 |  0:05:19s\n",
      "\n",
      "Early stopping occurred at epoch 158 with best_epoch = 108 and best_val_0_rmspe = 0.21284\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917006_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917006   0.2133087        1       15   18      1     1.97         2            1          0.00          0.02100062      entmax   200     1   0.00010000  32:27 \n",
      "\u001b[32m[I 2021-09-17 22:55:43,150]\u001b[0m Trial 6 finished with value: 0.2133086646354432 and parameters: {'n_d': 15, 'n_a': 18, 'n_steps': 1, 'gamma': 1.9723264184253528, 'n_independent': 2, 'n_shared': 1, 'lambda_sparse': 0.001, 'learning_rate': 0.02100062287063875}. Best is trial 6 with value: 0.2133086646354432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.2133086646354432\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 53.46574| val_0_rmspe: 4.37901 |  0:00:02s\n",
      "epoch 50 | loss: 0.21404 | val_0_rmspe: 0.22715 |  0:01:48s\n",
      "epoch 100| loss: 0.20592 | val_0_rmspe: 0.21253 |  0:03:35s\n",
      "epoch 150| loss: 0.20141 | val_0_rmspe: 0.21345 |  0:05:21s\n",
      "\n",
      "Early stopping occurred at epoch 153 with best_epoch = 103 and best_val_0_rmspe = 0.21197\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917007_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 78.57781| val_0_rmspe: 4.19806 |  0:00:02s\n",
      "epoch 50 | loss: 0.22323 | val_0_rmspe: 0.21967 |  0:01:48s\n",
      "epoch 100| loss: 0.21003 | val_0_rmspe: 0.21692 |  0:03:36s\n",
      "epoch 150| loss: 0.20198 | val_0_rmspe: 0.21646 |  0:05:22s\n",
      "\n",
      "Early stopping occurred at epoch 183 with best_epoch = 133 and best_val_0_rmspe = 0.21536\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917007_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 51.78111| val_0_rmspe: 3.99382 |  0:00:02s\n",
      "epoch 50 | loss: 0.21717 | val_0_rmspe: 0.22257 |  0:01:47s\n",
      "epoch 100| loss: 0.20413 | val_0_rmspe: 0.21666 |  0:03:33s\n",
      "\n",
      "Early stopping occurred at epoch 137 with best_epoch = 87 and best_val_0_rmspe = 0.21512\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917007_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 48.04806| val_0_rmspe: 2.95792 |  0:00:02s\n",
      "epoch 50 | loss: 0.22938 | val_0_rmspe: 0.22957 |  0:01:48s\n",
      "epoch 100| loss: 0.20862 | val_0_rmspe: 0.21054 |  0:03:35s\n",
      "epoch 150| loss: 0.20211 | val_0_rmspe: 0.21555 |  0:05:21s\n",
      "\n",
      "Early stopping occurred at epoch 194 with best_epoch = 144 and best_val_0_rmspe = 0.2101\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917007_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 77.74282| val_0_rmspe: 10.43174|  0:00:02s\n",
      "epoch 50 | loss: 0.23796 | val_0_rmspe: 0.22015 |  0:01:47s\n",
      "epoch 100| loss: 0.21286 | val_0_rmspe: 0.21511 |  0:03:33s\n",
      "epoch 150| loss: 0.20234 | val_0_rmspe: 0.2195  |  0:05:18s\n",
      "\n",
      "Early stopping occurred at epoch 171 with best_epoch = 121 and best_val_0_rmspe = 0.21226\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917007_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917007   0.2129706        1       14   16      1     1.94         2            1          0.00          0.01986204      entmax   200     1   0.00010000  30:03 \n",
      "\u001b[32m[I 2021-09-17 23:25:46,353]\u001b[0m Trial 7 finished with value: 0.21297060056178208 and parameters: {'n_d': 14, 'n_a': 16, 'n_steps': 1, 'gamma': 1.938938819615773, 'n_independent': 2, 'n_shared': 1, 'lambda_sparse': 0.0, 'learning_rate': 0.01986203869418597}. Best is trial 7 with value: 0.21297060056178208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.21297060056178208\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 134.84606| val_0_rmspe: 25.19872|  0:00:02s\n",
      "epoch 50 | loss: 0.23381 | val_0_rmspe: 0.29996 |  0:01:51s\n",
      "epoch 100| loss: 0.22338 | val_0_rmspe: 0.22133 |  0:03:40s\n",
      "epoch 150| loss: 0.20589 | val_0_rmspe: 0.21175 |  0:05:29s\n",
      "\n",
      "Early stopping occurred at epoch 199 with best_epoch = 149 and best_val_0_rmspe = 0.21162\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917008_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 138.45581| val_0_rmspe: 24.38071|  0:00:02s\n",
      "epoch 50 | loss: 0.33355 | val_0_rmspe: 0.35836 |  0:01:51s\n",
      "epoch 100| loss: 0.24386 | val_0_rmspe: 0.2414  |  0:03:40s\n",
      "epoch 150| loss: 0.21504 | val_0_rmspe: 0.22231 |  0:05:28s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 184 and best_val_0_rmspe = 0.21873\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917008_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 213.15332| val_0_rmspe: 95.29988|  0:00:02s\n",
      "epoch 50 | loss: 0.24056 | val_0_rmspe: 0.23819 |  0:01:49s\n",
      "epoch 100| loss: 0.21055 | val_0_rmspe: 0.21641 |  0:03:38s\n",
      "epoch 150| loss: 0.20509 | val_0_rmspe: 0.21651 |  0:05:26s\n",
      "\n",
      "Early stopping occurred at epoch 187 with best_epoch = 137 and best_val_0_rmspe = 0.21586\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917008_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 100.7127| val_0_rmspe: 28.27829|  0:00:02s\n",
      "epoch 50 | loss: 0.22884 | val_0_rmspe: 0.22853 |  0:01:51s\n",
      "epoch 100| loss: 0.21171 | val_0_rmspe: 0.22413 |  0:03:40s\n",
      "\n",
      "Early stopping occurred at epoch 149 with best_epoch = 99 and best_val_0_rmspe = 0.21216\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917008_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 122.42992| val_0_rmspe: 20.67537|  0:00:02s\n",
      "epoch 50 | loss: 0.23084 | val_0_rmspe: 0.22903 |  0:01:50s\n",
      "epoch 100| loss: 0.21048 | val_0_rmspe: 0.22699 |  0:03:39s\n",
      "epoch 150| loss: 0.20236 | val_0_rmspe: 0.21595 |  0:05:26s\n",
      "\n",
      "Early stopping occurred at epoch 174 with best_epoch = 124 and best_val_0_rmspe = 0.21418\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917008_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917008   0.2145262        1       17   17      1     1.98         3            1          0.00          0.01627786      entmax   200     1   0.00010000  33:16 \n",
      "\u001b[32m[I 2021-09-17 23:59:02,951]\u001b[0m Trial 8 finished with value: 0.214526172871051 and parameters: {'n_d': 17, 'n_a': 17, 'n_steps': 1, 'gamma': 1.980689222867, 'n_independent': 3, 'n_shared': 1, 'lambda_sparse': 0.0, 'learning_rate': 0.016277859441750763}. Best is trial 7 with value: 0.21297060056178208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.214526172871051\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 240.38018| val_0_rmspe: 99.22467|  0:00:02s\n",
      "epoch 50 | loss: 0.22955 | val_0_rmspe: 0.22494 |  0:02:08s\n",
      "epoch 100| loss: 0.21717 | val_0_rmspe: 0.21476 |  0:04:13s\n",
      "epoch 150| loss: 0.20769 | val_0_rmspe: 0.21314 |  0:06:19s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 159 and best_val_0_rmspe = 0.21217\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917009_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 238.87055| val_0_rmspe: 306.61303|  0:00:02s\n",
      "epoch 50 | loss: 0.25141 | val_0_rmspe: 0.25736 |  0:02:08s\n",
      "epoch 100| loss: 0.21539 | val_0_rmspe: 0.21795 |  0:04:13s\n",
      "epoch 150| loss: 0.20743 | val_0_rmspe: 0.21557 |  0:06:19s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 181 and best_val_0_rmspe = 0.21415\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917009_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 268.66883| val_0_rmspe: 62.67154|  0:00:02s\n",
      "epoch 50 | loss: 0.25044 | val_0_rmspe: 0.24253 |  0:02:08s\n",
      "epoch 100| loss: 0.22744 | val_0_rmspe: 0.22922 |  0:04:13s\n",
      "epoch 150| loss: 0.21356 | val_0_rmspe: 0.22117 |  0:06:18s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 194 and best_val_0_rmspe = 0.21908\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917009_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 258.28073| val_0_rmspe: 148.242 |  0:00:02s\n",
      "epoch 50 | loss: 0.23289 | val_0_rmspe: 0.23131 |  0:02:08s\n",
      "epoch 100| loss: 0.21459 | val_0_rmspe: 0.21642 |  0:04:13s\n",
      "epoch 150| loss: 0.20929 | val_0_rmspe: 0.22082 |  0:06:18s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 158 and best_val_0_rmspe = 0.21216\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917009_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 242.34613| val_0_rmspe: 58.66718|  0:00:02s\n",
      "epoch 50 | loss: 0.25799 | val_0_rmspe: 0.2563  |  0:02:08s\n",
      "epoch 100| loss: 0.21579 | val_0_rmspe: 0.22371 |  0:04:12s\n",
      "epoch 150| loss: 0.20767 | val_0_rmspe: 0.21309 |  0:06:16s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 150 and best_val_0_rmspe = 0.21309\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917009_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917009   0.2141445        1       18   17      2     1.81         3            2          0.00          0.01375725      entmax   200     1   0.00010000  41:54 \n",
      "\u001b[32m[I 2021-09-18 00:40:57,586]\u001b[0m Trial 9 finished with value: 0.21414452534835468 and parameters: {'n_d': 18, 'n_a': 17, 'n_steps': 2, 'gamma': 1.813161814638165, 'n_independent': 3, 'n_shared': 2, 'lambda_sparse': 0.0, 'learning_rate': 0.013757245381037059}. Best is trial 7 with value: 0.21297060056178208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.21414452534835468\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 152.37041| val_0_rmspe: 50.72075|  0:00:02s\n",
      "epoch 50 | loss: 0.23046 | val_0_rmspe: 0.22622 |  0:02:11s\n",
      "epoch 100| loss: 0.21132 | val_0_rmspe: 0.21433 |  0:04:20s\n",
      "epoch 150| loss: 0.20573 | val_0_rmspe: 0.21292 |  0:06:29s\n",
      "\n",
      "Early stopping occurred at epoch 199 with best_epoch = 149 and best_val_0_rmspe = 0.21271\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917010_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 136.95321| val_0_rmspe: 56.8595 |  0:00:02s\n",
      "epoch 50 | loss: 0.22703 | val_0_rmspe: 0.22983 |  0:02:11s\n",
      "epoch 100| loss: 0.21322 | val_0_rmspe: 0.21833 |  0:04:21s\n",
      "epoch 150| loss: 0.20818 | val_0_rmspe: 0.2183  |  0:06:30s\n",
      "\n",
      "Early stopping occurred at epoch 167 with best_epoch = 117 and best_val_0_rmspe = 0.21503\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917010_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 172.44531| val_0_rmspe: 54.98831|  0:00:02s\n",
      "epoch 50 | loss: 0.23148 | val_0_rmspe: 0.22848 |  0:02:11s\n",
      "epoch 100| loss: 0.21482 | val_0_rmspe: 0.22201 |  0:04:19s\n",
      "epoch 150| loss: 0.20719 | val_0_rmspe: 0.21746 |  0:06:28s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 190 and best_val_0_rmspe = 0.21668\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917010_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 133.06717| val_0_rmspe: 35.09069|  0:00:02s\n",
      "epoch 50 | loss: 0.23762 | val_0_rmspe: 0.24754 |  0:02:12s\n",
      "epoch 100| loss: 0.21435 | val_0_rmspe: 0.21611 |  0:04:21s\n",
      "epoch 150| loss: 0.20904 | val_0_rmspe: 0.2137  |  0:06:30s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 151 and best_val_0_rmspe = 0.21214\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917010_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 122.83485| val_0_rmspe: 104.54992|  0:00:02s\n",
      "epoch 50 | loss: 0.23527 | val_0_rmspe: 0.23515 |  0:02:11s\n",
      "epoch 100| loss: 0.21147 | val_0_rmspe: 0.21376 |  0:04:20s\n",
      "epoch 150| loss: 0.2069  | val_0_rmspe: 0.21278 |  0:06:28s\n",
      "\n",
      "Early stopping occurred at epoch 174 with best_epoch = 124 and best_val_0_rmspe = 0.21233\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917010_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917010   0.2137879        1       16   15      3     1.98         2            1          0.00          0.01998502      entmax   200     1   0.00010000  40:42 \n",
      "\u001b[32m[I 2021-09-18 01:21:39,990]\u001b[0m Trial 10 finished with value: 0.21378786430510952 and parameters: {'n_d': 16, 'n_a': 15, 'n_steps': 3, 'gamma': 1.9793876594695212, 'n_independent': 2, 'n_shared': 1, 'lambda_sparse': 0.001, 'learning_rate': 0.019985015393063126}. Best is trial 7 with value: 0.21297060056178208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.21378786430510952\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 28.82134| val_0_rmspe: 2.09301 |  0:00:01s\n",
      "epoch 50 | loss: 0.21477 | val_0_rmspe: 0.22172 |  0:01:44s\n",
      "epoch 100| loss: 0.20395 | val_0_rmspe: 0.21281 |  0:03:28s\n",
      "\n",
      "Early stopping occurred at epoch 135 with best_epoch = 85 and best_val_0_rmspe = 0.2122\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917011_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 38.20095| val_0_rmspe: 3.95067 |  0:00:02s\n",
      "epoch 50 | loss: 0.21639 | val_0_rmspe: 0.22237 |  0:01:46s\n",
      "epoch 100| loss: 0.20531 | val_0_rmspe: 0.21458 |  0:03:30s\n",
      "\n",
      "Early stopping occurred at epoch 141 with best_epoch = 91 and best_val_0_rmspe = 0.21404\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917011_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 55.20741| val_0_rmspe: 2.51754 |  0:00:02s\n",
      "epoch 50 | loss: 0.21581 | val_0_rmspe: 0.22149 |  0:01:45s\n",
      "epoch 100| loss: 0.20448 | val_0_rmspe: 0.21656 |  0:03:28s\n",
      "\n",
      "Early stopping occurred at epoch 127 with best_epoch = 77 and best_val_0_rmspe = 0.21565\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917011_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 21.91769| val_0_rmspe: 2.44947 |  0:00:02s\n",
      "epoch 50 | loss: 0.22041 | val_0_rmspe: 0.22017 |  0:01:46s\n",
      "epoch 100| loss: 0.20348 | val_0_rmspe: 0.21394 |  0:03:30s\n",
      "\n",
      "Early stopping occurred at epoch 130 with best_epoch = 80 and best_val_0_rmspe = 0.21146\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917011_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 24.54163| val_0_rmspe: 3.21727 |  0:00:02s\n",
      "epoch 50 | loss: 0.22077 | val_0_rmspe: 0.23082 |  0:01:45s\n",
      "epoch 100| loss: 0.20538 | val_0_rmspe: 0.22382 |  0:03:28s\n",
      "\n",
      "Early stopping occurred at epoch 125 with best_epoch = 75 and best_val_0_rmspe = 0.21263\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917011_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917011   0.2131993        1       14   18      1     1.95         1            1          0.00          0.02761733      entmax   200     1   0.00010000  23:06 \n",
      "\u001b[32m[I 2021-09-18 01:44:46,134]\u001b[0m Trial 11 finished with value: 0.2131992503454295 and parameters: {'n_d': 14, 'n_a': 18, 'n_steps': 1, 'gamma': 1.9480579200097077, 'n_independent': 1, 'n_shared': 1, 'lambda_sparse': 0.0, 'learning_rate': 0.027617332064611547}. Best is trial 7 with value: 0.21297060056178208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.2131992503454295\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 290.98204| val_0_rmspe: 65.03957|  0:00:02s\n",
      "epoch 50 | loss: 0.24802 | val_0_rmspe: 0.23898 |  0:02:06s\n",
      "epoch 100| loss: 0.21958 | val_0_rmspe: 0.21666 |  0:04:11s\n",
      "epoch 150| loss: 0.21228 | val_0_rmspe: 0.21575 |  0:06:15s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 179 and best_val_0_rmspe = 0.21239\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917012_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 201.87899| val_0_rmspe: 69.4562 |  0:00:02s\n",
      "epoch 50 | loss: 0.23582 | val_0_rmspe: 0.23232 |  0:02:06s\n",
      "epoch 100| loss: 0.21869 | val_0_rmspe: 0.22459 |  0:04:11s\n",
      "epoch 150| loss: 0.20978 | val_0_rmspe: 0.21798 |  0:06:15s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 163 and best_val_0_rmspe = 0.21677\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917012_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 262.46298| val_0_rmspe: 99.69375|  0:00:02s\n",
      "epoch 50 | loss: 0.24096 | val_0_rmspe: 0.27036 |  0:02:05s\n",
      "epoch 100| loss: 0.21781 | val_0_rmspe: 0.22412 |  0:04:09s\n",
      "epoch 150| loss: 0.208   | val_0_rmspe: 0.21845 |  0:06:12s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 176 and best_val_0_rmspe = 0.21676\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917012_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 265.14583| val_0_rmspe: 58.33361|  0:00:02s\n",
      "epoch 50 | loss: 0.23292 | val_0_rmspe: 0.24281 |  0:02:06s\n",
      "epoch 100| loss: 0.21183 | val_0_rmspe: 0.2196  |  0:04:11s\n",
      "epoch 150| loss: 0.20601 | val_0_rmspe: 0.22085 |  0:06:15s\n",
      "\n",
      "Early stopping occurred at epoch 192 with best_epoch = 142 and best_val_0_rmspe = 0.21428\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917012_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 261.50418| val_0_rmspe: 69.35305|  0:00:02s\n",
      "epoch 50 | loss: 0.22497 | val_0_rmspe: 0.22156 |  0:02:05s\n",
      "epoch 100| loss: 0.21155 | val_0_rmspe: 0.21463 |  0:04:08s\n",
      "epoch 150| loss: 0.20651 | val_0_rmspe: 0.21636 |  0:06:12s\n",
      "\n",
      "Early stopping occurred at epoch 181 with best_epoch = 131 and best_val_0_rmspe = 0.21302\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917012_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917012   0.2146514        1       15   16      3     1.82         1            1          0.00          0.01671690      entmax   200     1   0.00010000  40:29 \n",
      "\u001b[32m[I 2021-09-18 02:25:15,793]\u001b[0m Trial 12 finished with value: 0.2146514000212205 and parameters: {'n_d': 15, 'n_a': 16, 'n_steps': 3, 'gamma': 1.8210391646540933, 'n_independent': 1, 'n_shared': 1, 'lambda_sparse': 0.001, 'learning_rate': 0.01671690048953213}. Best is trial 7 with value: 0.21297060056178208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.2146514000212205\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 305.97989| val_0_rmspe: 67.81943|  0:00:02s\n",
      "epoch 50 | loss: 0.22017 | val_0_rmspe: 0.22099 |  0:02:06s\n",
      "epoch 100| loss: 0.20821 | val_0_rmspe: 0.21384 |  0:04:10s\n",
      "epoch 150| loss: 0.20296 | val_0_rmspe: 0.21389 |  0:06:13s\n",
      "\n",
      "Early stopping occurred at epoch 177 with best_epoch = 127 and best_val_0_rmspe = 0.21181\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917013_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 342.63143| val_0_rmspe: 79.58143|  0:00:02s\n",
      "epoch 50 | loss: 0.23448 | val_0_rmspe: 0.23214 |  0:02:07s\n",
      "epoch 100| loss: 0.21825 | val_0_rmspe: 0.21997 |  0:04:12s\n",
      "epoch 150| loss: 0.20648 | val_0_rmspe: 0.2179  |  0:06:15s\n",
      "\n",
      "Early stopping occurred at epoch 153 with best_epoch = 103 and best_val_0_rmspe = 0.21769\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917013_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 287.88791| val_0_rmspe: 196.71441|  0:00:02s\n",
      "epoch 50 | loss: 0.23548 | val_0_rmspe: 0.23656 |  0:02:06s\n",
      "epoch 100| loss: 0.21747 | val_0_rmspe: 0.22498 |  0:04:10s\n",
      "epoch 150| loss: 0.21018 | val_0_rmspe: 0.21863 |  0:06:13s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 181 and best_val_0_rmspe = 0.21678\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917013_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 246.63054| val_0_rmspe: 69.72056|  0:00:02s\n",
      "epoch 50 | loss: 0.22579 | val_0_rmspe: 0.22274 |  0:02:07s\n",
      "epoch 100| loss: 0.2084  | val_0_rmspe: 0.21568 |  0:04:11s\n",
      "epoch 150| loss: 0.20433 | val_0_rmspe: 0.2174  |  0:06:16s\n",
      "\n",
      "Early stopping occurred at epoch 171 with best_epoch = 121 and best_val_0_rmspe = 0.21197\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917013_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 314.99302| val_0_rmspe: 110.10905|  0:00:02s\n",
      "epoch 50 | loss: 0.23329 | val_0_rmspe: 0.23399 |  0:02:06s\n",
      "epoch 100| loss: 0.21604 | val_0_rmspe: 0.22329 |  0:04:09s\n",
      "epoch 150| loss: 0.21139 | val_0_rmspe: 0.22018 |  0:06:13s\n",
      "\n",
      "Early stopping occurred at epoch 186 with best_epoch = 136 and best_val_0_rmspe = 0.21315\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917013_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917013   0.2142939        1       18   18      3     1.99         1            1          0.00          0.01850070      entmax   200     1   0.00010000  37:02 \n",
      "\u001b[32m[I 2021-09-18 03:02:18,275]\u001b[0m Trial 13 finished with value: 0.21429393105156097 and parameters: {'n_d': 18, 'n_a': 18, 'n_steps': 3, 'gamma': 1.99396672975095, 'n_independent': 1, 'n_shared': 1, 'lambda_sparse': 0.001, 'learning_rate': 0.018500703044194815}. Best is trial 7 with value: 0.21297060056178208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.21429393105156097\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 123.9744| val_0_rmspe: 106.77523|  0:00:02s\n",
      "epoch 50 | loss: 0.22713 | val_0_rmspe: 0.23016 |  0:02:02s\n",
      "epoch 100| loss: 0.21193 | val_0_rmspe: 0.21458 |  0:04:03s\n",
      "epoch 150| loss: 0.20677 | val_0_rmspe: 0.21216 |  0:06:03s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 170 and best_val_0_rmspe = 0.21194\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917014_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 175.58117| val_0_rmspe: 67.06066|  0:00:02s\n",
      "epoch 50 | loss: 0.23789 | val_0_rmspe: 0.23155 |  0:02:03s\n",
      "epoch 100| loss: 0.21551 | val_0_rmspe: 0.22265 |  0:04:04s\n",
      "epoch 150| loss: 0.20677 | val_0_rmspe: 0.21561 |  0:06:04s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 182 and best_val_0_rmspe = 0.21527\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917014_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 139.30255| val_0_rmspe: 37.65311|  0:00:02s\n",
      "epoch 50 | loss: 0.23965 | val_0_rmspe: 0.23079 |  0:02:02s\n",
      "epoch 100| loss: 0.21168 | val_0_rmspe: 0.21903 |  0:04:02s\n",
      "epoch 150| loss: 0.20703 | val_0_rmspe: 0.21707 |  0:06:02s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 171 and best_val_0_rmspe = 0.21567\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917014_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 176.1817| val_0_rmspe: 56.11949|  0:00:02s\n",
      "epoch 50 | loss: 0.23282 | val_0_rmspe: 0.26849 |  0:02:03s\n",
      "epoch 100| loss: 0.21357 | val_0_rmspe: 0.21832 |  0:04:05s\n",
      "\n",
      "Early stopping occurred at epoch 141 with best_epoch = 91 and best_val_0_rmspe = 0.21478\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917014_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 138.37554| val_0_rmspe: 47.13042|  0:00:02s\n",
      "epoch 50 | loss: 0.25062 | val_0_rmspe: 0.23299 |  0:02:02s\n",
      "epoch 100| loss: 0.21781 | val_0_rmspe: 0.21715 |  0:04:02s\n",
      "epoch 150| loss: 0.20914 | val_0_rmspe: 0.21532 |  0:06:03s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 173 and best_val_0_rmspe = 0.21375\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917014_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917014   0.2142864        1       15   17      2     1.99         1            3          0.00          0.01421623      entmax   200     1   0.00010000  38:01 \n",
      "\u001b[32m[I 2021-09-18 03:40:19,590]\u001b[0m Trial 14 finished with value: 0.21428637866348973 and parameters: {'n_d': 15, 'n_a': 17, 'n_steps': 2, 'gamma': 1.9942425522109481, 'n_independent': 1, 'n_shared': 3, 'lambda_sparse': 0.0, 'learning_rate': 0.01421622830663111}. Best is trial 7 with value: 0.21297060056178208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.21428637866348973\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 68.68506| val_0_rmspe: 8.16448 |  0:00:02s\n",
      "epoch 50 | loss: 0.21534 | val_0_rmspe: 0.21522 |  0:01:47s\n",
      "epoch 100| loss: 0.20798 | val_0_rmspe: 0.21523 |  0:03:34s\n",
      "epoch 150| loss: 0.20272 | val_0_rmspe: 0.21301 |  0:05:20s\n",
      "\n",
      "Early stopping occurred at epoch 188 with best_epoch = 138 and best_val_0_rmspe = 0.211\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917015_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 63.66979| val_0_rmspe: 24.69537|  0:00:02s\n",
      "epoch 50 | loss: 0.21419 | val_0_rmspe: 0.22482 |  0:01:49s\n",
      "epoch 100| loss: 0.20547 | val_0_rmspe: 0.21613 |  0:03:35s\n",
      "\n",
      "Early stopping occurred at epoch 130 with best_epoch = 80 and best_val_0_rmspe = 0.21451\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917015_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 62.21292| val_0_rmspe: 3.39327 |  0:00:02s\n",
      "epoch 50 | loss: 0.22652 | val_0_rmspe: 0.22328 |  0:01:47s\n",
      "epoch 100| loss: 0.20918 | val_0_rmspe: 0.21688 |  0:03:34s\n",
      "epoch 150| loss: 0.2027  | val_0_rmspe: 0.21778 |  0:05:20s\n",
      "\n",
      "Early stopping occurred at epoch 167 with best_epoch = 117 and best_val_0_rmspe = 0.21509\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917015_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 96.52239| val_0_rmspe: 33.64991|  0:00:02s\n",
      "epoch 50 | loss: 0.22062 | val_0_rmspe: 0.2189  |  0:01:48s\n",
      "epoch 100| loss: 0.20899 | val_0_rmspe: 0.21125 |  0:03:34s\n",
      "epoch 150| loss: 0.20398 | val_0_rmspe: 0.21161 |  0:05:21s\n",
      "\n",
      "Early stopping occurred at epoch 195 with best_epoch = 145 and best_val_0_rmspe = 0.21031\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917015_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 50.61277| val_0_rmspe: 5.05088 |  0:00:02s\n",
      "epoch 50 | loss: 0.22179 | val_0_rmspe: 0.21763 |  0:01:47s\n",
      "epoch 100| loss: 0.20948 | val_0_rmspe: 0.21756 |  0:03:32s\n",
      "epoch 150| loss: 0.20197 | val_0_rmspe: 0.21704 |  0:05:18s\n",
      "\n",
      "Early stopping occurred at epoch 159 with best_epoch = 109 and best_val_0_rmspe = 0.21325\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917015_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917015   0.2128403        1       14   14      1     1.94         1            2          0.00          0.02394244      entmax   200     1   0.00010000  30:02 \n",
      "\u001b[32m[I 2021-09-18 04:10:22,509]\u001b[0m Trial 15 finished with value: 0.21284028675292316 and parameters: {'n_d': 14, 'n_a': 14, 'n_steps': 1, 'gamma': 1.9372640832466164, 'n_independent': 1, 'n_shared': 2, 'lambda_sparse': 0.0, 'learning_rate': 0.023942436341719324}. Best is trial 15 with value: 0.21284028675292316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.21284028675292316\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 77.1076 | val_0_rmspe: 4.71387 |  0:00:02s\n",
      "epoch 50 | loss: 0.21848 | val_0_rmspe: 0.21606 |  0:01:49s\n",
      "epoch 100| loss: 0.20755 | val_0_rmspe: 0.21636 |  0:03:35s\n",
      "epoch 150| loss: 0.20156 | val_0_rmspe: 0.2157  |  0:05:21s\n",
      "\n",
      "Early stopping occurred at epoch 156 with best_epoch = 106 and best_val_0_rmspe = 0.21204\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917016_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 58.9196 | val_0_rmspe: 8.48058 |  0:00:02s\n",
      "epoch 50 | loss: 0.2604  | val_0_rmspe: 0.25883 |  0:01:49s\n",
      "epoch 100| loss: 0.20989 | val_0_rmspe: 0.22351 |  0:03:35s\n",
      "epoch 150| loss: 0.20254 | val_0_rmspe: 0.22016 |  0:05:21s\n",
      "\n",
      "Early stopping occurred at epoch 163 with best_epoch = 113 and best_val_0_rmspe = 0.21599\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917016_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 66.33544| val_0_rmspe: 10.16622|  0:00:02s\n",
      "epoch 50 | loss: 0.21765 | val_0_rmspe: 0.22606 |  0:01:48s\n",
      "epoch 100| loss: 0.20468 | val_0_rmspe: 0.21659 |  0:03:33s\n",
      "epoch 150| loss: 0.19826 | val_0_rmspe: 0.21703 |  0:05:19s\n",
      "\n",
      "Early stopping occurred at epoch 163 with best_epoch = 113 and best_val_0_rmspe = 0.21567\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917016_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 62.46053| val_0_rmspe: 7.23007 |  0:00:02s\n",
      "epoch 50 | loss: 0.21956 | val_0_rmspe: 0.22988 |  0:01:48s\n",
      "epoch 100| loss: 0.20554 | val_0_rmspe: 0.21504 |  0:03:34s\n",
      "epoch 150| loss: 0.20027 | val_0_rmspe: 0.21839 |  0:05:21s\n",
      "\n",
      "Early stopping occurred at epoch 170 with best_epoch = 120 and best_val_0_rmspe = 0.21111\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917016_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 62.98282| val_0_rmspe: 7.32294 |  0:00:02s\n",
      "epoch 50 | loss: 0.28129 | val_0_rmspe: 0.31505 |  0:01:48s\n",
      "epoch 100| loss: 0.20813 | val_0_rmspe: 0.2157  |  0:03:34s\n",
      "epoch 150| loss: 0.20212 | val_0_rmspe: 0.22035 |  0:05:20s\n",
      "\n",
      "Early stopping occurred at epoch 150 with best_epoch = 100 and best_val_0_rmspe = 0.2157\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917016_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917016   0.2141119        1       14   14      1     1.93         1            2          0.00          0.02375626      entmax   200     1   0.00010000  28:46 \n",
      "\u001b[32m[I 2021-09-18 04:39:08,921]\u001b[0m Trial 16 finished with value: 0.21411189770218841 and parameters: {'n_d': 14, 'n_a': 14, 'n_steps': 1, 'gamma': 1.9313511975051108, 'n_independent': 1, 'n_shared': 2, 'lambda_sparse': 0.0, 'learning_rate': 0.023756264938729718}. Best is trial 15 with value: 0.21284028675292316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.21411189770218841\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 81.1144 | val_0_rmspe: 5.49105 |  0:00:02s\n",
      "epoch 50 | loss: 0.22026 | val_0_rmspe: 0.22883 |  0:01:52s\n",
      "epoch 100| loss: 0.21438 | val_0_rmspe: 0.21521 |  0:03:44s\n",
      "epoch 150| loss: 0.20607 | val_0_rmspe: 0.21392 |  0:05:34s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 164 and best_val_0_rmspe = 0.21263\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917017_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 89.1035 | val_0_rmspe: 9.55241 |  0:00:02s\n",
      "epoch 50 | loss: 0.23151 | val_0_rmspe: 0.2365  |  0:01:53s\n",
      "epoch 100| loss: 0.21231 | val_0_rmspe: 0.21797 |  0:03:44s\n",
      "epoch 150| loss: 0.20455 | val_0_rmspe: 0.22567 |  0:05:35s\n",
      "\n",
      "Early stopping occurred at epoch 166 with best_epoch = 116 and best_val_0_rmspe = 0.21512\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917017_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 107.8822| val_0_rmspe: 14.0853 |  0:00:02s\n",
      "epoch 50 | loss: 0.22966 | val_0_rmspe: 0.23031 |  0:01:53s\n",
      "epoch 100| loss: 0.224   | val_0_rmspe: 0.2872  |  0:03:43s\n",
      "epoch 150| loss: 0.20306 | val_0_rmspe: 0.21478 |  0:05:34s\n",
      "\n",
      "Early stopping occurred at epoch 190 with best_epoch = 140 and best_val_0_rmspe = 0.21447\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917017_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 64.46279| val_0_rmspe: 7.09803 |  0:00:02s\n",
      "epoch 50 | loss: 0.22489 | val_0_rmspe: 0.21928 |  0:01:54s\n",
      "epoch 100| loss: 0.21125 | val_0_rmspe: 0.21911 |  0:03:46s\n",
      "epoch 150| loss: 0.20428 | val_0_rmspe: 0.21397 |  0:05:37s\n",
      "\n",
      "Early stopping occurred at epoch 196 with best_epoch = 146 and best_val_0_rmspe = 0.20949\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917017_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 71.10526| val_0_rmspe: 45.54906|  0:00:02s\n",
      "epoch 50 | loss: 0.23748 | val_0_rmspe: 0.23989 |  0:01:54s\n",
      "epoch 100| loss: 0.21788 | val_0_rmspe: 0.23539 |  0:03:44s\n",
      "\n",
      "Early stopping occurred at epoch 119 with best_epoch = 69 and best_val_0_rmspe = 0.22013\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917017_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917017   0.2143960        1       14   14      1     1.93         3            2          0.00          0.02274588      entmax   200     1   0.00010000  32:38 \n",
      "\u001b[32m[I 2021-09-18 05:11:46,949]\u001b[0m Trial 17 finished with value: 0.21439597685382844 and parameters: {'n_d': 14, 'n_a': 14, 'n_steps': 1, 'gamma': 1.9255856981300656, 'n_independent': 3, 'n_shared': 2, 'lambda_sparse': 0.0, 'learning_rate': 0.022745878639265898}. Best is trial 15 with value: 0.21284028675292316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.21439597685382844\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 79.59824| val_0_rmspe: 8.70163 |  0:00:02s\n",
      "epoch 50 | loss: 0.23056 | val_0_rmspe: 0.23512 |  0:01:50s\n",
      "epoch 100| loss: 0.21379 | val_0_rmspe: 0.22868 |  0:03:38s\n",
      "epoch 150| loss: 0.20554 | val_0_rmspe: 0.21318 |  0:05:27s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 178 and best_val_0_rmspe = 0.21287\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917018_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 89.92384| val_0_rmspe: 17.00592|  0:00:02s\n",
      "epoch 50 | loss: 0.43608 | val_0_rmspe: 0.44013 |  0:01:50s\n",
      "epoch 100| loss: 0.28602 | val_0_rmspe: 0.24947 |  0:03:39s\n",
      "epoch 150| loss: 0.22566 | val_0_rmspe: 0.22836 |  0:05:28s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 197 and best_val_0_rmspe = 0.21952\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917018_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 89.33308| val_0_rmspe: 9.02187 |  0:00:02s\n",
      "epoch 50 | loss: 0.27833 | val_0_rmspe: 0.26331 |  0:01:50s\n",
      "epoch 100| loss: 0.36043 | val_0_rmspe: 0.29232 |  0:03:39s\n",
      "epoch 150| loss: 0.22746 | val_0_rmspe: 0.22976 |  0:05:27s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 195 and best_val_0_rmspe = 0.22474\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917018_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 173.01634| val_0_rmspe: 59.86025|  0:00:02s\n",
      "epoch 50 | loss: 0.21877 | val_0_rmspe: 0.22188 |  0:01:51s\n",
      "epoch 100| loss: 0.20874 | val_0_rmspe: 0.21169 |  0:03:40s\n",
      "\n",
      "Early stopping occurred at epoch 139 with best_epoch = 89 and best_val_0_rmspe = 0.21131\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917018_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 109.68172| val_0_rmspe: 10.25717|  0:00:02s\n",
      "epoch 50 | loss: 0.29685 | val_0_rmspe: 0.27981 |  0:01:50s\n",
      "epoch 100| loss: 0.21495 | val_0_rmspe: 0.28959 |  0:03:38s\n",
      "\n",
      "Early stopping occurred at epoch 120 with best_epoch = 70 and best_val_0_rmspe = 0.22324\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917018_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917018   0.2184007        1       15   15      1     1.91         2            2          0.00          0.02108952      entmax   200     1   0.00010000  31:20 \n",
      "\u001b[32m[I 2021-09-18 05:43:07,863]\u001b[0m Trial 18 finished with value: 0.21840074899432663 and parameters: {'n_d': 15, 'n_a': 15, 'n_steps': 1, 'gamma': 1.9075223641081287, 'n_independent': 2, 'n_shared': 2, 'lambda_sparse': 0.0, 'learning_rate': 0.02108952181429731}. Best is trial 15 with value: 0.21284028675292316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.21840074899432663\n",
      "Training fold 0\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 92.75645| val_0_rmspe: 21.47523|  0:00:02s\n",
      "epoch 50 | loss: 0.22476 | val_0_rmspe: 0.22164 |  0:01:49s\n",
      "epoch 100| loss: 0.21091 | val_0_rmspe: 0.27168 |  0:03:35s\n",
      "epoch 150| loss: 0.20533 | val_0_rmspe: 0.21256 |  0:05:22s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 150 and best_val_0_rmspe = 0.21256\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917019_fold0.model.zip\n",
      "Training fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 128.02522| val_0_rmspe: 27.24875|  0:00:02s\n",
      "epoch 50 | loss: 0.25322 | val_0_rmspe: 0.26272 |  0:01:49s\n",
      "epoch 100| loss: 0.22582 | val_0_rmspe: 0.23343 |  0:03:35s\n",
      "epoch 150| loss: 0.21345 | val_0_rmspe: 0.22004 |  0:05:22s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 189 and best_val_0_rmspe = 0.21815\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917019_fold1.model.zip\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 77.62687| val_0_rmspe: 18.24931|  0:00:02s\n",
      "epoch 50 | loss: 0.31717 | val_0_rmspe: 0.27747 |  0:01:49s\n",
      "epoch 100| loss: 0.23974 | val_0_rmspe: 0.23036 |  0:03:34s\n",
      "epoch 150| loss: 0.21957 | val_0_rmspe: 0.22436 |  0:05:21s\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 196 and best_val_0_rmspe = 0.22068\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917019_fold2.model.zip\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 107.51162| val_0_rmspe: 18.43496|  0:00:02s\n",
      "epoch 50 | loss: 0.23272 | val_0_rmspe: 0.22136 |  0:01:48s\n",
      "epoch 100| loss: 0.21365 | val_0_rmspe: 0.21515 |  0:03:34s\n",
      "epoch 150| loss: 0.20546 | val_0_rmspe: 0.21482 |  0:05:21s\n",
      "\n",
      "Early stopping occurred at epoch 156 with best_epoch = 106 and best_val_0_rmspe = 0.21269\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917019_fold3.model.zip\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 84.91052| val_0_rmspe: 13.28566|  0:00:02s\n",
      "epoch 50 | loss: 0.22294 | val_0_rmspe: 0.22057 |  0:01:47s\n",
      "epoch 100| loss: 0.21358 | val_0_rmspe: 0.22371 |  0:03:33s\n",
      "epoch 150| loss: 0.20709 | val_0_rmspe: 0.22631 |  0:05:19s\n",
      "\n",
      "Early stopping occurred at epoch 172 with best_epoch = 122 and best_val_0_rmspe = 0.21263\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at /home/xuming/workspace/output/tabnet_917019_fold4.model.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " suffix  rmspe_score  cat_emb_dim  n_d  n_a  n_steps  gamma  n_independent  n_shared  lambda_sparse  optimizer_params  mask_type  T_0  T_mult eta_min     time\n",
      " 917019   0.2153700        1       16   14      1     1.94         1            2          0.00          0.01076705      entmax   200     1   0.00010000  33:08 \n",
      "\u001b[32m[I 2021-09-18 06:16:16,644]\u001b[0m Trial 19 finished with value: 0.2153699706954589 and parameters: {'n_d': 16, 'n_a': 14, 'n_steps': 1, 'gamma': 1.9399151944545263, 'n_independent': 1, 'n_shared': 2, 'lambda_sparse': 0.0, 'learning_rate': 0.010767050638480795}. Best is trial 15 with value: 0.21284028675292316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score across folds: 0.2153699706954589\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(sampler=TPESampler(n_startup_trials=n_startup_trials),direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eda715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12584.329791,
   "end_time": "2021-08-28T09:02:33.403369",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-28T05:32:49.073578",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
