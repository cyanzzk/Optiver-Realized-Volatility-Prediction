{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf445700",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:21:09.079086Z",
     "iopub.status.busy": "2021-09-19T14:21:09.078498Z",
     "iopub.status.idle": "2021-09-19T14:21:09.080072Z",
     "shell.execute_reply": "2021-09-19T14:21:09.079572Z",
     "shell.execute_reply.started": "2021-08-31T14:42:26.629611Z"
    },
    "papermill": {
     "duration": 0.043509,
     "end_time": "2021-09-19T14:21:09.080196",
     "exception": false,
     "start_time": "2021-09-19T14:21:09.036687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip uninstall scikit-learn -y\n",
    "# !pip install ../input/outlib/scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl\n",
    "\n",
    "# import sklearn\n",
    "# sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f0acd7a",
   "metadata": {
    "_cell_guid": "33cd69f1-96e9-4214-920f-0fb86bcd2056",
    "_uuid": "c930aefe-c0c1-4336-858d-28d810af02ae",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T14:21:09.228642Z",
     "iopub.status.busy": "2021-09-19T14:21:09.227916Z",
     "iopub.status.idle": "2021-09-19T14:21:10.019112Z",
     "shell.execute_reply": "2021-09-19T14:21:10.018641Z",
     "shell.execute_reply.started": "2021-09-01T09:00:05.721628Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.906175,
     "end_time": "2021-09-19T14:21:10.019242",
     "exception": false,
     "start_time": "2021-09-19T14:21:09.113067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy.matlib\n",
    "import random\n",
    "\n",
    "path_submissions = '/'\n",
    "\n",
    "target_name = 'target'\n",
    "scores_folds = {}\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883eaa31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:21:10.089208Z",
     "iopub.status.busy": "2021-09-19T14:21:10.088709Z",
     "iopub.status.idle": "2021-09-19T14:21:10.091864Z",
     "shell.execute_reply": "2021-09-19T14:21:10.092768Z"
    },
    "papermill": {
     "duration": 0.039827,
     "end_time": "2021-09-19T14:21:10.092890",
     "exception": false,
     "start_time": "2021-09-19T14:21:10.053063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '../input/optiver-realized-volatility-prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9c210d",
   "metadata": {
    "_cell_guid": "aa9c17e0-9e8b-4c5f-9cf2-9380633c87f3",
    "_uuid": "ab71dda0-ff79-4c4d-8a5d-81dba69aa840",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T14:21:10.187891Z",
     "iopub.status.busy": "2021-09-19T14:21:10.175141Z",
     "iopub.status.idle": "2021-09-19T14:21:10.213624Z",
     "shell.execute_reply": "2021-09-19T14:21:10.213220Z",
     "shell.execute_reply.started": "2021-09-01T09:00:06.709803Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.089143,
     "end_time": "2021-09-19T14:21:10.213730",
     "exception": false,
     "start_time": "2021-09-19T14:21:10.124587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate first WAP\n",
    "def calc_wap1(df):\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "# Function to calculate second WAP\n",
    "def calc_wap2(df):\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap3(df):\n",
    "    wap = (df['bid_price1'] * df['bid_size1'] + df['ask_price1'] * df['ask_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap4(df):\n",
    "    wap = (df['bid_price2'] * df['bid_size2'] + df['ask_price2'] * df['ask_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "# Function to calculate the log of the return\n",
    "# Remember that logb(x / y) = logb(x) - logb(y)\n",
    "def log_return(series):\n",
    "    return np.log(series).diff()\n",
    "\n",
    "# Calculate the realized volatility\n",
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "# Function to count unique elements of a series\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))\n",
    "\n",
    "# Function to read our base train and test set\n",
    "def read_train_test():\n",
    "    train = pd.read_csv(f'{data_dir}/train.csv')\n",
    "    test = pd.read_csv(f'{data_dir}/test.csv')\n",
    "    # Create a key to merge with book and trade data\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n",
    "    print(f'Our training set has {train.shape[0]} rows')\n",
    "    return train, test\n",
    "\n",
    "# Function to preprocess book data (for each stock id)\n",
    "def book_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    # Calculate Wap\n",
    "    df['wap1'] = calc_wap1(df)\n",
    "    df['wap2'] = calc_wap2(df)\n",
    "    df['wap3'] = calc_wap3(df)\n",
    "    df['wap4'] = calc_wap4(df)\n",
    "    # Calculate log returns\n",
    "    df['log_return1'] = df.groupby(['time_id'])['wap1'].apply(log_return)\n",
    "    df['log_return2'] = df.groupby(['time_id'])['wap2'].apply(log_return)\n",
    "    df['log_return3'] = df.groupby(['time_id'])['wap3'].apply(log_return)\n",
    "    df['log_return4'] = df.groupby(['time_id'])['wap4'].apply(log_return)\n",
    "    # Calculate wap balance\n",
    "    df['wap_balance'] = abs(df['wap1'] - df['wap2'])\n",
    "    # Calculate spread\n",
    "    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n",
    "    df['price_spread2'] = (df['ask_price2'] - df['bid_price2']) / ((df['ask_price2'] + df['bid_price2']) / 2)\n",
    "    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n",
    "    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n",
    "    df[\"bid_ask_spread\"] = abs(df['bid_spread'] - df['ask_spread'])\n",
    "    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'wap1': [np.sum, np.std],\n",
    "        'wap2': [np.sum, np.std],\n",
    "        'wap3': [np.sum, np.std],\n",
    "        'wap4': [np.sum, np.std],\n",
    "        'log_return1': [realized_volatility],\n",
    "        'log_return2': [realized_volatility],\n",
    "        'log_return3': [realized_volatility],\n",
    "        'log_return4': [realized_volatility],\n",
    "        'wap_balance': [np.sum, np.max],\n",
    "        'price_spread':[np.sum, np.max],\n",
    "        'price_spread2':[np.sum, np.max],\n",
    "        'bid_spread':[np.sum, np.max],\n",
    "        'ask_spread':[np.sum, np.max],\n",
    "        'total_volume':[np.sum, np.max],\n",
    "        'volume_imbalance':[np.sum, np.max],\n",
    "        \"bid_ask_spread\":[np.sum,  np.max],\n",
    "    }\n",
    "    create_feature_dict_time = {\n",
    "        'log_return1': [realized_volatility],\n",
    "        'log_return2': [realized_volatility],\n",
    "        'log_return3': [realized_volatility],\n",
    "        'log_return4': [realized_volatility],\n",
    "    }\n",
    "    \n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "\n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id__100'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    # Create row_id so we can merge\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n",
    "    df_feature.drop(['time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to preprocess trade data (for each stock id)\n",
    "def trade_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    df['amount']=df['price']*df['size']\n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum, np.max, np.min],\n",
    "        'order_count':[np.sum,np.max],\n",
    "        'amount':[np.sum,np.max,np.min],\n",
    "    }\n",
    "    create_feature_dict_time = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.sum],\n",
    "    }\n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "\n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "    \n",
    "    def tendency(price, vol):    \n",
    "        df_diff = np.diff(price)\n",
    "        val = (df_diff/price[1:])*100\n",
    "        power = np.sum(val*vol[1:])\n",
    "        return(power)\n",
    "    \n",
    "    lis = []\n",
    "    for n_time_id in df['time_id'].unique():\n",
    "        df_id = df[df['time_id'] == n_time_id]        \n",
    "        tendencyV = tendency(df_id['price'].values, df_id['size'].values)      \n",
    "        f_max = np.sum(df_id['price'].values > np.mean(df_id['price'].values))\n",
    "        f_min = np.sum(df_id['price'].values < np.mean(df_id['price'].values))\n",
    "        df_max =  np.sum(np.diff(df_id['price'].values) > 0)\n",
    "        df_min =  np.sum(np.diff(df_id['price'].values) < 0)\n",
    "        # new\n",
    "        abs_diff = np.median(np.abs( df_id['price'].values - np.mean(df_id['price'].values)))        \n",
    "        energy = np.mean(df_id['price'].values**2)\n",
    "        iqr_p = np.percentile(df_id['price'].values,75) - np.percentile(df_id['price'].values,25)\n",
    "        \n",
    "        # vol vars\n",
    "        \n",
    "        abs_diff_v = np.median(np.abs( df_id['size'].values - np.mean(df_id['size'].values)))        \n",
    "        energy_v = np.sum(df_id['size'].values**2)\n",
    "        iqr_p_v = np.percentile(df_id['size'].values,75) - np.percentile(df_id['size'].values,25)\n",
    "        \n",
    "        lis.append({'time_id':n_time_id,'tendency':tendencyV,'f_max':f_max,'f_min':f_min,'df_max':df_max,'df_min':df_min,\n",
    "                   'abs_diff':abs_diff,'energy':energy,'iqr_p':iqr_p,'abs_diff_v':abs_diff_v,'energy_v':energy_v,'iqr_p_v':iqr_p_v})\n",
    "    \n",
    "    df_lr = pd.DataFrame(lis)\n",
    "        \n",
    "   \n",
    "    df_feature = df_feature.merge(df_lr, how = 'left', left_on = 'time_id_', right_on = 'time_id')\n",
    "    \n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id','time_id__100'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature.drop(['trade_time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to get group stats for the stock_id and time_id\n",
    "def get_time_stock(df):\n",
    "    vol_cols = ['log_return1_realized_volatility', 'log_return2_realized_volatility', 'log_return1_realized_volatility_400', 'log_return2_realized_volatility_400', \n",
    "                'log_return1_realized_volatility_300', 'log_return2_realized_volatility_300', 'log_return1_realized_volatility_200', 'log_return2_realized_volatility_200', \n",
    "                'trade_log_return_realized_volatility', 'trade_log_return_realized_volatility_400', 'trade_log_return_realized_volatility_300', 'trade_log_return_realized_volatility_200']\n",
    "\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n",
    "    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n",
    "    df_time_id = df_time_id.add_suffix('_' + 'time')\n",
    "    \n",
    "    # Merge with original dataframe\n",
    "    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n",
    "    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n",
    "    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n",
    "    return df\n",
    "    \n",
    "# Funtion to make preprocessing function in parallel (for each stock id)\n",
    "def preprocessor(list_stock_ids, is_train = True):\n",
    "    \n",
    "    # Parrallel for loop\n",
    "    def for_joblib(stock_id):\n",
    "        # Train\n",
    "        if is_train:\n",
    "            file_path_book = data_dir + \"/book_train.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"/trade_train.parquet/stock_id=\" + str(stock_id)\n",
    "        # Test\n",
    "        else:\n",
    "            file_path_book = data_dir + \"/book_test.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"/trade_test.parquet/stock_id=\" + str(stock_id)\n",
    "    \n",
    "        # Preprocess book and trade data and merge them\n",
    "        df_tmp = pd.merge(book_preprocessor(file_path_book), trade_preprocessor(file_path_trade), on = 'row_id', how = 'left')\n",
    "        \n",
    "        # Return the merge dataframe\n",
    "        return df_tmp\n",
    "    \n",
    "    # Use parallel api to call paralle for loop\n",
    "    df = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(stock_id) for stock_id in list_stock_ids)\n",
    "    # Concatenate all the dataframes that return from Parallel\n",
    "    df = pd.concat(df, ignore_index = True)\n",
    "    return df\n",
    "\n",
    "# Function to calculate the root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a57a91fd",
   "metadata": {
    "_cell_guid": "7e27f391-4b1d-404c-af0f-032e3db59084",
    "_uuid": "682cbed9-f863-476c-a3d0-0d5d23213411",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T14:21:10.282521Z",
     "iopub.status.busy": "2021-09-19T14:21:10.281912Z",
     "iopub.status.idle": "2021-09-19T14:21:13.353312Z",
     "shell.execute_reply": "2021-09-19T14:21:13.353968Z",
     "shell.execute_reply.started": "2021-09-01T09:00:07.018918Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.108217,
     "end_time": "2021-09-19T14:21:13.354173",
     "exception": false,
     "start_time": "2021-09-19T14:21:10.245956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training set has 428932 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Read train and test\n",
    "train, test = read_train_test()\n",
    "\n",
    "# Get unique stock ids \n",
    "# train_stock_ids = train['stock_id'].unique()\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "# train_ = preprocessor(train_stock_ids, is_train = True)\n",
    "# train = train.merge(train_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get unique stock ids \n",
    "test_stock_ids = test['stock_id'].unique()\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "test_ = preprocessor(test_stock_ids, is_train = False)\n",
    "test = test.merge(test_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get group stats of time_id and stock_id \n",
    "# train = get_time_stock(train)  \n",
    "test = get_time_stock(test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca50d4f",
   "metadata": {
    "_cell_guid": "752ab3c0-d9be-40fc-8c0a-b2ec406289fa",
    "_uuid": "951a39e6-a4b0-41d4-ade9-f4d5d859d0a6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T14:21:13.474053Z",
     "iopub.status.busy": "2021-09-19T14:21:13.473163Z",
     "iopub.status.idle": "2021-09-19T14:21:13.475488Z",
     "shell.execute_reply": "2021-09-19T14:21:13.475920Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.06051,
     "end_time": "2021-09-19T14:21:13.476045",
     "exception": false,
     "start_time": "2021-09-19T14:21:13.415535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace by order sum (tau)\n",
    "# train['size_tau'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique'] )\n",
    "test['size_tau'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique'] )\n",
    "# train['size_tau_400'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_400'] )\n",
    "test['size_tau_400'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_400'] )\n",
    "# train['size_tau_300'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_300'] )\n",
    "test['size_tau_300'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_300'] )\n",
    "# train['size_tau_200'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_200'] )\n",
    "test['size_tau_200'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_200'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e6a58b7",
   "metadata": {
    "_cell_guid": "f8236f0e-db9a-4222-8c68-e1196e8009da",
    "_uuid": "172424a6-3ac3-44f0-9365-75cc32fbd25f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T14:21:13.556052Z",
     "iopub.status.busy": "2021-09-19T14:21:13.555201Z",
     "iopub.status.idle": "2021-09-19T14:21:13.558011Z",
     "shell.execute_reply": "2021-09-19T14:21:13.557558Z",
     "shell.execute_reply.started": "2021-08-31T15:14:54.895436Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.047019,
     "end_time": "2021-09-19T14:21:13.558112",
     "exception": false,
     "start_time": "2021-09-19T14:21:13.511093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train['size_tau2'] = np.sqrt( 1/ train['trade_order_count_sum'] )\n",
    "test['size_tau2'] = np.sqrt( 1/ test['trade_order_count_sum'] )\n",
    "# train['size_tau2_400'] = np.sqrt( 0.33/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_400'] = np.sqrt( 0.33/ test['trade_order_count_sum'] )\n",
    "# train['size_tau2_300'] = np.sqrt( 0.5/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_300'] = np.sqrt( 0.5/ test['trade_order_count_sum'] )\n",
    "# train['size_tau2_200'] = np.sqrt( 0.66/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_200'] = np.sqrt( 0.66/ test['trade_order_count_sum'] )\n",
    "\n",
    "\n",
    "# train['size_tau2_d'] = train['size_tau2_400'] - train['size_tau2']\n",
    "test['size_tau2_d'] = test['size_tau2_400'] - test['size_tau2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bfaa6b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:21:13.630177Z",
     "iopub.status.busy": "2021-09-19T14:21:13.629672Z",
     "iopub.status.idle": "2021-09-19T14:21:19.146823Z",
     "shell.execute_reply": "2021-09-19T14:21:19.145919Z"
    },
    "papermill": {
     "duration": 5.553376,
     "end_time": "2021-09-19T14:21:19.146970",
     "exception": false,
     "start_time": "2021-09-19T14:21:13.593594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"../input/traintestdata/train_lgb_hy13_090716_after_size_tau2_d.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28055b51",
   "metadata": {
    "_cell_guid": "01dd32c9-a254-44b1-a22d-b5d8258ecea0",
    "_uuid": "3cb65021-a5c9-44ba-9873-f6c201382e62",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T14:21:19.222755Z",
     "iopub.status.busy": "2021-09-19T14:21:19.221877Z",
     "iopub.status.idle": "2021-09-19T14:21:19.225717Z",
     "shell.execute_reply": "2021-09-19T14:21:19.226116Z",
     "shell.execute_reply.started": "2021-08-31T15:14:54.934394Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.045753,
     "end_time": "2021-09-19T14:21:19.226250",
     "exception": false,
     "start_time": "2021-09-19T14:21:19.180497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colNames = [col for col in list(train.columns) if col not in {\"stock_id\", \"time_id\", \"target\", \"row_id\"}]\n",
    "len(colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e74eb1e7",
   "metadata": {
    "_cell_guid": "7bb2399f-f980-4ab4-9555-9a16e8f6677d",
    "_uuid": "c58ba138-6eaa-41fd-8b96-098c8ba469ed",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T14:21:19.304056Z",
     "iopub.status.busy": "2021-09-19T14:21:19.303305Z",
     "iopub.status.idle": "2021-09-19T14:21:21.240446Z",
     "shell.execute_reply": "2021-09-19T14:21:21.241056Z",
     "shell.execute_reply.started": "2021-08-31T15:14:54.948483Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.980708,
     "end_time": "2021-09-19T14:21:21.241251",
     "exception": false,
     "start_time": "2021-09-19T14:21:19.260543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 4 2 1 1 2 4 6 2 1 0 4 4 1 1 1 2 4 4 4 0 1 1 3 1 1 4 3 4 3 4 4 1 3 3 4\n",
      " 3 4 1 4 1 4 4 1 0 4 4 1 0 0 3 3 3 2 0 2 4 1 4 4 1 4 1 0 3 3 0 3 0 6 5 3 3\n",
      " 0 1 2 0 3 3 3 4 1 1 0 2 3 3 1 0 1 4 4 4 4 4 1 3 1 0 1 4 1 0 1 4 1 0 4 0 4\n",
      " 0]\n",
      "[1, 11, 22, 50, 55, 56, 62, 73, 76, 78, 84, 87, 96, 101, 112, 116, 122, 124, 126]\n",
      "[0, 4, 5, 10, 15, 16, 17, 23, 26, 28, 29, 36, 42, 44, 48, 53, 66, 69, 72, 85, 94, 95, 100, 102, 109, 111, 113, 115, 118, 120]\n",
      "[3, 6, 9, 18, 61, 63, 86, 97]\n",
      "[27, 31, 33, 37, 38, 40, 58, 59, 60, 74, 75, 77, 82, 83, 88, 89, 90, 98, 99, 110]\n",
      "[2, 7, 13, 14, 19, 20, 21, 30, 32, 34, 35, 39, 41, 43, 46, 47, 51, 52, 64, 67, 68, 70, 93, 103, 104, 105, 107, 108, 114, 119, 123, 125]\n",
      "[81]\n",
      "[8, 80]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# making agg features\n",
    "\n",
    "train_p = pd.read_csv(f'{data_dir}/train.csv')\n",
    "train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "corr = train_p.corr()\n",
    "ids = corr.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "l = []\n",
    "for n in range(7):\n",
    "    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "    \n",
    "\n",
    "mat = []\n",
    "matTest = []\n",
    "\n",
    "n = 0\n",
    "for ind in l:\n",
    "    print(ind)\n",
    "    newDf = train.loc[train['stock_id'].isin(ind) ]\n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    mat.append ( newDf )\n",
    "    \n",
    "    newDf = test.loc[test['stock_id'].isin(ind) ]    \n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    matTest.append ( newDf )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "mat1 = pd.concat(mat).reset_index()\n",
    "mat1.drop(columns=['target'],inplace=True)\n",
    "\n",
    "mat2 = pd.concat(matTest).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed81ad82",
   "metadata": {
    "_cell_guid": "27870a1d-3d87-4f27-89f1-c51599103193",
    "_uuid": "fbbe0a85-9780-4878-92d6-fa6244afc7b5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T14:21:21.321850Z",
     "iopub.status.busy": "2021-09-19T14:21:21.321041Z",
     "iopub.status.idle": "2021-09-19T14:21:21.466904Z",
     "shell.execute_reply": "2021-09-19T14:21:21.467511Z",
     "shell.execute_reply.started": "2021-08-31T15:14:56.736126Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.189501,
     "end_time": "2021-09-19T14:21:21.467703",
     "exception": false,
     "start_time": "2021-09-19T14:21:21.278202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])\n",
    "mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "mat1.reset_index(inplace=True)\n",
    "\n",
    "mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "mat2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62dbcba6",
   "metadata": {
    "_cell_guid": "5f40f9bc-b5d6-4d47-b3b2-02d98cb6317c",
    "_uuid": "d1455822-0691-4f54-a8ee-1a224d16e047",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T14:21:21.549575Z",
     "iopub.status.busy": "2021-09-19T14:21:21.548725Z",
     "iopub.status.idle": "2021-09-19T14:21:29.153817Z",
     "shell.execute_reply": "2021-09-19T14:21:29.153321Z",
     "shell.execute_reply.started": "2021-08-31T15:14:56.87681Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 7.648987,
     "end_time": "2021-09-19T14:21:29.153963",
     "exception": false,
     "start_time": "2021-09-19T14:21:21.504976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nnn = ['time_id',\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_volume_sum_0c1',\n",
    "     'total_volume_sum_1c1', \n",
    "     'total_volume_sum_3c1',\n",
    "     'total_volume_sum_4c1', \n",
    "     'total_volume_sum_6c1',\n",
    "     'trade_size_sum_0c1',\n",
    "     'trade_size_sum_1c1', \n",
    "     'trade_size_sum_3c1',\n",
    "     'trade_size_sum_4c1', \n",
    "     'trade_size_sum_6c1',\n",
    "     'trade_order_count_sum_0c1',\n",
    "     'trade_order_count_sum_1c1',\n",
    "     'trade_order_count_sum_3c1',\n",
    "     'trade_order_count_sum_4c1',\n",
    "     'trade_order_count_sum_6c1',      \n",
    "     'price_spread_sum_0c1',\n",
    "     'price_spread_sum_1c1',\n",
    "     'price_spread_sum_3c1',\n",
    "     'price_spread_sum_4c1',\n",
    "     'price_spread_sum_6c1',   \n",
    "     'bid_spread_sum_0c1',\n",
    "     'bid_spread_sum_1c1',\n",
    "     'bid_spread_sum_3c1',\n",
    "     'bid_spread_sum_4c1',\n",
    "     'bid_spread_sum_6c1',       \n",
    "     'ask_spread_sum_0c1',\n",
    "     'ask_spread_sum_1c1',\n",
    "     'ask_spread_sum_3c1',\n",
    "     'ask_spread_sum_4c1',\n",
    "     'ask_spread_sum_6c1',   \n",
    "     'volume_imbalance_sum_0c1',\n",
    "     'volume_imbalance_sum_1c1',\n",
    "     'volume_imbalance_sum_3c1',\n",
    "     'volume_imbalance_sum_4c1',\n",
    "     'volume_imbalance_sum_6c1',       \n",
    "     'bid_ask_spread_sum_0c1',\n",
    "     'bid_ask_spread_sum_1c1',\n",
    "     'bid_ask_spread_sum_3c1',\n",
    "     'bid_ask_spread_sum_4c1',\n",
    "     'bid_ask_spread_sum_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1'] \n",
    "train = pd.merge(train,mat1[nnn],how='left',on='time_id')\n",
    "test = pd.merge(test,mat2[nnn],how='left',on='time_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c20a1560",
   "metadata": {
    "_cell_guid": "96e87fb0-46a5-4857-b111-213cfe46fa10",
    "_uuid": "ba3cf7cb-9625-4489-a005-c80e08ed1f59",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T14:21:29.333829Z",
     "iopub.status.busy": "2021-09-19T14:21:29.333005Z",
     "iopub.status.idle": "2021-09-19T14:21:29.336297Z",
     "shell.execute_reply": "2021-09-19T14:21:29.336701Z",
     "shell.execute_reply.started": "2021-08-31T15:15:07.514163Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.14779,
     "end_time": "2021-09-19T14:21:29.336845",
     "exception": false,
     "start_time": "2021-09-19T14:21:29.189055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del mat1,mat2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb309dfa",
   "metadata": {
    "_cell_guid": "4385d7ed-6e8a-496c-84ec-8c2c8525c96f",
    "_uuid": "970c77e5-afd7-4fa3-a4de-8eccbceced90",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T14:21:29.421620Z",
     "iopub.status.busy": "2021-09-19T14:21:29.420879Z",
     "iopub.status.idle": "2021-09-19T15:13:17.589878Z",
     "shell.execute_reply": "2021-09-19T15:13:17.589440Z",
     "shell.execute_reply.started": "2021-08-31T15:15:07.630173Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3108.217153,
     "end_time": "2021-09-19T15:13:17.590000",
     "exception": false,
     "start_time": "2021-09-19T14:21:29.372847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000435956\ttraining's RMSPE: 0.20162\tvalid_1's rmse: 0.000448012\tvalid_1's RMSPE: 0.207942\n",
      "[500]\ttraining's rmse: 0.000405925\ttraining's RMSPE: 0.187732\tvalid_1's rmse: 0.000426544\tvalid_1's RMSPE: 0.197977\n",
      "[750]\ttraining's rmse: 0.000389658\ttraining's RMSPE: 0.180209\tvalid_1's rmse: 0.000417402\tvalid_1's RMSPE: 0.193734\n",
      "[1000]\ttraining's rmse: 0.000377986\ttraining's RMSPE: 0.174811\tvalid_1's rmse: 0.000412057\tvalid_1's RMSPE: 0.191254\n",
      "[1250]\ttraining's rmse: 0.000369059\ttraining's RMSPE: 0.170682\tvalid_1's rmse: 0.000408907\tvalid_1's RMSPE: 0.189792\n",
      "[1500]\ttraining's rmse: 0.000361535\ttraining's RMSPE: 0.167202\tvalid_1's rmse: 0.000406688\tvalid_1's RMSPE: 0.188762\n",
      "[1750]\ttraining's rmse: 0.000354832\ttraining's RMSPE: 0.164102\tvalid_1's rmse: 0.000405079\tvalid_1's RMSPE: 0.188015\n",
      "[2000]\ttraining's rmse: 0.000348995\ttraining's RMSPE: 0.161403\tvalid_1's rmse: 0.000403892\tvalid_1's RMSPE: 0.187464\n",
      "[2250]\ttraining's rmse: 0.000343695\ttraining's RMSPE: 0.158952\tvalid_1's rmse: 0.000403382\tvalid_1's RMSPE: 0.187227\n",
      "[2500]\ttraining's rmse: 0.000338734\ttraining's RMSPE: 0.156657\tvalid_1's rmse: 0.000402717\tvalid_1's RMSPE: 0.186919\n",
      "[2750]\ttraining's rmse: 0.000334086\ttraining's RMSPE: 0.154508\tvalid_1's rmse: 0.000402295\tvalid_1's RMSPE: 0.186723\n",
      "[3000]\ttraining's rmse: 0.000329802\ttraining's RMSPE: 0.152527\tvalid_1's rmse: 0.000401994\tvalid_1's RMSPE: 0.186583\n",
      "Early stopping, best iteration is:\n",
      "[3138]\ttraining's rmse: 0.000327435\ttraining's RMSPE: 0.151432\tvalid_1's rmse: 0.00040171\tvalid_1's RMSPE: 0.186451\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000435377\ttraining's RMSPE: 0.201705\tvalid_1's rmse: 0.000448008\tvalid_1's RMSPE: 0.20649\n",
      "[500]\ttraining's rmse: 0.000405548\ttraining's RMSPE: 0.187886\tvalid_1's rmse: 0.000426368\tvalid_1's RMSPE: 0.196516\n",
      "[750]\ttraining's rmse: 0.000389095\ttraining's RMSPE: 0.180263\tvalid_1's rmse: 0.000416909\tvalid_1's RMSPE: 0.192156\n",
      "[1000]\ttraining's rmse: 0.000377653\ttraining's RMSPE: 0.174962\tvalid_1's rmse: 0.000411921\tvalid_1's RMSPE: 0.189857\n",
      "[1250]\ttraining's rmse: 0.000368309\ttraining's RMSPE: 0.170633\tvalid_1's rmse: 0.000408292\tvalid_1's RMSPE: 0.188185\n",
      "[1500]\ttraining's rmse: 0.000360686\ttraining's RMSPE: 0.167101\tvalid_1's rmse: 0.000406027\tvalid_1's RMSPE: 0.187141\n",
      "[1750]\ttraining's rmse: 0.000354166\ttraining's RMSPE: 0.164081\tvalid_1's rmse: 0.000404733\tvalid_1's RMSPE: 0.186544\n",
      "[2000]\ttraining's rmse: 0.000348083\ttraining's RMSPE: 0.161262\tvalid_1's rmse: 0.000403449\tvalid_1's RMSPE: 0.185952\n",
      "[2250]\ttraining's rmse: 0.000342855\ttraining's RMSPE: 0.158841\tvalid_1's rmse: 0.000402691\tvalid_1's RMSPE: 0.185603\n",
      "[2500]\ttraining's rmse: 0.000337856\ttraining's RMSPE: 0.156525\tvalid_1's rmse: 0.000402187\tvalid_1's RMSPE: 0.185371\n",
      "[2750]\ttraining's rmse: 0.000333197\ttraining's RMSPE: 0.154366\tvalid_1's rmse: 0.000401813\tvalid_1's RMSPE: 0.185198\n",
      "[3000]\ttraining's rmse: 0.000328831\ttraining's RMSPE: 0.152343\tvalid_1's rmse: 0.000401396\tvalid_1's RMSPE: 0.185006\n",
      "[3250]\ttraining's rmse: 0.000324592\ttraining's RMSPE: 0.150379\tvalid_1's rmse: 0.000401103\tvalid_1's RMSPE: 0.184871\n",
      "Early stopping, best iteration is:\n",
      "[3442]\ttraining's rmse: 0.000321551\ttraining's RMSPE: 0.148971\tvalid_1's rmse: 0.000400921\tvalid_1's RMSPE: 0.184788\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000435919\ttraining's RMSPE: 0.201596\tvalid_1's rmse: 0.000480324\tvalid_1's RMSPE: 0.22297\n",
      "[500]\ttraining's rmse: 0.000406411\ttraining's RMSPE: 0.18795\tvalid_1's rmse: 0.000459122\tvalid_1's RMSPE: 0.213128\n",
      "[750]\ttraining's rmse: 0.000390031\ttraining's RMSPE: 0.180375\tvalid_1's rmse: 0.000451133\tvalid_1's RMSPE: 0.20942\n",
      "[1000]\ttraining's rmse: 0.000378407\ttraining's RMSPE: 0.174999\tvalid_1's rmse: 0.000445808\tvalid_1's RMSPE: 0.206948\n",
      "[1250]\ttraining's rmse: 0.000368888\ttraining's RMSPE: 0.170597\tvalid_1's rmse: 0.00044275\tvalid_1's RMSPE: 0.205528\n",
      "[1500]\ttraining's rmse: 0.000361061\ttraining's RMSPE: 0.166977\tvalid_1's rmse: 0.000441565\tvalid_1's RMSPE: 0.204978\n",
      "Early stopping, best iteration is:\n",
      "[1481]\ttraining's rmse: 0.000361591\ttraining's RMSPE: 0.167222\tvalid_1's rmse: 0.000441405\tvalid_1's RMSPE: 0.204904\n",
      "Training fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000434907\ttraining's RMSPE: 0.201488\tvalid_1's rmse: 0.000450979\tvalid_1's RMSPE: 0.207858\n",
      "[500]\ttraining's rmse: 0.000405714\ttraining's RMSPE: 0.187963\tvalid_1's rmse: 0.000429848\tvalid_1's RMSPE: 0.198118\n",
      "[750]\ttraining's rmse: 0.00038921\ttraining's RMSPE: 0.180316\tvalid_1's rmse: 0.000420619\tvalid_1's RMSPE: 0.193865\n",
      "[1000]\ttraining's rmse: 0.00037737\ttraining's RMSPE: 0.174831\tvalid_1's rmse: 0.000415483\tvalid_1's RMSPE: 0.191497\n",
      "[1250]\ttraining's rmse: 0.000368313\ttraining's RMSPE: 0.170635\tvalid_1's rmse: 0.000412771\tvalid_1's RMSPE: 0.190248\n",
      "[1500]\ttraining's rmse: 0.000360834\ttraining's RMSPE: 0.167171\tvalid_1's rmse: 0.000411042\tvalid_1's RMSPE: 0.189451\n",
      "[1750]\ttraining's rmse: 0.000354224\ttraining's RMSPE: 0.164108\tvalid_1's rmse: 0.000409676\tvalid_1's RMSPE: 0.188821\n",
      "[2000]\ttraining's rmse: 0.000348444\ttraining's RMSPE: 0.16143\tvalid_1's rmse: 0.000408915\tvalid_1's RMSPE: 0.18847\n",
      "[2250]\ttraining's rmse: 0.000343167\ttraining's RMSPE: 0.158986\tvalid_1's rmse: 0.000408353\tvalid_1's RMSPE: 0.188211\n",
      "[2500]\ttraining's rmse: 0.000338255\ttraining's RMSPE: 0.15671\tvalid_1's rmse: 0.000407949\tvalid_1's RMSPE: 0.188025\n",
      "Early stopping, best iteration is:\n",
      "[2609]\ttraining's rmse: 0.000336109\ttraining's RMSPE: 0.155716\tvalid_1's rmse: 0.00040781\tvalid_1's RMSPE: 0.187961\n",
      "Training fold 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.0004361\ttraining's RMSPE: 0.201715\tvalid_1's rmse: 0.000448378\tvalid_1's RMSPE: 0.207998\n",
      "[500]\ttraining's rmse: 0.000406357\ttraining's RMSPE: 0.187958\tvalid_1's rmse: 0.00042734\tvalid_1's RMSPE: 0.198238\n",
      "[750]\ttraining's rmse: 0.000389992\ttraining's RMSPE: 0.180388\tvalid_1's rmse: 0.000418522\tvalid_1's RMSPE: 0.194147\n",
      "[1000]\ttraining's rmse: 0.000378688\ttraining's RMSPE: 0.17516\tvalid_1's rmse: 0.000414351\tvalid_1's RMSPE: 0.192213\n",
      "[1250]\ttraining's rmse: 0.000369742\ttraining's RMSPE: 0.171022\tvalid_1's rmse: 0.000411476\tvalid_1's RMSPE: 0.190879\n",
      "[1500]\ttraining's rmse: 0.000362156\ttraining's RMSPE: 0.167513\tvalid_1's rmse: 0.000410103\tvalid_1's RMSPE: 0.190242\n",
      "[1750]\ttraining's rmse: 0.000355509\ttraining's RMSPE: 0.164438\tvalid_1's rmse: 0.00040899\tvalid_1's RMSPE: 0.189726\n",
      "[2000]\ttraining's rmse: 0.000349432\ttraining's RMSPE: 0.161628\tvalid_1's rmse: 0.000408316\tvalid_1's RMSPE: 0.189413\n",
      "Early stopping, best iteration is:\n",
      "[1985]\ttraining's rmse: 0.000349783\ttraining's RMSPE: 0.16179\tvalid_1's rmse: 0.000408255\tvalid_1's RMSPE: 0.189385\n",
      "Our out of folds RMSPE is 0.1908359582734313\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "seed0=2021\n",
    "# params0 = {\n",
    "#     'objective': 'rmse',\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'max_depth': -1,\n",
    "#     'max_bin':100,\n",
    "#     'min_data_in_leaf':500,\n",
    "#     'learning_rate': 0.05,\n",
    "#     'subsample': 0.72,\n",
    "#     'subsample_freq': 4,\n",
    "#     'feature_fraction': 0.5,\n",
    "#     'lambda_l1': 0.5,\n",
    "#     'lambda_l2': 1.0,\n",
    "#     'categorical_column':[0],\n",
    "#     'seed':seed0,\n",
    "#     'feature_fraction_seed': seed0,\n",
    "#     'bagging_seed': seed0,\n",
    "#     'drop_seed': seed0,\n",
    "#     'data_random_seed': seed0,\n",
    "#     'n_jobs':-1,\n",
    "#     'verbose': -1}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate_lgb(train, test, params):\n",
    "    # Hyperparammeters (just basic)\n",
    "    \n",
    "    features = [col for col in train.columns if col not in {\"time_id\", \"target\", \"row_id\"}]\n",
    "    y = train['target']\n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(train.shape[0])\n",
    "    # Create test array to store predictions\n",
    "    test_predictions = np.zeros(test.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = KFold(n_splits = 5, random_state = 2021, shuffle = True)\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = train.iloc[trn_ind], train.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        # Root mean squared percentage error weights\n",
    "        train_weights = 1 / np.square(y_train)\n",
    "        val_weights = 1 / np.square(y_val)\n",
    "        train_dataset = lgb.Dataset(x_train[features], y_train, weight = train_weights)\n",
    "        val_dataset = lgb.Dataset(x_val[features], y_val, weight = val_weights)\n",
    "        model = lgb.train(params = params,\n",
    "                          num_boost_round=30000,\n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          verbose_eval = 250,\n",
    "                          early_stopping_rounds=50,\n",
    "                          feval = feval_rmspe)\n",
    "        # Add predictions to the out of folds array\n",
    "        oof_predictions[val_ind] = model.predict(x_val[features])\n",
    "        # Predict the test set\n",
    "        test_predictions += model.predict(test[features]) / 5\n",
    "    rmspe_score = rmspe(y, oof_predictions)\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    lgb.plot_importance(model,max_num_features=20)\n",
    "    # Return test predictions\n",
    "    return test_predictions\n",
    "# Traing and evaluate\n",
    "predictions_lgb= train_and_evaluate_lgb(train, test,params0) \n",
    "test['target'] = predictions_lgb\n",
    "test[['row_id', 'target']].to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e0326d2",
   "metadata": {
    "_cell_guid": "7ed80701-93fe-4f67-9e56-b81e96f87771",
    "_uuid": "00f3cc82-29bb-4ca9-8dde-e485c6fc5bf7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T15:13:17.701685Z",
     "iopub.status.busy": "2021-09-19T15:13:17.701145Z",
     "iopub.status.idle": "2021-09-19T15:13:17.706677Z",
     "shell.execute_reply": "2021-09-19T15:13:17.706267Z",
     "shell.execute_reply.started": "2021-08-31T15:56:49.202798Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.062733,
     "end_time": "2021-09-19T15:13:17.706786",
     "exception": false,
     "start_time": "2021-09-19T15:13:17.644053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f2483e",
   "metadata": {
    "papermill": {
     "duration": 0.053693,
     "end_time": "2021-09-19T15:13:17.813951",
     "exception": false,
     "start_time": "2021-09-19T15:13:17.760258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00eb0627",
   "metadata": {
    "_cell_guid": "11a4c5fb-cb46-40c9-bd5a-e700c50dfa51",
    "_uuid": "01fc824d-2d8f-451c-873b-80e8f51c2629",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T15:13:17.928033Z",
     "iopub.status.busy": "2021-09-19T15:13:17.927408Z",
     "iopub.status.idle": "2021-09-19T15:13:22.059342Z",
     "shell.execute_reply": "2021-09-19T15:13:22.058413Z",
     "shell.execute_reply.started": "2021-08-31T15:56:49.211961Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.191822,
     "end_time": "2021-09-19T15:13:22.059515",
     "exception": false,
     "start_time": "2021-09-19T15:13:17.867693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "def root_mean_squared_per_error(y_true, y_pred):\n",
    "         return K.sqrt(K.mean(K.square( (y_true - y_pred)/ y_true )))\n",
    "    \n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, verbose=0,\n",
    "    mode='min',restore_best_weights=True)\n",
    "\n",
    "plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.2, patience=7, verbose=0,\n",
    "    mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d35dbb70",
   "metadata": {
    "_cell_guid": "2fd93222-9c45-419b-816c-747b1fa8b682",
    "_uuid": "19630c75-0fc8-4aaa-86e4-e7ec9a0cb080",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T15:13:22.194278Z",
     "iopub.status.busy": "2021-09-19T15:13:22.193671Z",
     "iopub.status.idle": "2021-09-19T15:13:30.630086Z",
     "shell.execute_reply": "2021-09-19T15:13:30.629560Z",
     "shell.execute_reply.started": "2021-08-31T15:56:56.402142Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 8.513119,
     "end_time": "2021-09-19T15:13:30.630226",
     "exception": false,
     "start_time": "2021-09-19T15:13:22.117107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kfold based on the knn++ algorithm\n",
    "\n",
    "out_train = pd.read_csv(f'{data_dir}/train.csv')\n",
    "out_train = out_train.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "#out_train[out_train.isna().any(axis=1)]\n",
    "out_train = out_train.fillna(out_train.mean())\n",
    "out_train.head()\n",
    "\n",
    "# code to add the just the read data after first execution\n",
    "\n",
    "# data separation based on knn ++\n",
    "nfolds = 5 # number of folds\n",
    "index = []\n",
    "totDist = []\n",
    "values = []\n",
    "# generates a matriz with the values of \n",
    "mat = out_train.values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "mat = scaler.fit_transform(mat)\n",
    "\n",
    "nind = int(mat.shape[0]/nfolds) # number of individuals\n",
    "\n",
    "# adds index in the last column\n",
    "mat = np.c_[mat,np.arange(mat.shape[0])]\n",
    "\n",
    "\n",
    "lineNumber = np.random.choice(np.array(mat.shape[0]), size=nfolds, replace=False)\n",
    "\n",
    "lineNumber = np.sort(lineNumber)[::-1]\n",
    "\n",
    "for n in range(nfolds):\n",
    "    totDist.append(np.zeros(mat.shape[0]-nfolds))\n",
    "\n",
    "# saves index\n",
    "for n in range(nfolds):\n",
    "    \n",
    "    values.append([lineNumber[n]])    \n",
    "\n",
    "\n",
    "s=[]\n",
    "for n in range(nfolds):\n",
    "    s.append(mat[lineNumber[n],:])\n",
    "    \n",
    "    mat = np.delete(mat, obj=lineNumber[n], axis=0)\n",
    "\n",
    "for n in range(nind-1):    \n",
    "\n",
    "    luck = np.random.uniform(0,1,nfolds)\n",
    "    \n",
    "    for cycle in range(nfolds):\n",
    "         # saves the values of index           \n",
    "\n",
    "        s[cycle] = np.matlib.repmat(s[cycle], mat.shape[0], 1)\n",
    "\n",
    "        sumDist = np.sum( (mat[:,:-1] - s[cycle][:,:-1])**2 , axis=1)   \n",
    "        totDist[cycle] += sumDist        \n",
    "                \n",
    "        # probabilities\n",
    "        f = totDist[cycle]/np.sum(totDist[cycle]) # normalizing the totdist\n",
    "        j = 0\n",
    "        kn = 0\n",
    "        for val in f:\n",
    "            j += val        \n",
    "            if (j > luck[cycle]): # the column was selected\n",
    "                break\n",
    "            kn +=1\n",
    "        lineNumber[cycle] = kn\n",
    "        \n",
    "        # delete line of the value added    \n",
    "        for n_iter in range(nfolds):\n",
    "            \n",
    "            totDist[n_iter] = np.delete(totDist[n_iter],obj=lineNumber[cycle], axis=0)\n",
    "            j= 0\n",
    "        \n",
    "        s[cycle] = mat[lineNumber[cycle],:]\n",
    "        values[cycle].append(int(mat[lineNumber[cycle],-1]))\n",
    "        mat = np.delete(mat, obj=lineNumber[cycle], axis=0)\n",
    "\n",
    "\n",
    "for n_mod in range(nfolds):\n",
    "    values[n_mod] = out_train.index[values[n_mod]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54923c1b",
   "metadata": {
    "_cell_guid": "1798d10c-8cb0-4101-9601-fa4c5b3741ad",
    "_uuid": "89b3bd20-b63e-49c8-9a70-f85e29c8c7f5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T15:13:30.746910Z",
     "iopub.status.busy": "2021-09-19T15:13:30.745468Z",
     "iopub.status.idle": "2021-09-19T15:13:54.525410Z",
     "shell.execute_reply": "2021-09-19T15:13:54.524919Z",
     "shell.execute_reply.started": "2021-08-31T15:57:09.206423Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 23.84051,
     "end_time": "2021-09-19T15:13:54.525568",
     "exception": false,
     "start_time": "2021-09-19T15:13:30.685058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#colNames.remove('row_id')\n",
    "train.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "test.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "qt_train = []\n",
    "train_nn=train[colNames].copy()\n",
    "test_nn=test[colNames].copy()\n",
    "for col in colNames:\n",
    "    #print(col)\n",
    "    qt = QuantileTransformer(random_state=21,n_quantiles=2000, output_distribution='normal')\n",
    "    train_nn[col] = qt.fit_transform(train_nn[[col]])\n",
    "    test_nn[col] = qt.transform(test_nn[[col]])    \n",
    "    qt_train.append(qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec44aa35",
   "metadata": {
    "_cell_guid": "b6cff8d8-1456-41b5-8668-b311de3725d8",
    "_uuid": "6cf7c998-e056-410a-892a-102ad7741889",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T15:13:54.641729Z",
     "iopub.status.busy": "2021-09-19T15:13:54.640497Z",
     "iopub.status.idle": "2021-09-19T15:13:54.648075Z",
     "shell.execute_reply": "2021-09-19T15:13:54.647639Z",
     "shell.execute_reply.started": "2021-08-31T15:57:48.14844Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.068169,
     "end_time": "2021-09-19T15:13:54.648185",
     "exception": false,
     "start_time": "2021-09-19T15:13:54.580016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_nn[['stock_id','time_id','target']]=train[['stock_id','time_id','target']]\n",
    "test_nn[['stock_id','time_id']]=test[['stock_id','time_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5eb04cf",
   "metadata": {
    "_cell_guid": "7028bfbb-6f6a-4d02-a962-173438704b44",
    "_uuid": "0dac85b1-1a3a-4ffd-b649-46481220227f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T15:13:54.765057Z",
     "iopub.status.busy": "2021-09-19T15:13:54.764524Z",
     "iopub.status.idle": "2021-09-19T15:13:56.258031Z",
     "shell.execute_reply": "2021-09-19T15:13:56.257575Z",
     "shell.execute_reply.started": "2021-08-31T15:57:48.169947Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.556121,
     "end_time": "2021-09-19T15:13:56.258161",
     "exception": false,
     "start_time": "2021-09-19T15:13:54.702040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 4 2 1 1 2 4 6 2 1 0 4 4 1 1 1 2 4 4 4 0 1 1 3 1 1 4 3 4 3 4 4 1 3 3 4\n",
      " 3 4 1 4 1 4 4 1 0 4 4 1 0 0 3 3 3 2 0 2 4 1 4 4 1 4 1 0 3 3 0 3 0 6 5 3 3\n",
      " 0 1 2 0 3 3 3 4 1 1 0 2 3 3 1 0 1 4 4 4 4 4 1 3 1 0 1 4 1 0 1 4 1 0 4 0 4\n",
      " 0]\n",
      "[1, 11, 22, 50, 55, 56, 62, 73, 76, 78, 84, 87, 96, 101, 112, 116, 122, 124, 126]\n",
      "[0, 4, 5, 10, 15, 16, 17, 23, 26, 28, 29, 36, 42, 44, 48, 53, 66, 69, 72, 85, 94, 95, 100, 102, 109, 111, 113, 115, 118, 120]\n",
      "[3, 6, 9, 18, 61, 63, 86, 97]\n",
      "[27, 31, 33, 37, 38, 40, 58, 59, 60, 74, 75, 77, 82, 83, 88, 89, 90, 98, 99, 110]\n",
      "[2, 7, 13, 14, 19, 20, 21, 30, 32, 34, 35, 39, 41, 43, 46, 47, 51, 52, 64, 67, 68, 70, 93, 103, 104, 105, 107, 108, 114, 119, 123, 125]\n",
      "[81]\n",
      "[8, 80]\n"
     ]
    }
   ],
   "source": [
    "# making agg features\n",
    "from sklearn.cluster import KMeans\n",
    "train_p = pd.read_csv(f'{data_dir}/train.csv')\n",
    "train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "corr = train_p.corr()\n",
    "\n",
    "ids = corr.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "l = []\n",
    "for n in range(7):\n",
    "    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "     \n",
    "\n",
    "mat = []\n",
    "matTest = []\n",
    "\n",
    "n = 0\n",
    "for ind in l:\n",
    "    print(ind)\n",
    "    newDf = train_nn.loc[train_nn['stock_id'].isin(ind) ]\n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    mat.append ( newDf )\n",
    "    \n",
    "    newDf = test_nn.loc[test_nn['stock_id'].isin(ind) ]    \n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    matTest.append ( newDf )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "mat1 = pd.concat(mat).reset_index()\n",
    "mat1.drop(columns=['target'],inplace=True)\n",
    "\n",
    "mat2 = pd.concat(matTest).reset_index()\n",
    "mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7237b22a",
   "metadata": {
    "_cell_guid": "af91e146-a98a-48af-b631-1cb36257a31b",
    "_uuid": "9ab787de-2582-40dd-bb33-2a615f7f4638",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T15:13:56.374359Z",
     "iopub.status.busy": "2021-09-19T15:13:56.373098Z",
     "iopub.status.idle": "2021-09-19T15:13:56.375450Z",
     "shell.execute_reply": "2021-09-19T15:13:56.375910Z",
     "shell.execute_reply.started": "2021-08-31T15:57:49.41425Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.063102,
     "end_time": "2021-09-19T15:13:56.376037",
     "exception": false,
     "start_time": "2021-09-19T15:13:56.312935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nnn = ['time_id',\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_volume_sum_0c1',\n",
    "     'total_volume_sum_1c1', \n",
    "     'total_volume_sum_3c1',\n",
    "     'total_volume_sum_4c1', \n",
    "     'total_volume_sum_6c1',\n",
    "     'trade_size_sum_0c1',\n",
    "     'trade_size_sum_1c1', \n",
    "     'trade_size_sum_3c1',\n",
    "     'trade_size_sum_4c1', \n",
    "     'trade_size_sum_6c1',\n",
    "     'trade_order_count_sum_0c1',\n",
    "     'trade_order_count_sum_1c1',\n",
    "     'trade_order_count_sum_3c1',\n",
    "     'trade_order_count_sum_4c1',\n",
    "     'trade_order_count_sum_6c1',      \n",
    "     'price_spread_sum_0c1',\n",
    "     'price_spread_sum_1c1',\n",
    "     'price_spread_sum_3c1',\n",
    "     'price_spread_sum_4c1',\n",
    "     'price_spread_sum_6c1',   \n",
    "     'bid_spread_sum_0c1',\n",
    "     'bid_spread_sum_1c1',\n",
    "     'bid_spread_sum_3c1',\n",
    "     'bid_spread_sum_4c1',\n",
    "     'bid_spread_sum_6c1',       \n",
    "     'ask_spread_sum_0c1',\n",
    "     'ask_spread_sum_1c1',\n",
    "     'ask_spread_sum_3c1',\n",
    "     'ask_spread_sum_4c1',\n",
    "     'ask_spread_sum_6c1',   \n",
    "     'volume_imbalance_sum_0c1',\n",
    "     'volume_imbalance_sum_1c1',\n",
    "     'volume_imbalance_sum_3c1',\n",
    "     'volume_imbalance_sum_4c1',\n",
    "     'volume_imbalance_sum_6c1',       \n",
    "     'bid_ask_spread_sum_0c1',\n",
    "     'bid_ask_spread_sum_1c1',\n",
    "     'bid_ask_spread_sum_3c1',\n",
    "     'bid_ask_spread_sum_4c1',\n",
    "     'bid_ask_spread_sum_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4f88ca1",
   "metadata": {
    "_cell_guid": "244e2ddf-e16d-4c90-82fb-e3a3a09a9407",
    "_uuid": "5b440e21-ab60-4320-87dc-edcd5fccb172",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T15:13:56.533342Z",
     "iopub.status.busy": "2021-09-19T15:13:56.531672Z",
     "iopub.status.idle": "2021-09-19T15:13:56.686639Z",
     "shell.execute_reply": "2021-09-19T15:13:56.687056Z",
     "shell.execute_reply.started": "2021-08-31T15:57:49.42471Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.216416,
     "end_time": "2021-09-19T15:13:56.687203",
     "exception": false,
     "start_time": "2021-09-19T15:13:56.470787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "mat1.reset_index(inplace=True)\n",
    "\n",
    "mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "mat2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1a2c1d2",
   "metadata": {
    "_cell_guid": "c5e264ce-4964-4f11-b015-92cb7140b125",
    "_uuid": "596b8974-9406-4721-aa4d-f3864f7ae418",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T15:13:56.807324Z",
     "iopub.status.busy": "2021-09-19T15:13:56.806528Z",
     "iopub.status.idle": "2021-09-19T15:14:01.566446Z",
     "shell.execute_reply": "2021-09-19T15:14:01.565924Z",
     "shell.execute_reply.started": "2021-08-31T15:57:49.598947Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.820818,
     "end_time": "2021-09-19T15:14:01.566640",
     "exception": false,
     "start_time": "2021-09-19T15:13:56.745822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "train_nn = pd.merge(train_nn,mat1[nnn],how='left',on='time_id')\n",
    "test_nn = pd.merge(test_nn,mat2[nnn],how='left',on='time_id')\n",
    "del mat1,mat2\n",
    "del train,test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34aba2a5",
   "metadata": {
    "_cell_guid": "e3b64b2b-338e-4b46-865f-4a09b26b57a1",
    "_uuid": "d7a5d2f8-cee3-4200-9155-f4a0cff53e79",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T15:14:01.691300Z",
     "iopub.status.busy": "2021-09-19T15:14:01.690547Z",
     "iopub.status.idle": "2021-09-19T15:14:01.704266Z",
     "shell.execute_reply": "2021-09-19T15:14:01.703861Z",
     "shell.execute_reply.started": "2021-08-31T15:57:58.834079Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.078749,
     "end_time": "2021-09-19T15:14:01.704375",
     "exception": false,
     "start_time": "2021-09-19T15:14:01.625626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://bignerdranch.com/blog/implementing-swish-activation-function-in-keras/\n",
    "from keras.backend import sigmoid\n",
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "hidden_units = (128, 64, 32, 16) #### (128,64,32)\n",
    "stock_embedding_size = 16 #### 24\n",
    "\n",
    "cat_data = train_nn['stock_id']\n",
    "\n",
    "def base_model():\n",
    "    \n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    stock_id_input = keras.Input(shape=(1,), name='stock_id')\n",
    "    num_input = keras.Input(shape=(244,), name='num_data')\n",
    "\n",
    "\n",
    "    #embedding, flatenning and concatenating\n",
    "    stock_embedded = keras.layers.Embedding(max(cat_data)+1, stock_embedding_size, \n",
    "                                           input_length=1, name='stock_embedding')(stock_id_input)\n",
    "    stock_flattened = keras.layers.Flatten()(stock_embedded)\n",
    "    out = keras.layers.Concatenate()([stock_flattened, num_input])\n",
    "    \n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "\n",
    "        out = keras.layers.Dense(n_hidden, activation='swish')(out)\n",
    "        \n",
    "\n",
    "    #out = keras.layers.Concatenate()([out, num_input])\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = keras.layers.Dense(1, activation='linear', name='prediction')(out)\n",
    "    \n",
    "    model = keras.Model(\n",
    "    inputs = [stock_id_input, num_input],\n",
    "    outputs = out,\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2aafc900",
   "metadata": {
    "_cell_guid": "5c69adb0-b65d-4472-9ad8-2a698ad5bb82",
    "_uuid": "426c6450-1f00-487f-a73b-ab4967c07319",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-09-19T15:14:01.834231Z",
     "iopub.status.busy": "2021-09-19T15:14:01.832572Z",
     "iopub.status.idle": "2021-09-19T15:19:00.858062Z",
     "shell.execute_reply": "2021-09-19T15:19:00.857204Z",
     "shell.execute_reply.started": "2021-08-31T15:57:58.874816Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 299.098713,
     "end_time": "2021-09-19T15:19:00.858200",
     "exception": false,
     "start_time": "2021-09-19T15:14:01.759487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 1/5\n",
      "Epoch 1/500\n",
      "168/168 [==============================] - 3s 9ms/step - loss: 16.7134 - val_loss: 0.3556\n",
      "Epoch 2/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6481 - val_loss: 0.6331\n",
      "Epoch 3/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5910 - val_loss: 0.8604\n",
      "Epoch 4/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.7251 - val_loss: 0.6956\n",
      "Epoch 5/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6347 - val_loss: 0.7598\n",
      "Epoch 6/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5859 - val_loss: 0.5752\n",
      "Epoch 7/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5397 - val_loss: 0.5992\n",
      "Epoch 8/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4960 - val_loss: 0.4779\n",
      "Epoch 9/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2533 - val_loss: 0.2147\n",
      "Epoch 10/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2172 - val_loss: 0.2170\n",
      "Epoch 11/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2165 - val_loss: 0.2155\n",
      "Epoch 12/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2162 - val_loss: 0.2156\n",
      "Epoch 13/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2159 - val_loss: 0.2122\n",
      "Epoch 14/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2140 - val_loss: 0.2289\n",
      "Epoch 15/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2178 - val_loss: 0.2158\n",
      "Epoch 16/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2165 - val_loss: 0.2196\n",
      "Epoch 17/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2165 - val_loss: 0.2121\n",
      "Epoch 18/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2151 - val_loss: 0.2182\n",
      "Epoch 19/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2135 - val_loss: 0.2145\n",
      "Epoch 20/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2145 - val_loss: 0.2179\n",
      "Epoch 21/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2136 - val_loss: 0.2346\n",
      "Epoch 22/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2156 - val_loss: 0.2123\n",
      "Epoch 23/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2216 - val_loss: 0.2272\n",
      "Epoch 24/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2460 - val_loss: 0.2300\n",
      "Epoch 25/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2172 - val_loss: 0.2100\n",
      "Epoch 26/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2087 - val_loss: 0.2102\n",
      "Epoch 27/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2081 - val_loss: 0.2098\n",
      "Epoch 28/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2077 - val_loss: 0.2095\n",
      "Epoch 29/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2075 - val_loss: 0.2106\n",
      "Epoch 30/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2071 - val_loss: 0.2094\n",
      "Epoch 31/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2077 - val_loss: 0.2110\n",
      "Epoch 32/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2072 - val_loss: 0.2106\n",
      "Epoch 33/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2074 - val_loss: 0.2099\n",
      "Epoch 34/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2067 - val_loss: 0.2098\n",
      "Epoch 35/500\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.2064 - val_loss: 0.2092\n",
      "Epoch 36/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2075 - val_loss: 0.2098\n",
      "Epoch 37/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2065 - val_loss: 0.2108\n",
      "Epoch 38/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2070 - val_loss: 0.2097\n",
      "Epoch 39/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2084 - val_loss: 0.2143\n",
      "Epoch 40/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2081 - val_loss: 0.2103\n",
      "Epoch 41/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2084 - val_loss: 0.2098\n",
      "Epoch 42/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2072 - val_loss: 0.2174\n",
      "Epoch 43/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2070 - val_loss: 0.2087\n",
      "Epoch 44/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2052 - val_loss: 0.2092\n",
      "Epoch 45/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2049 - val_loss: 0.2087\n",
      "Epoch 46/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2056 - val_loss: 0.2088\n",
      "Epoch 47/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2050 - val_loss: 0.2088\n",
      "Epoch 48/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2040 - val_loss: 0.2086\n",
      "Epoch 49/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2043 - val_loss: 0.2094\n",
      "Epoch 50/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2044 - val_loss: 0.2092\n",
      "Epoch 51/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2058 - val_loss: 0.2099\n",
      "Epoch 52/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2048 - val_loss: 0.2089\n",
      "Epoch 53/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2044 - val_loss: 0.2105\n",
      "Epoch 54/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2049 - val_loss: 0.2097\n",
      "Epoch 55/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2046 - val_loss: 0.2091\n",
      "Epoch 56/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2037 - val_loss: 0.2088\n",
      "Epoch 57/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2030 - val_loss: 0.2087\n",
      "Epoch 58/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2038 - val_loss: 0.2088\n",
      "Epoch 59/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2026 - val_loss: 0.2087\n",
      "Epoch 60/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2038 - val_loss: 0.2088\n",
      "Epoch 61/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2033 - val_loss: 0.2089\n",
      "Epoch 62/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2035 - val_loss: 0.2093\n",
      "Epoch 63/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2035 - val_loss: 0.2087\n",
      "Epoch 64/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2029 - val_loss: 0.2087\n",
      "Epoch 65/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2036 - val_loss: 0.2087\n",
      "Epoch 66/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2036 - val_loss: 0.2088\n",
      "Epoch 67/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2027 - val_loss: 0.2087\n",
      "Epoch 68/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2043 - val_loss: 0.2087\n",
      "Fold 1 NN: 0.20858\n",
      "CV 2/5\n",
      "Epoch 1/500\n",
      "168/168 [==============================] - 2s 6ms/step - loss: 17.0437 - val_loss: 2.1934\n",
      "Epoch 2/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.1094 - val_loss: 0.5330\n",
      "Epoch 3/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.7448 - val_loss: 0.7489\n",
      "Epoch 4/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6603 - val_loss: 0.6971\n",
      "Epoch 5/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5841 - val_loss: 0.2568\n",
      "Epoch 6/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3985 - val_loss: 0.6305\n",
      "Epoch 7/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5442 - val_loss: 0.5909\n",
      "Epoch 8/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5066 - val_loss: 0.5416\n",
      "Epoch 9/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4838 - val_loss: 0.5686\n",
      "Epoch 10/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4634 - val_loss: 0.4064\n",
      "Epoch 11/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4477 - val_loss: 0.4821\n",
      "Epoch 12/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4174 - val_loss: 0.4454\n",
      "Epoch 13/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2462 - val_loss: 0.2218\n",
      "Epoch 14/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2136 - val_loss: 0.2231\n",
      "Epoch 15/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2126 - val_loss: 0.2229\n",
      "Epoch 16/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2124 - val_loss: 0.2206\n",
      "Epoch 17/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2114 - val_loss: 0.2216\n",
      "Epoch 18/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2108 - val_loss: 0.2204\n",
      "Epoch 19/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2178 - val_loss: 0.2245\n",
      "Epoch 20/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2135 - val_loss: 0.2201\n",
      "Epoch 21/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2108 - val_loss: 0.2183\n",
      "Epoch 22/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2095 - val_loss: 0.2183\n",
      "Epoch 23/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2109 - val_loss: 0.2229\n",
      "Epoch 24/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2101 - val_loss: 0.2168\n",
      "Epoch 25/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2086 - val_loss: 0.2180\n",
      "Epoch 26/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2118 - val_loss: 0.2182\n",
      "Epoch 27/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2104 - val_loss: 0.2188\n",
      "Epoch 28/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2097 - val_loss: 0.2175\n",
      "Epoch 29/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2100 - val_loss: 0.2156\n",
      "Epoch 30/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2115 - val_loss: 0.2177\n",
      "Epoch 31/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2140 - val_loss: 0.2167\n",
      "Epoch 32/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2113 - val_loss: 0.2254\n",
      "Epoch 33/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2166 - val_loss: 0.2181\n",
      "Epoch 34/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2112 - val_loss: 0.2289\n",
      "Epoch 35/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2131 - val_loss: 0.2168\n",
      "Epoch 36/500\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.2135 - val_loss: 0.2212\n",
      "Epoch 37/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2051 - val_loss: 0.2150\n",
      "Epoch 38/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2039 - val_loss: 0.2152\n",
      "Epoch 39/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2036 - val_loss: 0.2128\n",
      "Epoch 40/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2027 - val_loss: 0.2138\n",
      "Epoch 41/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2037 - val_loss: 0.2147\n",
      "Epoch 42/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2031 - val_loss: 0.2129\n",
      "Epoch 43/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2038 - val_loss: 0.2152\n",
      "Epoch 44/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2031 - val_loss: 0.2144\n",
      "Epoch 45/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2029 - val_loss: 0.2129\n",
      "Epoch 46/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2037 - val_loss: 0.2158\n",
      "Epoch 47/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2015 - val_loss: 0.2136\n",
      "Epoch 48/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2016 - val_loss: 0.2139\n",
      "Epoch 49/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2015 - val_loss: 0.2141\n",
      "Epoch 50/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2011 - val_loss: 0.2137\n",
      "Epoch 51/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2013 - val_loss: 0.2146\n",
      "Epoch 52/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2013 - val_loss: 0.2132\n",
      "Epoch 53/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2009 - val_loss: 0.2131\n",
      "Epoch 54/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2020 - val_loss: 0.2138\n",
      "Epoch 55/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2009 - val_loss: 0.2134\n",
      "Epoch 56/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2006 - val_loss: 0.2142\n",
      "Epoch 57/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2014 - val_loss: 0.2146\n",
      "Epoch 58/500\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.2011 - val_loss: 0.2143\n",
      "Epoch 59/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2010 - val_loss: 0.2138\n",
      "Fold 2 NN: 0.21277\n",
      "CV 3/5\n",
      "Epoch 1/500\n",
      "168/168 [==============================] - 2s 6ms/step - loss: 18.1411 - val_loss: 3.2973\n",
      "Epoch 2/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5345 - val_loss: 1.0762\n",
      "Epoch 3/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.2909 - val_loss: 0.8376\n",
      "Epoch 4/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0333 - val_loss: 0.9832\n",
      "Epoch 5/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9572 - val_loss: 0.8488\n",
      "Epoch 6/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9239 - val_loss: 0.7963\n",
      "Epoch 7/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.8262 - val_loss: 0.9849\n",
      "Epoch 8/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.7646 - val_loss: 0.2341\n",
      "Epoch 9/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2411 - val_loss: 0.2293\n",
      "Epoch 10/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2598 - val_loss: 0.2525\n",
      "Epoch 11/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2635 - val_loss: 0.2186\n",
      "Epoch 12/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2654 - val_loss: 0.2540\n",
      "Epoch 13/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2848 - val_loss: 0.5462\n",
      "Epoch 14/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5149 - val_loss: 0.4481\n",
      "Epoch 15/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3919 - val_loss: 0.6027\n",
      "Epoch 16/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.4723 - val_loss: 0.4080\n",
      "Epoch 17/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4360 - val_loss: 0.4301\n",
      "Epoch 18/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3981 - val_loss: 0.3847\n",
      "Epoch 19/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2381 - val_loss: 0.2138\n",
      "Epoch 20/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2110 - val_loss: 0.2120\n",
      "Epoch 21/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2101 - val_loss: 0.2150\n",
      "Epoch 22/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2099 - val_loss: 0.2121\n",
      "Epoch 23/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2098 - val_loss: 0.2110\n",
      "Epoch 24/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2088 - val_loss: 0.2114\n",
      "Epoch 25/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2093 - val_loss: 0.2110\n",
      "Epoch 26/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2087 - val_loss: 0.2101\n",
      "Epoch 27/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2097 - val_loss: 0.2131\n",
      "Epoch 28/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2095 - val_loss: 0.2104\n",
      "Epoch 29/500\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.2101 - val_loss: 0.2116\n",
      "Epoch 30/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2105 - val_loss: 0.2167\n",
      "Epoch 31/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2080 - val_loss: 0.2152\n",
      "Epoch 32/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2094 - val_loss: 0.2183\n",
      "Epoch 33/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2106 - val_loss: 0.2114\n",
      "Epoch 34/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2050 - val_loss: 0.2092\n",
      "Epoch 35/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2045 - val_loss: 0.2093\n",
      "Epoch 36/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2038 - val_loss: 0.2096\n",
      "Epoch 37/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2034 - val_loss: 0.2109\n",
      "Epoch 38/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2038 - val_loss: 0.2095\n",
      "Epoch 39/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2031 - val_loss: 0.2110\n",
      "Epoch 40/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2042 - val_loss: 0.2102\n",
      "Epoch 41/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2036 - val_loss: 0.2097\n",
      "Epoch 42/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2041 - val_loss: 0.2092\n",
      "Epoch 43/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2030 - val_loss: 0.2095\n",
      "Epoch 44/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2024 - val_loss: 0.2094\n",
      "Epoch 45/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2029 - val_loss: 0.2096\n",
      "Epoch 46/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2029 - val_loss: 0.2098\n",
      "Epoch 47/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2027 - val_loss: 0.2093\n",
      "Epoch 48/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2028 - val_loss: 0.2091\n",
      "Epoch 49/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2021 - val_loss: 0.2094\n",
      "Epoch 50/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2028 - val_loss: 0.2094\n",
      "Epoch 51/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2023 - val_loss: 0.2092\n",
      "Epoch 52/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2027 - val_loss: 0.2091\n",
      "Epoch 53/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2033 - val_loss: 0.2094\n",
      "Epoch 54/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2022 - val_loss: 0.2093\n",
      "Epoch 55/500\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.2020 - val_loss: 0.2093\n",
      "Epoch 56/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2022 - val_loss: 0.2093\n",
      "Epoch 57/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2026 - val_loss: 0.2093\n",
      "Epoch 58/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2026 - val_loss: 0.2092\n",
      "Epoch 59/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2025 - val_loss: 0.2093\n",
      "Epoch 60/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2026 - val_loss: 0.2093\n",
      "Epoch 61/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2026 - val_loss: 0.2092\n",
      "Epoch 62/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2029 - val_loss: 0.2092\n",
      "Epoch 63/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2026 - val_loss: 0.2093\n",
      "Epoch 64/500\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.2018 - val_loss: 0.2093\n",
      "Epoch 65/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2025 - val_loss: 0.2093\n",
      "Epoch 66/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2024 - val_loss: 0.2093\n",
      "Epoch 67/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2030 - val_loss: 0.2093\n",
      "Epoch 68/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2025 - val_loss: 0.2093\n",
      "Fold 3 NN: 0.20915\n",
      "CV 4/5\n",
      "Epoch 1/500\n",
      "168/168 [==============================] - 2s 7ms/step - loss: 17.0668 - val_loss: 1.8120\n",
      "Epoch 2/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0864 - val_loss: 0.3466\n",
      "Epoch 3/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.7486 - val_loss: 1.0222\n",
      "Epoch 4/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6085 - val_loss: 0.6661\n",
      "Epoch 5/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6015 - val_loss: 0.5300\n",
      "Epoch 6/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5339 - val_loss: 0.4227\n",
      "Epoch 7/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5145 - val_loss: 0.5780\n",
      "Epoch 8/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4907 - val_loss: 0.3683\n",
      "Epoch 9/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4794 - val_loss: 0.4378\n",
      "Epoch 10/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2482 - val_loss: 0.2250\n",
      "Epoch 11/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2150 - val_loss: 0.2246\n",
      "Epoch 12/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2157 - val_loss: 0.2193\n",
      "Epoch 13/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2126 - val_loss: 0.2242\n",
      "Epoch 14/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2137 - val_loss: 0.2220\n",
      "Epoch 15/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2132 - val_loss: 0.2214\n",
      "Epoch 16/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2133 - val_loss: 0.2234\n",
      "Epoch 17/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2142 - val_loss: 0.2335\n",
      "Epoch 18/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2145 - val_loss: 0.2181\n",
      "Epoch 19/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2122 - val_loss: 0.2226\n",
      "Epoch 20/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2117 - val_loss: 0.2202\n",
      "Epoch 21/500\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.2185 - val_loss: 0.2230\n",
      "Epoch 22/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2124 - val_loss: 0.2241\n",
      "Epoch 23/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2130 - val_loss: 0.2225\n",
      "Epoch 24/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2119 - val_loss: 0.2224\n",
      "Epoch 25/500\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.2088 - val_loss: 0.2180\n",
      "Epoch 26/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2065 - val_loss: 0.2162\n",
      "Epoch 27/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2060 - val_loss: 0.2192\n",
      "Epoch 28/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2055 - val_loss: 0.2181\n",
      "Epoch 29/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2053 - val_loss: 0.2173\n",
      "Epoch 30/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2053 - val_loss: 0.2163\n",
      "Epoch 31/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2058 - val_loss: 0.2194\n",
      "Epoch 32/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2060 - val_loss: 0.2172\n",
      "Epoch 33/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2053 - val_loss: 0.2171\n",
      "Epoch 34/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2045 - val_loss: 0.2168\n",
      "Epoch 35/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2038 - val_loss: 0.2167\n",
      "Epoch 36/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2045 - val_loss: 0.2172\n",
      "Epoch 37/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2044 - val_loss: 0.2166\n",
      "Epoch 38/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2039 - val_loss: 0.2165\n",
      "Epoch 39/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2040 - val_loss: 0.2163\n",
      "Epoch 40/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2046 - val_loss: 0.2167\n",
      "Epoch 41/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2041 - val_loss: 0.2164\n",
      "Epoch 42/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2036 - val_loss: 0.2165\n",
      "Epoch 43/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2040 - val_loss: 0.2165\n",
      "Epoch 44/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2037 - val_loss: 0.2167\n",
      "Epoch 45/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2035 - val_loss: 0.2165\n",
      "Epoch 46/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2039 - val_loss: 0.2167\n",
      "Fold 4 NN: 0.21616\n",
      "CV 5/5\n",
      "Epoch 1/500\n",
      "168/168 [==============================] - 2s 7ms/step - loss: 14.4111 - val_loss: 1.4885\n",
      "Epoch 2/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.2640 - val_loss: 0.3120\n",
      "Epoch 3/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9358 - val_loss: 0.5660\n",
      "Epoch 4/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6097 - val_loss: 0.4052\n",
      "Epoch 5/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5366 - val_loss: 0.6110\n",
      "Epoch 6/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5276 - val_loss: 0.4397\n",
      "Epoch 7/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4734 - val_loss: 0.4940\n",
      "Epoch 8/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.4641 - val_loss: 0.4643\n",
      "Epoch 9/500\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.4203 - val_loss: 0.2390\n",
      "Epoch 10/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2866 - val_loss: 0.3605\n",
      "Epoch 11/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4452 - val_loss: 0.3056\n",
      "Epoch 12/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4216 - val_loss: 0.4007\n",
      "Epoch 13/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4064 - val_loss: 0.3834\n",
      "Epoch 14/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6117 - val_loss: 0.4221\n",
      "Epoch 15/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3637 - val_loss: 0.5497\n",
      "Epoch 16/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3613 - val_loss: 0.3550\n",
      "Epoch 17/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2295 - val_loss: 0.2178\n",
      "Epoch 18/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2117 - val_loss: 0.2180\n",
      "Epoch 19/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2100 - val_loss: 0.2188\n",
      "Epoch 20/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2108 - val_loss: 0.2209\n",
      "Epoch 21/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2098 - val_loss: 0.2197\n",
      "Epoch 22/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2094 - val_loss: 0.2182\n",
      "Epoch 23/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2087 - val_loss: 0.2175\n",
      "Epoch 24/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2087 - val_loss: 0.2200\n",
      "Epoch 25/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2119 - val_loss: 0.2152\n",
      "Epoch 26/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2075 - val_loss: 0.2158\n",
      "Epoch 27/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2143 - val_loss: 0.2281\n",
      "Epoch 28/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2118 - val_loss: 0.2190\n",
      "Epoch 29/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2075 - val_loss: 0.2160\n",
      "Epoch 30/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2072 - val_loss: 0.2188\n",
      "Epoch 31/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2081 - val_loss: 0.2165\n",
      "Epoch 32/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2123 - val_loss: 0.2169\n",
      "Epoch 33/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2051 - val_loss: 0.2137\n",
      "Epoch 34/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2050 - val_loss: 0.2144\n",
      "Epoch 35/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2049 - val_loss: 0.2142\n",
      "Epoch 36/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2036 - val_loss: 0.2154\n",
      "Epoch 37/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2037 - val_loss: 0.2146\n",
      "Epoch 38/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2035 - val_loss: 0.2150\n",
      "Epoch 39/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2028 - val_loss: 0.2152\n",
      "Epoch 40/500\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.2031 - val_loss: 0.2151\n",
      "Epoch 41/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2023 - val_loss: 0.2138\n",
      "Epoch 42/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2025 - val_loss: 0.2136\n",
      "Epoch 43/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2022 - val_loss: 0.2142\n",
      "Epoch 44/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2026 - val_loss: 0.2141\n",
      "Epoch 45/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2026 - val_loss: 0.2137\n",
      "Epoch 46/500\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.2022 - val_loss: 0.2144\n",
      "Epoch 47/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2029 - val_loss: 0.2144\n",
      "Epoch 48/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2024 - val_loss: 0.2137\n",
      "Epoch 49/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2030 - val_loss: 0.2138\n",
      "Epoch 50/500\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.2024 - val_loss: 0.2140\n",
      "Epoch 51/500\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2023 - val_loss: 0.2138\n",
      "Epoch 52/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2018 - val_loss: 0.2139\n",
      "Epoch 53/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2024 - val_loss: 0.2136\n",
      "Epoch 54/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2021 - val_loss: 0.2137\n",
      "Epoch 55/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2030 - val_loss: 0.2138\n",
      "Epoch 56/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2019 - val_loss: 0.2137\n",
      "Epoch 57/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2018 - val_loss: 0.2139\n",
      "Epoch 58/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2028 - val_loss: 0.2138\n",
      "Epoch 59/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2012 - val_loss: 0.2137\n",
      "Epoch 60/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2018 - val_loss: 0.2138\n",
      "Epoch 61/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2019 - val_loss: 0.2138\n",
      "Epoch 62/500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2023 - val_loss: 0.2137\n",
      "Fold 5 NN: 0.21361\n"
     ]
    }
   ],
   "source": [
    "target_name='target'\n",
    "scores_folds = {}\n",
    "model_name = 'NN'\n",
    "pred_name = 'pred_{}'.format(model_name)\n",
    "\n",
    "n_folds = 5\n",
    "kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=2020)\n",
    "scores_folds[model_name] = []\n",
    "counter = 1\n",
    "\n",
    "features_to_consider = list(train_nn)\n",
    "\n",
    "features_to_consider.remove('time_id')\n",
    "features_to_consider.remove('target')\n",
    "try:\n",
    "    features_to_consider.remove('pred_NN')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "train_nn[features_to_consider] = train_nn[features_to_consider].fillna(train_nn[features_to_consider].mean())\n",
    "test_nn[features_to_consider] = test_nn[features_to_consider].fillna(train_nn[features_to_consider].mean())\n",
    "\n",
    "train_nn[pred_name] = 0\n",
    "test_nn[target_name] = 0\n",
    "test_predictions_nn = np.zeros(test_nn.shape[0])\n",
    "\n",
    "for n_count in range(n_folds):\n",
    "    print('CV {}/{}'.format(counter, n_folds))\n",
    "    \n",
    "    indexes = np.arange(nfolds).astype(int)    \n",
    "    indexes = np.delete(indexes,obj=n_count, axis=0) \n",
    "    \n",
    "    indexes = np.r_[values[indexes[0]],values[indexes[1]],values[indexes[2]],values[indexes[3]]]\n",
    "    \n",
    "    X_train = train_nn.loc[train_nn.time_id.isin(indexes), features_to_consider]\n",
    "    y_train = train_nn.loc[train_nn.time_id.isin(indexes), target_name]\n",
    "    X_test = train_nn.loc[train_nn.time_id.isin(values[n_count]), features_to_consider]\n",
    "    y_test = train_nn.loc[train_nn.time_id.isin(values[n_count]), target_name]\n",
    "    \n",
    "    #############################################################################################\n",
    "    # NN\n",
    "    #############################################################################################\n",
    "    \n",
    "    model = base_model()\n",
    "    \n",
    "    model.compile(\n",
    "        keras.optimizers.Adam(learning_rate=0.006),\n",
    "        loss=root_mean_squared_per_error\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        features_to_consider.remove('stock_id')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    num_data = X_train[features_to_consider]\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))         \n",
    "    num_data = scaler.fit_transform(num_data.values)    \n",
    "    \n",
    "    cat_data = X_train['stock_id']    \n",
    "    target =  y_train\n",
    "    \n",
    "    num_data_test = X_test[features_to_consider]\n",
    "    num_data_test = scaler.transform(num_data_test.values)\n",
    "    cat_data_test = X_test['stock_id']\n",
    "\n",
    "    model.fit([cat_data, num_data], \n",
    "              target,               \n",
    "              batch_size=2048,\n",
    "              epochs=500, #### 1000,\n",
    "              validation_data=([cat_data_test, num_data_test], y_test),\n",
    "              callbacks=[es, plateau],\n",
    "              validation_batch_size=len(y_test),\n",
    "              shuffle=True,\n",
    "             verbose = 1)\n",
    "\n",
    "    preds = model.predict([cat_data_test, num_data_test]).reshape(1,-1)[0]\n",
    "    \n",
    "    score = round(rmspe(y_true = y_test, y_pred = preds),5)\n",
    "    print('Fold {} {}: {}'.format(counter, model_name, score))\n",
    "    scores_folds[model_name].append(score)\n",
    "    \n",
    "    tt =scaler.transform(test_nn[features_to_consider].values)\n",
    "    test_predictions_nn += model.predict([test_nn['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)/n_folds\n",
    "       \n",
    "    counter += 1\n",
    "    features_to_consider.append('stock_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bc73cee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:19:03.666669Z",
     "iopub.status.busy": "2021-09-19T15:19:03.665868Z",
     "iopub.status.idle": "2021-09-19T15:19:03.818124Z",
     "shell.execute_reply": "2021-09-19T15:19:03.817635Z"
    },
    "papermill": {
     "duration": 1.634013,
     "end_time": "2021-09-19T15:19:03.818243",
     "exception": false,
     "start_time": "2021-09-19T15:19:02.184230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del X_train, y_train\n",
    "del num_data, train_nn\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0db5970f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:19:06.394115Z",
     "iopub.status.busy": "2021-09-19T15:19:06.386749Z",
     "iopub.status.idle": "2021-09-19T15:19:06.411579Z",
     "shell.execute_reply": "2021-09-19T15:19:06.412091Z",
     "shell.execute_reply.started": "2021-09-01T09:00:46.204378Z"
    },
    "papermill": {
     "duration": 1.322384,
     "end_time": "2021-09-19T15:19:06.412306",
     "exception": false,
     "start_time": "2021-09-19T15:19:05.089922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show_memory:\n",
      "train_p 3\n",
      "out_train 3\n",
      "cat_data 5\n",
      "X_test 113\n",
      "y_test 1\n",
      "target 5\n",
      "num_data_test 159\n",
      "cat_data_test 1\n"
     ]
    }
   ],
   "source": [
    "def show_memory(unit='MB', threshold=1):\n",
    "    from sys import getsizeof\n",
    "    scale = {'B': 1, 'KB': 1024, 'MB': 1048576, 'GB': 1073741824}[unit]\n",
    "    for i in list(globals().keys()):\n",
    "        memory = eval(\"getsizeof({})\".format(i)) // scale\n",
    "        if memory >= threshold:\n",
    "            print(i, memory)\n",
    "try: \n",
    "    print(\"show_memory:\")\n",
    "    show_memory()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37d061a",
   "metadata": {
    "papermill": {
     "duration": 1.2978,
     "end_time": "2021-09-19T15:19:08.965174",
     "exception": false,
     "start_time": "2021-09-19T15:19:07.667374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0103af3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:19:11.734182Z",
     "iopub.status.busy": "2021-09-19T15:19:11.733447Z",
     "iopub.status.idle": "2021-09-19T15:19:38.670091Z",
     "shell.execute_reply": "2021-09-19T15:19:38.670579Z",
     "shell.execute_reply.started": "2021-08-31T16:14:49.200325Z"
    },
    "papermill": {
     "duration": 28.366338,
     "end_time": "2021-09-19T15:19:38.670765",
     "exception": false,
     "start_time": "2021-09-19T15:19:10.304427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ../input/d/ryati131457/pytorchtabnet/pytorch_tabnet-3.1.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0eec75a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:19:41.249304Z",
     "iopub.status.busy": "2021-09-19T15:19:41.248508Z",
     "iopub.status.idle": "2021-09-19T15:19:42.220629Z",
     "shell.execute_reply": "2021-09-19T15:19:42.219681Z",
     "shell.execute_reply.started": "2021-08-31T16:15:11.319116Z"
    },
    "papermill": {
     "duration": 2.263415,
     "end_time": "2021-09-19T15:19:42.220773",
     "exception": false,
     "start_time": "2021-09-19T15:19:39.957358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy.matlib\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "\n",
    "\n",
    "# setting some globl config\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "orange_black = [\n",
    "    '#fdc029', '#df861d', '#FF6347', '#aa3d01', '#a30e15', '#800000', '#171820'\n",
    "]\n",
    "plt.rcParams['figure.figsize'] = (16,9)\n",
    "plt.rcParams[\"figure.facecolor\"] = '#FFFACD'\n",
    "plt.rcParams[\"axes.facecolor\"] = '#FFFFE0'\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"grid.color\"] = orange_black[3]\n",
    "plt.rcParams[\"grid.alpha\"] = 0.5\n",
    "plt.rcParams[\"grid.linestyle\"] = '--'\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15e2bd4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:19:45.061218Z",
     "iopub.status.busy": "2021-09-19T15:19:45.060449Z",
     "iopub.status.idle": "2021-09-19T15:19:45.065155Z",
     "shell.execute_reply": "2021-09-19T15:19:45.064657Z"
    },
    "papermill": {
     "duration": 1.31028,
     "end_time": "2021-09-19T15:19:45.065264",
     "exception": false,
     "start_time": "2021-09-19T15:19:43.754984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "psutil.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab5f9dde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:19:47.657931Z",
     "iopub.status.busy": "2021-09-19T15:19:47.657052Z",
     "iopub.status.idle": "2021-09-19T15:19:47.727174Z",
     "shell.execute_reply": "2021-09-19T15:19:47.726647Z"
    },
    "papermill": {
     "duration": 1.366184,
     "end_time": "2021-09-19T15:19:47.727294",
     "exception": false,
     "start_time": "2021-09-19T15:19:46.361110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 19 15:19:47 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   38C    P0    36W / 250W |  15399MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03869567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:19:50.311845Z",
     "iopub.status.busy": "2021-09-19T15:19:50.310811Z",
     "iopub.status.idle": "2021-09-19T15:19:50.313945Z",
     "shell.execute_reply": "2021-09-19T15:19:50.313475Z"
    },
    "papermill": {
     "duration": 1.297771,
     "end_time": "2021-09-19T15:19:50.314056",
     "exception": false,
     "start_time": "2021-09-19T15:19:49.016285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_train_test():\n",
    "    # Function to read our base train and test set\n",
    "    \n",
    "    train = pd.read_csv(f'{data_dir}/train.csv')\n",
    "    test = pd.read_csv(f'{data_dir}/test.csv')\n",
    "\n",
    "    # Create a key to merge with book and trade data\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n",
    "    print(f'Our training set has {train.shape[0]} rows')\n",
    "    print(f'Our test set has {test.shape[0]} rows')\n",
    "    print(f'Our training set has {train.isna().sum().sum()} missing values')\n",
    "    print(f'Our test set has {test.isna().sum().sum()} missing values')\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3356c9a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:19:52.925696Z",
     "iopub.status.busy": "2021-09-19T15:19:52.925137Z",
     "iopub.status.idle": "2021-09-19T15:19:54.127721Z",
     "shell.execute_reply": "2021-09-19T15:19:54.128300Z"
    },
    "papermill": {
     "duration": 2.506696,
     "end_time": "2021-09-19T15:19:54.128543",
     "exception": false,
     "start_time": "2021-09-19T15:19:51.621847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training set has 428932 rows\n",
      "Our test set has 3 rows\n",
      "Our training set has 0 missing values\n",
      "Our test set has 0 missing values\n"
     ]
    }
   ],
   "source": [
    "train, test = read_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ead66b22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:19:57.485391Z",
     "iopub.status.busy": "2021-09-19T15:19:57.469807Z",
     "iopub.status.idle": "2021-09-19T15:19:57.495866Z",
     "shell.execute_reply": "2021-09-19T15:19:57.495252Z"
    },
    "papermill": {
     "duration": 1.701647,
     "end_time": "2021-09-19T15:19:57.496038",
     "exception": false,
     "start_time": "2021-09-19T15:19:55.794391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_wap1(df):\n",
    "    # Function to calculate first WAP\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap2(df):\n",
    "    # Function to calculate second WAP\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "def log_return(series):\n",
    "    # Function to calculate the log of the return\n",
    "    return np.log(series).diff()\n",
    "\n",
    "def realized_volatility(series):\n",
    "    # Calculate the realized volatility\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "def count_unique(series):\n",
    "    # Function to count unique elements of a series\n",
    "    return len(np.unique(series))\n",
    "\n",
    "def book_preprocessor(file_path):\n",
    "    # Function to preprocess book data (for each stock id)\n",
    "    \n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Calculate Wap\n",
    "    df['wap1'] = calc_wap1(df)\n",
    "    df['wap2'] = calc_wap2(df)\n",
    "    \n",
    "    # Calculate log returns\n",
    "    df['log_return1'] = df.groupby(['time_id'])['wap1'].apply(log_return)\n",
    "    df['log_return2'] = df.groupby(['time_id'])['wap2'].apply(log_return)\n",
    "    \n",
    "    # Calculate wap balance\n",
    "    df['wap_balance'] = abs(df['wap1'] - df['wap2'])\n",
    "    \n",
    "    # Calculate spread\n",
    "    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n",
    "    df['price_spread2'] = (df['ask_price2'] - df['bid_price2']) / ((df['ask_price2'] + df['bid_price2']) / 2)\n",
    "    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n",
    "    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n",
    "    df[\"bid_ask_spread\"] = abs(df['bid_spread'] - df['ask_spread'])\n",
    "    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'wap1': [np.sum, np.mean, np.std],\n",
    "        'wap2': [np.sum, np.mean, np.std],\n",
    "        'log_return1': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return2': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'wap_balance': [np.sum, np.mean, np.std],\n",
    "        'price_spread':[np.sum, np.mean, np.std],\n",
    "        'price_spread2':[np.sum, np.mean, np.std],\n",
    "        'bid_spread':[np.sum, np.mean, np.std],\n",
    "        'ask_spread':[np.sum, np.mean, np.std],\n",
    "        'total_volume':[np.sum, np.mean, np.std],\n",
    "        'volume_imbalance':[np.sum, np.mean, np.std],\n",
    "        \"bid_ask_spread\":[np.sum, np.mean, np.std],\n",
    "    }\n",
    "    \n",
    "    def get_stats_window(seconds_in_bucket, add_suffix = False):\n",
    "        # Function to get group stats for different windows (seconds in bucket)\n",
    "        \n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(create_feature_dict).reset_index()\n",
    "        \n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        \n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_400 = get_stats_window(seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(seconds_in_bucket = 200, add_suffix = True)\n",
    "    \n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__400', 'time_id__300', 'time_id__200'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    # Create row_id so we can merge\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n",
    "    df_feature.drop(['time_id_'], axis = 1, inplace = True)\n",
    "    \n",
    "    return df_feature\n",
    "\n",
    "\n",
    "def trade_preprocessor(file_path):\n",
    "    # Function to preprocess trade data (for each stock id)\n",
    "    \n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum, realized_volatility, np.mean, np.std, np.max, np.min],\n",
    "        'order_count':[np.mean,np.sum,np.max],\n",
    "    }\n",
    "    \n",
    "    def get_stats_window(seconds_in_bucket, add_suffix = False):\n",
    "        # Function to get group stats for different windows (seconds in bucket)\n",
    "        \n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(create_feature_dict).reset_index()\n",
    "        \n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        \n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_400 = get_stats_window(seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(seconds_in_bucket = 200, add_suffix = True)\n",
    "    \n",
    "    def tendency(price, vol):    \n",
    "        df_diff = np.diff(price)\n",
    "        val = (df_diff/price[1:])*100\n",
    "        power = np.sum(val*vol[1:])\n",
    "        return(power)\n",
    "    \n",
    "    lis = []\n",
    "    for n_time_id in df['time_id'].unique():\n",
    "        df_id = df[df['time_id'] == n_time_id]        \n",
    "        tendencyV = tendency(df_id['price'].values, df_id['size'].values)      \n",
    "        f_max = np.sum(df_id['price'].values > np.mean(df_id['price'].values))\n",
    "        f_min = np.sum(df_id['price'].values < np.mean(df_id['price'].values))\n",
    "        df_max =  np.sum(np.diff(df_id['price'].values) > 0)\n",
    "        df_min =  np.sum(np.diff(df_id['price'].values) < 0)\n",
    "        abs_diff = np.median(np.abs( df_id['price'].values - np.mean(df_id['price'].values)))        \n",
    "        energy = np.mean(df_id['price'].values**2)\n",
    "        iqr_p = np.percentile(df_id['price'].values,75) - np.percentile(df_id['price'].values,25)\n",
    "        abs_diff_v = np.median(np.abs( df_id['size'].values - np.mean(df_id['size'].values)))        \n",
    "        energy_v = np.sum(df_id['size'].values**2)\n",
    "        iqr_p_v = np.percentile(df_id['size'].values,75) - np.percentile(df_id['size'].values,25)\n",
    "        \n",
    "        lis.append({'time_id':n_time_id,'tendency':tendencyV,'f_max':f_max,'f_min':f_min,'df_max':df_max,'df_min':df_min,\n",
    "                   'abs_diff':abs_diff,'energy':energy,'iqr_p':iqr_p,'abs_diff_v':abs_diff_v,'energy_v':energy_v,'iqr_p_v':iqr_p_v})\n",
    "    \n",
    "    df_lr = pd.DataFrame(lis)\n",
    "        \n",
    "   \n",
    "    df_feature = df_feature.merge(df_lr, how = 'left', left_on = 'time_id_', right_on = 'time_id')\n",
    "    \n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__400', 'time_id__300', 'time_id__200','time_id'], axis = 1, inplace = True)\n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature.drop(['trade_time_id_'], axis = 1, inplace = True)\n",
    "    \n",
    "    def order_sum(df, sec:str):\n",
    "        new_col = 'size_tau' + sec\n",
    "        bucket_col = 'trade_seconds_in_bucket_count_unique' + sec\n",
    "        df[new_col] = np.sqrt(1/df[bucket_col])\n",
    "        \n",
    "        new_col2 = 'size_tau2' + sec\n",
    "        order_col = 'trade_order_count_sum' + sec\n",
    "        df[new_col2] = np.sqrt(1/df[order_col])\n",
    "        \n",
    "        if sec == '400_':\n",
    "            df['size_tau2_d'] = df['size_tau2_400'] - df['size_tau2']\n",
    "        \n",
    "\n",
    "    \n",
    "    for sec in ['','_200','_300','_400']:\n",
    "        order_sum(df_feature, sec)\n",
    "        \n",
    "    df_feature['size_tau2_d'] = df_feature['size_tau2_400'] - df_feature['size_tau2']\n",
    "    \n",
    "    return df_feature\n",
    "\n",
    "\n",
    "def get_time_stock(df):\n",
    "    # Function to get group stats for the stock_id and time_id\n",
    "    \n",
    "    # Get realized volatility columns\n",
    "    vol_cols = ['log_return1_realized_volatility', 'log_return2_realized_volatility', 'log_return1_realized_volatility_400', 'log_return2_realized_volatility_400', \n",
    "                'log_return1_realized_volatility_300', 'log_return2_realized_volatility_300', 'log_return1_realized_volatility_200', 'log_return2_realized_volatility_200', \n",
    "                'trade_log_return_realized_volatility', 'trade_log_return_realized_volatility_400', 'trade_log_return_realized_volatility_300', 'trade_log_return_realized_volatility_200']\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    \n",
    "    # Rename columns joining suffix\n",
    "    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n",
    "    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    \n",
    "    # Rename columns joining suffix\n",
    "    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n",
    "    df_time_id = df_time_id.add_suffix('_' + 'time')\n",
    "    \n",
    "    # Merge with original dataframe\n",
    "    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n",
    "    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n",
    "    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_agg_features(train, test):\n",
    "\n",
    "    # Making agg features\n",
    "\n",
    "    train_p = pd.read_csv(f'{data_dir}/train.csv')\n",
    "    train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "    corr = train_p.corr()\n",
    "    ids = corr.index\n",
    "    kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "    l = []\n",
    "    for n in range(7):\n",
    "        l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "\n",
    "    mat = []\n",
    "    matTest = []\n",
    "    n = 0\n",
    "    for ind in l:\n",
    "        newDf = train.loc[train['stock_id'].isin(ind) ]\n",
    "        newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "        newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "        mat.append ( newDf )\n",
    "        newDf = test.loc[test['stock_id'].isin(ind) ]    \n",
    "        newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "        newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "        matTest.append ( newDf )\n",
    "        n+=1\n",
    "\n",
    "    mat1 = pd.concat(mat).reset_index()\n",
    "    mat1.drop(columns=['target'],inplace=True)\n",
    "    mat2 = pd.concat(matTest).reset_index()\n",
    "    \n",
    "    mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])\n",
    "    \n",
    "    mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "    mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "    mat1.reset_index(inplace=True)\n",
    "    \n",
    "    mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "    mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "    mat2.reset_index(inplace=True)\n",
    "    \n",
    "    prefix = ['log_return1_realized_volatility', 'total_volume_mean', 'trade_size_mean', 'trade_order_count_mean','price_spread_mean','bid_spread_mean','ask_spread_mean',\n",
    "              'volume_imbalance_mean', 'bid_ask_spread_mean','size_tau2']\n",
    "    selected_cols=mat1.filter(regex='|'.join(f'^{x}.(0|1|3|4|6)c1' for x in prefix)).columns.tolist()\n",
    "    selected_cols.append('time_id')\n",
    "    \n",
    "    train_m = pd.merge(train,mat1[selected_cols],how='left',on='time_id')\n",
    "    test_m = pd.merge(test,mat2[selected_cols],how='left',on='time_id')\n",
    "    \n",
    "    # filling missing values with train means\n",
    "\n",
    "    features = [col for col in train_m.columns.tolist() if col not in ['time_id','target','row_id']]\n",
    "    train_m[features] = train_m[features].fillna(train_m[features].mean())\n",
    "    test_m[features] = test_m[features].fillna(train_m[features].mean())\n",
    "\n",
    "    return train_m, test_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d5a1715",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:20:00.154298Z",
     "iopub.status.busy": "2021-09-19T15:20:00.153427Z",
     "iopub.status.idle": "2021-09-19T15:20:41.235387Z",
     "shell.execute_reply": "2021-09-19T15:20:41.236210Z"
    },
    "papermill": {
     "duration": 42.401417,
     "end_time": "2021-09-19T15:20:41.236388",
     "exception": false,
     "start_time": "2021-09-19T15:19:58.834971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Get unique stock ids \n",
    "# train_stock_ids = train['stock_id'].unique()\n",
    "\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "# train_ = preprocessor(train_stock_ids, is_train = True)\n",
    "# train = train.merge(train_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get unique stock ids \n",
    "test_stock_ids = test['stock_id'].unique()\n",
    "\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "test_ = preprocessor(test_stock_ids, is_train = False)\n",
    "test = test.merge(test_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get group stats of time_id and stock_id\n",
    "# train = get_time_stock(train)\n",
    "test = get_time_stock(test)\n",
    "\n",
    "# Fill inf values\n",
    "# train.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "test.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    " \n",
    "    \n",
    "train = pd.read_pickle(\"../input/traintestdata/tabnet_oringal_091410_before_create_agg_features_tabnet.pkl\")\n",
    "# Aggregating some features   \n",
    "train, test = create_agg_features(train,test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5aafcfcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:20:44.053321Z",
     "iopub.status.busy": "2021-09-19T15:20:44.052757Z",
     "iopub.status.idle": "2021-09-19T15:20:44.057017Z",
     "shell.execute_reply": "2021-09-19T15:20:44.056607Z"
    },
    "papermill": {
     "duration": 1.538188,
     "end_time": "2021-09-19T15:20:44.057147",
     "exception": false,
     "start_time": "2021-09-19T15:20:42.518959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train.drop(['row_id', 'target', 'time_id'], axis = 1)\n",
    "y = train['target']\n",
    "X_test=test.copy() \n",
    "X_test.drop(['time_id','row_id'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b7897ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:20:46.650962Z",
     "iopub.status.busy": "2021-09-19T15:20:46.650059Z",
     "iopub.status.idle": "2021-09-19T15:20:46.652745Z",
     "shell.execute_reply": "2021-09-19T15:20:46.652292Z"
    },
    "papermill": {
     "duration": 1.321596,
     "end_time": "2021-09-19T15:20:46.652868",
     "exception": false,
     "start_time": "2021-09-19T15:20:45.331272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RMSPE(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"rmspe\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        \n",
    "        return np.sqrt(np.mean(np.square((y_true - y_score) / y_true)))\n",
    "\n",
    "def RMSPELoss(y_pred, y_true):\n",
    "    return torch.sqrt(torch.mean( ((y_true - y_pred) / y_true) ** 2 )).clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23bf506f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:20:49.280224Z",
     "iopub.status.busy": "2021-09-19T15:20:49.279476Z",
     "iopub.status.idle": "2021-09-19T15:20:57.300277Z",
     "shell.execute_reply": "2021-09-19T15:20:57.299766Z"
    },
    "papermill": {
     "duration": 9.373748,
     "end_time": "2021-09-19T15:20:57.300394",
     "exception": false,
     "start_time": "2021-09-19T15:20:47.926646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nunique = X.nunique()\n",
    "types = X.dtypes\n",
    "\n",
    "categorical_columns = []\n",
    "categorical_dims =  {}\n",
    "\n",
    "for col in X.columns:\n",
    "    if  col == 'stock_id':\n",
    "        l_enc = LabelEncoder()\n",
    "        X[col] = l_enc.fit_transform(X[col].values)\n",
    "        X_test[col] = l_enc.transform(X_test[col].values)\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(l_enc.classes_)\n",
    "    else:\n",
    "        scaler = StandardScaler()\n",
    "        X[col] = scaler.fit_transform(X[col].values.reshape(-1, 1))\n",
    "        X_test[col] = scaler.transform(X_test[col].values.reshape(-1, 1))\n",
    "\n",
    "cat_idxs = [ i for i, f in enumerate(X.columns.tolist()) if f in categorical_columns]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(X.columns.tolist()) if f in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc143de1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:20:59.944498Z",
     "iopub.status.busy": "2021-09-19T15:20:59.943570Z",
     "iopub.status.idle": "2021-09-19T15:20:59.945872Z",
     "shell.execute_reply": "2021-09-19T15:20:59.945205Z"
    },
    "papermill": {
     "duration": 1.358041,
     "end_time": "2021-09-19T15:20:59.946028",
     "exception": false,
     "start_time": "2021-09-19T15:20:58.587987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tabnet_params = dict(\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    cat_emb_dim=1,\n",
    "    n_d = 16,\n",
    "    n_a = 16,\n",
    "    n_steps = 2,\n",
    "    gamma = 2,\n",
    "    n_independent = 2,\n",
    "    n_shared = 2,\n",
    "    lambda_sparse = 0, \n",
    "    optimizer_fn = Adam,\n",
    "    optimizer_params = dict(lr = (2e-2)),\n",
    "    mask_type = \"entmax\",\n",
    "    scheduler_params = dict(T_0=200, T_mult=1, eta_min=1e-4, last_epoch=-1, verbose=False),\n",
    "    scheduler_fn = CosineAnnealingWarmRestarts,\n",
    "    seed = 42,\n",
    "    verbose = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f49ea183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:21:03.291430Z",
     "iopub.status.busy": "2021-09-19T15:21:03.290798Z",
     "iopub.status.idle": "2021-09-19T15:21:06.831818Z",
     "shell.execute_reply": "2021-09-19T15:21:06.832372Z"
    },
    "papermill": {
     "duration": 4.918596,
     "end_time": "2021-09-19T15:21:06.832584",
     "exception": false,
     "start_time": "2021-09-19T15:21:01.913988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: model_params.json (deflated 44%)\r\n",
      "  adding: network.pt (deflated 19%)\r\n",
      "  adding: model_params.json (deflated 44%)\r\n",
      "  adding: network.pt (deflated 19%)\r\n",
      "  adding: model_params.json (deflated 44%)\r\n",
      "  adding: network.pt (deflated 19%)\r\n",
      "  adding: model_params.json (deflated 44%)\r\n",
      "  adding: network.pt (deflated 19%)\r\n",
      "  adding: model_params.json (deflated 44%)\r\n",
      "  adding: network.pt (deflated 19%)\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/kaggle/input/tabnetmodelpth/tabnet_917015_fold0.model\")\n",
    "!zip /kaggle/working/fold0.zip ./* \n",
    "os.chdir(\"/kaggle/input/tabnetmodelpth/tabnet_917015_fold1.model\")\n",
    "!zip /kaggle/working/fold1.zip ./* \n",
    "os.chdir(\"/kaggle/input/tabnetmodelpth/tabnet_917015_fold2.model\")\n",
    "!zip /kaggle/working/fold2.zip ./* \n",
    "os.chdir(\"/kaggle/input/tabnetmodelpth/tabnet_917015_fold3.model\")\n",
    "!zip /kaggle/working/fold3.zip ./* \n",
    "os.chdir(\"/kaggle/input/tabnetmodelpth/tabnet_917015_fold4.model\")\n",
    "!zip /kaggle/working/fold4.zip ./* \n",
    "os.chdir('/kaggle/working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2fa8e09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:21:09.415618Z",
     "iopub.status.busy": "2021-09-19T15:21:09.413888Z",
     "iopub.status.idle": "2021-09-19T15:21:09.416370Z",
     "shell.execute_reply": "2021-09-19T15:21:09.416810Z"
    },
    "papermill": {
     "duration": 1.298109,
     "end_time": "2021-09-19T15:21:09.416947",
     "exception": false,
     "start_time": "2021-09-19T15:21:08.118838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn import model_selection\n",
    "\n",
    "# ---- GroupKFold ----\n",
    "class GroupKFold(object):\n",
    "    \"\"\"\n",
    "    GroupKFold with random shuffle with a sklearn-like structure\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=4, shuffle=True, random_state=42):\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, group=None):\n",
    "        return self.n_splits\n",
    "\n",
    "    def split(self, X, y, group):\n",
    "        kf = model_selection.KFold(n_splits=self.n_splits, shuffle=self.shuffle, random_state=self.random_state)\n",
    "        unique_ids = X[group].unique()\n",
    "        for fold, (tr_group_idx, va_group_idx) in enumerate(kf.split(unique_ids)):\n",
    "            # split group\n",
    "            tr_group, va_group = unique_ids[tr_group_idx], unique_ids[va_group_idx]\n",
    "            train_idx = np.where(X[group].isin(tr_group))[0]\n",
    "            val_idx = np.where(X[group].isin(va_group))[0]\n",
    "            yield train_idx, val_idx\n",
    "\n",
    "cv = GroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "kf = cv.split(train, train['target'], 'time_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec183259",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:21:12.229415Z",
     "iopub.status.busy": "2021-09-19T15:21:12.228603Z",
     "iopub.status.idle": "2021-09-19T15:21:54.878751Z",
     "shell.execute_reply": "2021-09-19T15:21:54.877983Z"
    },
    "papermill": {
     "duration": 44.166592,
     "end_time": "2021-09-19T15:21:54.878956",
     "exception": false,
     "start_time": "2021-09-19T15:21:10.712364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Training fold 2\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Training fold 3\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Training fold 4\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Training fold 5\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "OOF score across folds: 0.21283575918435563\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "# Create out of folds array\n",
    "oof_predictions = np.zeros((X.shape[0], 1))\n",
    "tabnet_test_predictions = np.zeros(X_test.shape[0])\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances[\"feature\"] = X.columns.tolist()\n",
    "stats = pd.DataFrame()\n",
    "explain_matrices = []\n",
    "masks_ =[]\n",
    "\n",
    "for fold, (trn_ind, val_ind) in enumerate(kf):\n",
    "# for fold, (trn_ind, val_ind) in enumerate(kfold.split(X)):\n",
    "    print(f'Training fold {fold + 1}')\n",
    "    X_val = X.iloc[val_ind].values\n",
    "    y_val = y.iloc[val_ind].values.reshape(-1,1)\n",
    "\n",
    "\n",
    "    clf =  TabNetRegressor(**tabnet_params)\n",
    "#     clf.fit(\n",
    "#       X_train, y_train,\n",
    "#       eval_set=[(X_val, y_val)],\n",
    "#       max_epochs = 200,\n",
    "#       patience = 50,\n",
    "#       batch_size = 1024*20, \n",
    "#       virtual_batch_size = 128*20,\n",
    "#       num_workers = 4,\n",
    "#       drop_last = False,\n",
    "#       eval_metric=[RMSPE],\n",
    "#       loss_fn=RMSPELoss\n",
    "#       )\n",
    "    \n",
    "#     saving_path_name = f\"./fold{fold}\"\n",
    "#     saved_filepath = clf.save_model(saving_path_name)\n",
    "    \n",
    "    \n",
    "    clf.load_model(f\"./fold{fold}.zip\")\n",
    "    \n",
    "    \n",
    "    explain_matrix, masks = clf.explain(X_val)\n",
    "#     explain_matrices.append(explain_matrix)\n",
    "#     masks_.append(masks[0])\n",
    "#     masks_.append(masks[1])\n",
    "      \n",
    "    oof_predictions[val_ind] = clf.predict(X_val)\n",
    "    tabnet_test_predictions+=clf.predict(X_test.values).flatten()/5\n",
    "#     feature_importances[f\"importance_fold{fold}+1\"] = clf.feature_importances_\n",
    "    \n",
    "#     stats[f'fold{fold+1}_train_rmspe']=clf.history['loss']\n",
    "#     stats[f'fold{fold+1}_val_rmspe']=clf.history['val_0_rmspe']\n",
    "    \n",
    "print(f'OOF score across folds: {rmspe(y, oof_predictions.flatten())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e964dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T15:21:57.792662Z",
     "iopub.status.busy": "2021-09-19T15:21:57.791953Z",
     "iopub.status.idle": "2021-09-19T15:21:57.795150Z",
     "shell.execute_reply": "2021-09-19T15:21:57.794741Z"
    },
    "papermill": {
     "duration": 1.327279,
     "end_time": "2021-09-19T15:21:57.795263",
     "exception": false,
     "start_time": "2021-09-19T15:21:56.467984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['target'] = test_predictions_nn*0.27 + predictions_lgb*0.23 + tabnet_test_predictions*0.5\n",
    "test[['row_id', 'target']].to_csv('submission.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3659.267462,
   "end_time": "2021-09-19T15:22:01.879529",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-19T14:21:02.612067",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}